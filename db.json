{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/images/cli.JPG","path":"images/cli.JPG","modified":0,"renderable":0},{"_id":"source/images/Memory-Leaks.JPG","path":"images/Memory-Leaks.JPG","modified":0,"renderable":0},{"_id":"source/images/redux-saga.JPG","path":"images/redux-saga.JPG","modified":0,"renderable":0},{"_id":"source/images/treeRecursion.JPG","path":"images/treeRecursion.JPG","modified":0,"renderable":0},{"_id":"source/images/treeRecursion11.JPG","path":"images/treeRecursion11.JPG","modified":0,"renderable":0},{"_id":"source/images/vscode.JPG","path":"images/vscode.JPG","modified":0,"renderable":0},{"_id":"themes/ocean/source/404.html","path":"404.html","modified":0,"renderable":1},{"_id":"themes/ocean/source/favicon.ico","path":"favicon.ico","modified":0,"renderable":1},{"_id":"source/images/lisp.JPG","path":"images/lisp.JPG","modified":0,"renderable":0},{"_id":"source/images/IMG_0504.JPG","path":"images/IMG_0504.JPG","modified":0,"renderable":0},{"_id":"source/images/IMG_0606.JPG","path":"images/IMG_0606.JPG","modified":0,"renderable":0},{"_id":"themes/ocean/source/css/404.styl","path":"css/404.styl","modified":0,"renderable":1},{"_id":"themes/ocean/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/ocean/source/fancybox/jquery.fancybox.min.css","path":"fancybox/jquery.fancybox.min.css","modified":0,"renderable":1},{"_id":"themes/ocean/source/css/tranquilheart.css","path":"css/tranquilheart.css","modified":0,"renderable":1},{"_id":"themes/ocean/source/images/hexo-inverted.svg","path":"images/hexo-inverted.svg","modified":0,"renderable":1},{"_id":"themes/ocean/source/images/hexo.svg","path":"images/hexo.svg","modified":0,"renderable":1},{"_id":"themes/ocean/source/images/searchfooter.png","path":"images/searchfooter.png","modified":0,"renderable":1},{"_id":"themes/ocean/source/js/busuanzi-2.3.pure.min.js","path":"js/busuanzi-2.3.pure.min.js","modified":0,"renderable":1},{"_id":"themes/ocean/source/js/lazyload.min.js","path":"js/lazyload.min.js","modified":0,"renderable":1},{"_id":"themes/ocean/source/js/ocean.js","path":"js/ocean.js","modified":0,"renderable":1},{"_id":"themes/ocean/source/js/pace.min.js","path":"js/pace.min.js","modified":0,"renderable":1},{"_id":"themes/ocean/source/js/search.js","path":"js/search.js","modified":0,"renderable":1},{"_id":"themes/ocean/source/js/prettify.js","path":"js/prettify.js","modified":0,"renderable":1},{"_id":"themes/ocean/source/fancybox/jquery.fancybox.min.js","path":"fancybox/jquery.fancybox.min.js","modified":0,"renderable":1},{"_id":"themes/ocean/source/js/jquery-2.0.3.min.js","path":"js/jquery-2.0.3.min.js","modified":0,"renderable":1},{"_id":"themes/ocean/source/css/feathericon/feathericon.eot","path":"css/feathericon/feathericon.eot","modified":0,"renderable":1},{"_id":"themes/ocean/source/css/feathericon/feathericon.ttf","path":"css/feathericon/feathericon.ttf","modified":0,"renderable":1},{"_id":"themes/ocean/source/css/feathericon/feathericon.woff","path":"css/feathericon/feathericon.woff","modified":0,"renderable":1},{"_id":"themes/ocean/source/css/feathericon/feathericon.woff2","path":"css/feathericon/feathericon.woff2","modified":0,"renderable":1},{"_id":"themes/ocean/source/images/ocean/overlay-hero.png","path":"images/ocean/overlay-hero.png","modified":0,"renderable":1},{"_id":"source/images/IMG_1891.JPG","path":"images/IMG_1891.JPG","modified":0,"renderable":0},{"_id":"source/images/IMG_2148.JPG","path":"images/IMG_2148.JPG","modified":0,"renderable":0},{"_id":"source/images/futako010010.JPG","path":"images/futako010010.JPG","modified":0,"renderable":0},{"_id":"themes/ocean/source/css/feathericon/feathericon.svg","path":"css/feathericon/feathericon.svg","modified":0,"renderable":1},{"_id":"source/images/IMG_0874.JPG","path":"images/IMG_0874.JPG","modified":0,"renderable":0},{"_id":"source/images/IMG_4200.JPG","path":"images/IMG_4200.JPG","modified":0,"renderable":0},{"_id":"themes/ocean/source/images/forrestgump.png","path":"images/forrestgump.png","modified":0,"renderable":1},{"_id":"source/images/IMG_0444.JPG","path":"images/IMG_0444.JPG","modified":0,"renderable":0},{"_id":"source/images/IMG_4201.JPG","path":"images/IMG_4201.JPG","modified":0,"renderable":0},{"_id":"source/images/IMG_0875.JPG","path":"images/IMG_0875.JPG","modified":0,"renderable":0},{"_id":"source/images/IMG_1333.JPG","path":"images/IMG_1333.JPG","modified":0,"renderable":0},{"_id":"source/images/IMG_0226.JPG","path":"images/IMG_0226.JPG","modified":0,"renderable":0},{"_id":"source/images/IMG_0518.JPG","path":"images/IMG_0518.JPG","modified":0,"renderable":0},{"_id":"source/images/IMG_2194.JPG","path":"images/IMG_2194.JPG","modified":0,"renderable":0},{"_id":"source/images/IMG_2221.JPG","path":"images/IMG_2221.JPG","modified":0,"renderable":0},{"_id":"source/images/IMG_0637.JPG","path":"images/IMG_0637.JPG","modified":0,"renderable":0},{"_id":"source/images/IMG_2151.JPG","path":"images/IMG_2151.JPG","modified":0,"renderable":0},{"_id":"source/images/IMG_0222.JPG","path":"images/IMG_0222.JPG","modified":0,"renderable":0},{"_id":"source/images/IMG_2192.JPG","path":"images/IMG_2192.JPG","modified":0,"renderable":0},{"_id":"themes/ocean/source/images/ocean/ocean.ogv","path":"images/ocean/ocean.ogv","modified":0,"renderable":1},{"_id":"source/images/IMG_0873.JPG","path":"images/IMG_0873.JPG","modified":0,"renderable":0},{"_id":"source/images/IMG_2209.JPG","path":"images/IMG_2209.JPG","modified":0,"renderable":0},{"_id":"source/images/IMG_1331.JPG","path":"images/IMG_1331.JPG","modified":0,"renderable":0},{"_id":"source/images/futako010029.JPG","path":"images/futako010029.JPG","modified":0,"renderable":0},{"_id":"source/images/IMG_2195.JPG","path":"images/IMG_2195.JPG","modified":0,"renderable":0},{"_id":"source/images/IMG_0077.JPG","path":"images/IMG_0077.JPG","modified":0,"renderable":0},{"_id":"source/images/IMG_0605.JPG","path":"images/IMG_0605.JPG","modified":0,"renderable":0},{"_id":"source/images/futako010013.JPG","path":"images/futako010013.JPG","modified":0,"renderable":0},{"_id":"source/images/IMG_2200.JPG","path":"images/IMG_2200.JPG","modified":0,"renderable":0},{"_id":"source/images/IMG_0519.JPG","path":"images/IMG_0519.JPG","modified":0,"renderable":0},{"_id":"source/images/futako010041.JPG","path":"images/futako010041.JPG","modified":0,"renderable":0},{"_id":"themes/ocean/source/images/ocean/ocean.png","path":"images/ocean/ocean.png","modified":0,"renderable":1},{"_id":"themes/ocean/source/images/ocean/ocean.webm","path":"images/ocean/ocean.webm","modified":0,"renderable":1},{"_id":"themes/ocean/source/images/ocean/ocean.mp4","path":"images/ocean/ocean.mp4","modified":0,"renderable":1},{"_id":"source/images/GoSlice.JPG","path":"images/GoSlice.JPG","modified":0,"renderable":0}],"Cache":[{"_id":"source/.DS_Store","hash":"15f017f93da154ec6ff1c2fe8a64b1bc129083df","modified":1557649441932},{"_id":"themes/ocean/README.md","hash":"0a5f44c3b9f6757ffdb3576f57afa53f203ea985","modified":1556351608519},{"_id":"themes/ocean/_config.yml","hash":"47b265d984ab07f28744025ce97efda24a257675","modified":1556620349317},{"_id":"themes/ocean/.DS_Store","hash":"dd0586a49b712829ce1e0c97a7b19a1232e0d1a3","modified":1557473998810},{"_id":"themes/ocean/package.json","hash":"b993176f8c35bc3ab9dbd8642ec6cd125fcb447e","modified":1556351608530},{"_id":"source/_posts/A-Brief-Introduce-to-Redux-Saga.md","hash":"6ba6a634260e80626ac3b2726325097a955e7e51","modified":1557482512394},{"_id":"source/_posts/How-to-Check-Open-TCP-IP-Ports-in-Mac-OS-X.md","hash":"9b68262d9aba32708433448fca14ed6298d6e978","modified":1557478812697},{"_id":"source/_posts/How-to-debug-NodeJS-on-VS-Code.md","hash":"a8c08f053ae7192c55b1fdb50ec4b1ebe70601ac","modified":1557481978626},{"_id":"source/_posts/Memory-Leak-in-Serveral-Commonly-Used-Programming-Languages.md","hash":"532b9dfe4d56b5c88ae8a3742ff524091145e46b","modified":1557483219539},{"_id":"source/_posts/Prefix-Notation.md","hash":"39925b12b50b0bd5aaf05fa8a4cd29577ef0fc84","modified":1557477976855},{"_id":"source/_posts/Type-slice-in-Golang.md","hash":"643f703b7898cd1a1b45f8d2d53510202162897f","modified":1557649548418},{"_id":"source/_posts/hello-world.md","hash":"b28643c0f92783a2204f2bffd1031a6ecae5b0d2","modified":1556522293367},{"_id":"source/about/index.md","hash":"d91209004b506f3aa81f86f94a6482e1138aaeac","modified":1556364296199},{"_id":"source/gallery/index.md","hash":"81878942167add6fa3ed58c994176e6573a859d8","modified":1556357667537},{"_id":"source/images/.DS_Store","hash":"d144c4ebaa2edb901642095d308fb14694d35727","modified":1557189120846},{"_id":"source/images/cli.JPG","hash":"9dc4dd69083df96b774dee488bb42cfe7dc35922","modified":1557132969055},{"_id":"source/images/Memory-Leaks.JPG","hash":"88744198f42bcd6b31e70e82f798645cb453e2e1","modified":1557038733681},{"_id":"source/images/redux-saga.JPG","hash":"246254876cfd63cdbb5d31523d02d078daecf40e","modified":1556430638342},{"_id":"source/images/treeRecursion.JPG","hash":"a09da0ab4779d513b081eeacff2ec0a80d78576a","modified":1556595372000},{"_id":"source/images/treeRecursion11.JPG","hash":"b3cb61f46ddff0067dc8ebe5357d21a37aeaecb7","modified":1556619951956},{"_id":"source/images/vscode.JPG","hash":"7d97031e400f3b8ad192de733d9711f52a7f80ad","modified":1557390022434},{"_id":"themes/ocean/languages/de.yml","hash":"3ebf0775abbee928c8d7bda943c191d166ded0d3","modified":1556351608519},{"_id":"themes/ocean/languages/default.yml","hash":"3083f319b352d21d80fc5e20113ddf27889c9d11","modified":1556351608519},{"_id":"themes/ocean/languages/es.yml","hash":"76edb1171b86532ef12cfd15f5f2c1ac3949f061","modified":1556351608520},{"_id":"themes/ocean/languages/fr.yml","hash":"415e1c580ced8e4ce20b3b0aeedc3610341c76fb","modified":1556351608520},{"_id":"themes/ocean/languages/ja.yml","hash":"a73e1b9c80fd6e930e2628b393bfe3fb716a21a9","modified":1556351608520},{"_id":"themes/ocean/languages/ko.yml","hash":"881d6a0a101706e0452af81c580218e0bfddd9cf","modified":1556351608520},{"_id":"themes/ocean/languages/nl.yml","hash":"12ed59faba1fc4e8cdd1d42ab55ef518dde8039c","modified":1556351608520},{"_id":"themes/ocean/languages/no.yml","hash":"965a171e70347215ec726952e63f5b47930931ef","modified":1556351608521},{"_id":"themes/ocean/languages/pt.yml","hash":"57d07b75d434fbfc33b0ddb543021cb5f53318a8","modified":1556351608521},{"_id":"themes/ocean/languages/ru.yml","hash":"4fda301bbd8b39f2c714e2c934eccc4b27c0a2b0","modified":1556351608521},{"_id":"themes/ocean/languages/zh-CN.yml","hash":"ca40697097ab0b3672a80b455d3f4081292d1eed","modified":1556351608521},{"_id":"themes/ocean/languages/zh-TW.yml","hash":"53ce3000c5f767759c7d2c4efcaa9049788599c3","modified":1556351608521},{"_id":"themes/ocean/layout/.DS_Store","hash":"acf7fef488db0d4e3170f1ce64478a72a6dd681a","modified":1556362284452},{"_id":"themes/ocean/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1556351608528},{"_id":"themes/ocean/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1556351608528},{"_id":"themes/ocean/layout/index.ejs","hash":"dead30ea8014348cef977dcb44eea0ae0f0601c5","modified":1556351608529},{"_id":"themes/ocean/layout/layout.ejs","hash":"9ce598d82d973518e255fe64019b8523a2d65796","modified":1556351608529},{"_id":"themes/ocean/layout/page.ejs","hash":"a9a48ae63f5d68a36382951166fdd6e482b901f1","modified":1556351608529},{"_id":"themes/ocean/layout/post.ejs","hash":"a9a48ae63f5d68a36382951166fdd6e482b901f1","modified":1556351608530},{"_id":"themes/ocean/layout/tag.ejs","hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1556351608530},{"_id":"themes/ocean/source/.DS_Store","hash":"31e61c090aa46ea0c4d227808d995d0ef4d0ce46","modified":1557473998808},{"_id":"themes/ocean/source/404.html","hash":"fe1497ac9b2d47f4e3e880946e22fbfe3db7496e","modified":1556351608533},{"_id":"themes/ocean/source/favicon.ico","hash":"0f20298a6a4d1ebd7a7ae7b87d7a3ae9afec0623","modified":1556351608546},{"_id":"source/images/lisp.JPG","hash":"5f09d56757170819589f35eed3cb8397dea6c222","modified":1556618649935},{"_id":"source/images/IMG_0504.JPG","hash":"bdd3c4dcc7e813685793a2226728b0c60fb653b9","modified":1556355556624},{"_id":"source/images/IMG_0606.JPG","hash":"1aa6473addf50803fef60b42e90cdb2d71113db8","modified":1556355554985},{"_id":"themes/ocean/layout/_partial/after-footer.ejs","hash":"f34ea37e96ce18a24e00e6f5ffdaf94b999a589a","modified":1557474490123},{"_id":"themes/ocean/layout/_partial/archive-post.ejs","hash":"8f46a5a73c95827d812ca3e90ebb0ad8f16fb7b2","modified":1556351608522},{"_id":"themes/ocean/layout/_partial/archive.ejs","hash":"6c6cf7d1acb6548396183ce4836f1f9a3a1a4d10","modified":1556351608523},{"_id":"themes/ocean/layout/_partial/article.ejs","hash":"875408862fa6048e08fe04cfb1864af2ae4ef81a","modified":1556619274055},{"_id":"themes/ocean/layout/_partial/footer.ejs","hash":"259129dfc8a952f81be494751982dc3d2c763037","modified":1556360249353},{"_id":"themes/ocean/layout/_partial/head.ejs","hash":"b8174a6094f859ce82e8af2f1b30e1ce03fd0eb2","modified":1556351608524},{"_id":"themes/ocean/layout/_partial/ocean.ejs","hash":"be76e0cbc4ecd9171972fabed6830cb592b5b343","modified":1556351608524},{"_id":"themes/ocean/layout/_partial/sidebar.ejs","hash":"6e5fadba43415d4605593674591cce822b6fb8bf","modified":1556351608528},{"_id":"themes/ocean/layout/_partial/totop.ejs","hash":"70176e319a1558c8b61abecfedbbc08b258e7beb","modified":1556351608528},{"_id":"themes/ocean/source/css/404.styl","hash":"25bf5e29c00d57f90f30673912e13478e47db69c","modified":1556514756850},{"_id":"themes/ocean/source/css/_extend.styl","hash":"1fb5b31668579d177b340e03a78136bc04e22a36","modified":1556513611196},{"_id":"themes/ocean/source/css/_feathericon.styl","hash":"8494f0e869411781264868f08eda62fd838e0cee","modified":1556351608534},{"_id":"themes/ocean/source/css/_mixins.styl","hash":"fbe77673e6f8c714a90daabba6c94cf491650887","modified":1556351608535},{"_id":"themes/ocean/source/css/_normalize.styl","hash":"b3337320133b7a336db7033aa6bbe94b054c0b21","modified":1556351608535},{"_id":"themes/ocean/source/css/.DS_Store","hash":"f4924987f89647cf5bd58a0bbddf33ed3e4d6c3f","modified":1557473993133},{"_id":"themes/ocean/source/css/_variables.styl","hash":"a91de5d66d44a31b7ea7b2e918e47f9d7c662434","modified":1556514844779},{"_id":"themes/ocean/source/css/style.styl","hash":"c16117215595ef87c0e88bbb2bcd7b0d1f02290c","modified":1557641211730},{"_id":"themes/ocean/source/fancybox/jquery.fancybox.min.css","hash":"2e6a66987dbc7a57bbfd2655bce166739b4ba426","modified":1556351608545},{"_id":"themes/ocean/source/css/tranquilheart.css","hash":"9c669545e3517de77f5cff50a58e4ef035855c87","modified":1557474779374},{"_id":"themes/ocean/screenshots/hexo-theme-ocean.jpg","hash":"13b5045d2120cac2f68849757f5e0af08938b7c6","modified":1556351608532},{"_id":"themes/ocean/source/images/hexo-inverted.svg","hash":"525309ea3c7360f83d1d9df6d04c256d7171950d","modified":1556351608548},{"_id":"themes/ocean/source/images/.DS_Store","hash":"758d8ae8486197e8ad1b0dc53b5b7ce7ad19c6db","modified":1556701955107},{"_id":"themes/ocean/source/images/hexo.svg","hash":"71e7204d04ccfe260f06ea5873484791cd5f404a","modified":1556351608549},{"_id":"themes/ocean/source/images/searchfooter.png","hash":"519b76e799d2a45a456c3a90fb1308cdb011b352","modified":1556683156662},{"_id":"themes/ocean/source/js/busuanzi-2.3.pure.min.js","hash":"6e41f31100ae7eb3a6f23f2c168f6dd56e7f7a9a","modified":1556351608607},{"_id":"themes/ocean/source/js/lazyload.min.js","hash":"b801b3946fb9b72e03512c0663458e140e1fa77b","modified":1556351608608},{"_id":"themes/ocean/source/js/ocean.js","hash":"3457be62843930ad58997cd6fd387783285242c7","modified":1556351608609},{"_id":"themes/ocean/source/js/pace.min.js","hash":"d32ab818e0f97d3b0c80f5631fc23d8a0cb52795","modified":1556351608609},{"_id":"themes/ocean/source/js/search.js","hash":"88fa5c780f9093f70d6e3066cca0d6165a8364b4","modified":1556683974980},{"_id":"themes/ocean/source/js/prettify.js","hash":"66f5fafc7321fcb0864a8dc680b32cb1d40ac57b","modified":1362427944000},{"_id":"themes/ocean/source/css/_partial/comment.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1556351608536},{"_id":"themes/ocean/source/fancybox/jquery.fancybox.min.js","hash":"b2b093d8f5ffeee250c8d0d3a2285a213318e4ea","modified":1556351608546},{"_id":"themes/ocean/source/js/jquery-2.0.3.min.js","hash":"800edb7787c30f4982bf38f2cb8f4f6fb61340e9","modified":1556351608608},{"_id":"themes/ocean/layout/_partial/post/albums.ejs","hash":"dcfea9a328f5e1d90758ac71d7d7555b31b93bcb","modified":1556351608525},{"_id":"themes/ocean/layout/_partial/post/busuanzi.ejs","hash":"88462d160479cc3f0cc58efcd888fbaf22b0d4d8","modified":1556351608525},{"_id":"themes/ocean/layout/_partial/post/category.ejs","hash":"85f0ebeceee1c32623bfa1e4170dbe1e34442fea","modified":1556351608525},{"_id":"themes/ocean/layout/_partial/post/date.ejs","hash":"6197802873157656e3077c5099a7dda3d3b01c29","modified":1556351608526},{"_id":"themes/ocean/layout/_partial/post/gallery.ejs","hash":"5f8487fe7bed9a09001c6655244ff35f583cf1eb","modified":1556351608526},{"_id":"themes/ocean/layout/_partial/post/gitalk.ejs","hash":"e36d149ad83c3a52562dbef61a0083957eb24578","modified":1556351608526},{"_id":"themes/ocean/layout/_partial/post/nav.ejs","hash":"e59198918e92ef92156aeefbf6023584ac1cae64","modified":1556351608527},{"_id":"themes/ocean/layout/_partial/post/search.ejs","hash":"2c9d19d1685e834aa2020998da2a2d259ce9b9ff","modified":1556351608527},{"_id":"themes/ocean/layout/_partial/post/tag.ejs","hash":"2fcb0bf9c8847a644167a27824c9bb19ac74dd14","modified":1556351608527},{"_id":"themes/ocean/layout/_partial/post/title.ejs","hash":"f8c9cb35d8d1975aa3b457d9a92f38c462e97732","modified":1556351608527},{"_id":"themes/ocean/source/css/_partial/.DS_Store","hash":"7e82340cd372744d424f18f0b7b25c3c2d9f21fe","modified":1557473001675},{"_id":"themes/ocean/source/css/_partial/albums.styl","hash":"0659d5f7469f24a415354ff767d949926465d515","modified":1556351608535},{"_id":"themes/ocean/source/css/_partial/archive.styl","hash":"8aefdcf2d542ad839018c2c58511e3318a38490d","modified":1556351608536},{"_id":"themes/ocean/source/css/_partial/article.styl","hash":"93905de0339f3e831a383739bdc477c29c1914c4","modified":1556351608536},{"_id":"themes/ocean/source/css/_partial/articles.styl","hash":"7bf289013d304505984b251be725b49165a694fd","modified":1556351608536},{"_id":"themes/ocean/source/css/_partial/float.styl","hash":"d888df89a172e4c8119cb8740fc1eae1a9539157","modified":1556351608537},{"_id":"themes/ocean/source/css/_partial/footer.styl","hash":"24779cbce1012d4f35ffc6b3ec0830cbc2ea3b3f","modified":1556351608537},{"_id":"themes/ocean/source/css/_partial/gallery.styl","hash":"7bdc2c9fb4971dbd7511c5cbb69bd611f20db591","modified":1556351608537},{"_id":"themes/ocean/source/css/_partial/gitalk.styl","hash":"3706eef2e0541493f1679a30241d279e29dfdc17","modified":1556351608537},{"_id":"themes/ocean/source/css/_partial/layou.styl","hash":"47a8a98aaaf7db4d2d89b8c41b43394d1cc92849","modified":1556351608538},{"_id":"themes/ocean/source/css/_partial/lists.styl","hash":"087f08e0ce9aca48e096dabca6eed2368b5bcd6b","modified":1556351608538},{"_id":"themes/ocean/source/css/_partial/mobile.styl","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1556351608539},{"_id":"themes/ocean/source/css/_partial/navbar.styl","hash":"fb32443da45975567ebae8683c18f0cda0aa0a3d","modified":1556351608539},{"_id":"themes/ocean/source/css/_partial/ocean.styl","hash":"6c68a00bcd69853711db48f5fdd02544d8a6152e","modified":1556351608539},{"_id":"themes/ocean/source/css/_partial/pace.styl","hash":"e326918ba276ee332d0598d8193ccd8353e7d916","modified":1556351608540},{"_id":"themes/ocean/source/css/_partial/prettify.css","hash":"d920b34adf4458bfc13937cbd083f4ca04341e8a","modified":1362427944000},{"_id":"themes/ocean/source/css/_partial/highlight.styl","hash":"c6e99fd23056fb01177aeefbc5dd4a8e88cf8f81","modified":1556351608538},{"_id":"themes/ocean/source/css/_partial/search.styl","hash":"a81fe253dae61b114d9cdb15673d1588aae35285","modified":1556513307655},{"_id":"themes/ocean/source/css/_partial/sidebar.styl","hash":"600c70f1de82da5223af290d47a583f9c379d188","modified":1556351608540},{"_id":"themes/ocean/source/css/_partial/totop.styl","hash":"69fcb0c9adb45f592838c3babc58d3490f413db2","modified":1556351608541},{"_id":"themes/ocean/source/css/feathericon/feathericon.eot","hash":"e2a01ae6f849841bc7a9fd21e5b7b450f1ded19b","modified":1556351608542},{"_id":"themes/ocean/source/css/feathericon/feathericon.ttf","hash":"d0d80c3c960d7d45e6bd7fa428d8a6a8c8245b2d","modified":1556351608543},{"_id":"themes/ocean/source/css/feathericon/feathericon.woff","hash":"d22fe861e47afd92969ab46c7cbb7ea9c225aaf8","modified":1556351608544},{"_id":"themes/ocean/source/css/feathericon/feathericon.woff2","hash":"2c11c45331d914ee38ad42ccf966132a508b5596","modified":1556351608544},{"_id":"themes/ocean/source/images/ocean/overlay-hero.png","hash":"92481a1848c35be96a693af11f77265323a7c189","modified":1556351608606},{"_id":"source/images/IMG_1891.JPG","hash":"676dcaf369929ef6b3d9ec8e8f7cf088c8ecdae4","modified":1556357445197},{"_id":"source/images/IMG_2148.JPG","hash":"9f08338b4842b7853a7132a098c0d2440afc8fd8","modified":1556356922750},{"_id":"source/images/futako010010.JPG","hash":"6f13fba723f69932261d8db10e2af818aa52dac4","modified":1556356904280},{"_id":"themes/ocean/source/css/feathericon/feathericon.svg","hash":"c113006c6822451802c8457128c352c0e4934453","modified":1556351608543},{"_id":"source/images/IMG_0874.JPG","hash":"09ef9b6fe4b1f11b2adc52865f98a66f79bdbe58","modified":1556357450715},{"_id":"source/images/IMG_4200.JPG","hash":"b66b09b2026648ca9bff1b9d7f3adbbe0f5a0413","modified":1556357449003},{"_id":"themes/ocean/source/images/forrestgump.png","hash":"18ad6a8ba815878e36a0d5562136dc4fb8920c12","modified":1556351608548},{"_id":"source/images/IMG_0444.JPG","hash":"a07f11160a4ff6ebfdbc4faf25868ea8c3f18b71","modified":1556356906367},{"_id":"source/images/IMG_4201.JPG","hash":"df6d4734798dbbe1b22e82864ab38739fecce8d3","modified":1556357442956},{"_id":"source/images/IMG_0875.JPG","hash":"de4c08db2a5751996b99fbc8dfded7c53da935f9","modified":1556357449935},{"_id":"source/images/IMG_1333.JPG","hash":"176423f03fdb3bf5e56643027cf01005a5eb2a74","modified":1556357447915},{"_id":"source/images/IMG_0226.JPG","hash":"08238c849695d9214b2f5b8d807a9f5c22d805cd","modified":1556356907611},{"_id":"source/images/IMG_0518.JPG","hash":"cdf83313366ef6bfedc05f8127d08e4897de5154","modified":1556355555852},{"_id":"source/images/IMG_2194.JPG","hash":"cb802e60eb35ea0e5135c786cef1608b1f32f1c0","modified":1556356920498},{"_id":"source/images/IMG_2221.JPG","hash":"707dfcc82b32818ff8b1d12840a863bca517cd16","modified":1556356919011},{"_id":"source/images/IMG_0637.JPG","hash":"bd5f1d97a0be08a89769b01429a35465e0fc85d7","modified":1556355551809},{"_id":"source/images/IMG_2151.JPG","hash":"a22eccebcc934cb9ce8e4038fee0d39d0469f1a2","modified":1556357444520},{"_id":"source/images/IMG_0222.JPG","hash":"8424385dc15a5f8069190386292cce0fbfdc086f","modified":1556356908641},{"_id":"source/images/IMG_2192.JPG","hash":"e725c4037834f60d40b777244edbeb6de337ad9a","modified":1556356911364},{"_id":"themes/ocean/source/images/ocean/ocean.ogv","hash":"9c6b5d6b0544472cee39f5eafac2d5cbba5fd86b","modified":1556351608579},{"_id":"source/images/IMG_0873.JPG","hash":"e4754500a08ed9a78e9154e67c67eb61daa9d3ab","modified":1556357452650},{"_id":"source/images/IMG_2209.JPG","hash":"0045c460208e70189907588d74542e7dd7a9537b","modified":1556356917888},{"_id":"source/images/IMG_1331.JPG","hash":"1274e2476d4aaa0b24eb6330cdf87e238595c0f2","modified":1556357446640},{"_id":"source/images/futako010029.JPG","hash":"8438933ed62e1cf5b2db488140fb3d93d6bae0f5","modified":1556356902207},{"_id":"source/images/IMG_2195.JPG","hash":"dbf948d502538248eef8e73df5418530b8cc891c","modified":1556356912377},{"_id":"source/images/IMG_0077.JPG","hash":"33b8f580dd1c24eaf7e2c2ed42958638637da02a","modified":1556356909567},{"_id":"source/images/IMG_0605.JPG","hash":"fe5cfd86c45ddba8ac06c7834deb3acb0ca21ba0","modified":1556355554106},{"_id":"source/images/futako010013.JPG","hash":"d2bc5d03172a0664ae145288257d1dac48047cb5","modified":1556356901206},{"_id":"source/images/IMG_2200.JPG","hash":"6741848ea3e666881f9dc9a31efa817207a7a1c2","modified":1556356921703},{"_id":"source/images/IMG_0519.JPG","hash":"af2e9071c8f319b00bf4a84ff6b78e2d413c46b6","modified":1556355557862},{"_id":"source/images/futako010041.JPG","hash":"06474d6fa82c7e0183f90fb6a1660280a87f2d89","modified":1556356903293},{"_id":"themes/ocean/source/images/ocean/ocean.png","hash":"8245d07f812625d19b48ad2d00f8191f2aa4d304","modified":1556351608586},{"_id":"themes/ocean/source/images/ocean/ocean.webm","hash":"65aa2b6483e0151611899e31571057334c60d9e4","modified":1556351608604},{"_id":"themes/ocean/source/images/ocean/ocean.mp4","hash":"1e89cac2d652005d9dafd3ecb4dd460a8ff6d6af","modified":1556351608572},{"_id":"source/images/GoSlice.JPG","hash":"920bdae1c37b54a35358ce3ed70ab278b8b96a7c","modified":1557649400006}],"Category":[],"Data":[],"Page":[{"title":"About Me","date":"2019-04-27T11:24:18.000Z","_content":"","source":"about/index.md","raw":"---\ntitle: About Me\ndate: 2019-04-27 20:24:18\n---\n","updated":"2019-04-27T11:24:56.199Z","path":"about/index.html","comments":1,"layout":"page","_id":"cjvkl7rrq0001seaounqac665","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"My Gallery","date":"2019-04-27T08:49:44.000Z","albums":[["../images/IMG_0504.JPG","Nikko, JP"],["../images/IMG_0518.JPG","Meguro, JP"],["../images/IMG_0519.JPG","Meguro, JP"],["../images/IMG_0605.JPG","Kyoto Yasaka Shrine, JP"],["../images/IMG_0606.JPG","Kyoto Kiyomizu, JP"],["../images/IMG_0637.JPG","Odaiba, JP"],["../images/futako010010.JPG","Futakotawagama, JP"],["../images/futako010013.JPG","Futakotawagama, JP"],["../images/futako010029.JPG","Futakotawagama, JP"],["../images/futako010041.JPG","Futakotawagama, JP"],["../images/IMG_0077.JPG","Kamakura, JP"],["../images/IMG_0222.JPG","Roppongi Hills, JP"],["../images/IMG_0226.JPG","Roppongi Hills, JP"],["../images/IMG_0444.JPG","Nara, JP"],["../images/IMG_2148.JPG","Niagara Falls, CA"],["../images/IMG_2192.JPG","Banff National Parks, CA"],["../images/IMG_2194.JPG","Banff National Parks, CA"],["../images/IMG_2195.JPG","Banff National Parks, CA"],["../images/IMG_2200.JPG","Banff National Parks, CA"],["../images/IMG_2209.JPG","Banff Town, CA"],["../images/IMG_2221.JPG","Banff, Lake Louis, CA"],["../images/IMG_4200.JPG","Waterloo, CA"],["../images/IMG_4201.JPG","Niagara Falls, CA"],["../images/IMG_1331.JPG","Waterloo, CA"],["../images/IMG_1333.JPG","Waterloo, CA"],["../images/IMG_2151.JPG","Niagara Falls, CA"],["../images/IMG_1891.JPG","Montreal, CA"],["../images/IMG_0873.JPG","Dali, CN"],["../images/IMG_0874.JPG","Dali, CN"],["../images/IMG_0875.JPG","Dali, CN"]],"_content":"","source":"gallery/index.md","raw":"---\ntitle: My Gallery\ndate: 2019-04-27 17:49:44\nalbums: [\n    [\"../images/IMG_0504.JPG\", \"Nikko, JP\"],\n    [\"../images/IMG_0518.JPG\", \"Meguro, JP\"],\n    [\"../images/IMG_0519.JPG\", \"Meguro, JP\"],\n    [\"../images/IMG_0605.JPG\", \"Kyoto Yasaka Shrine, JP\"],\n    [\"../images/IMG_0606.JPG\", \"Kyoto Kiyomizu, JP\"],\n    [\"../images/IMG_0637.JPG\", \"Odaiba, JP\"],\n    [\"../images/futako010010.JPG\", \"Futakotawagama, JP\"],\n    [\"../images/futako010013.JPG\", \"Futakotawagama, JP\"],\n    [\"../images/futako010029.JPG\", \"Futakotawagama, JP\"],\n    [\"../images/futako010041.JPG\", \"Futakotawagama, JP\"],\n    [\"../images/IMG_0077.JPG\", \"Kamakura, JP\"],\n    [\"../images/IMG_0222.JPG\", \"Roppongi Hills, JP\"],\n    [\"../images/IMG_0226.JPG\", \"Roppongi Hills, JP\"],\n    [\"../images/IMG_0444.JPG\", \"Nara, JP\"],\n    [\"../images/IMG_2148.JPG\", \"Niagara Falls, CA\"],\n    [\"../images/IMG_2192.JPG\", \"Banff National Parks, CA\"],\n    [\"../images/IMG_2194.JPG\", \"Banff National Parks, CA\"],\n    [\"../images/IMG_2195.JPG\", \"Banff National Parks, CA\"],\n    [\"../images/IMG_2200.JPG\", \"Banff National Parks, CA\"],\n    [\"../images/IMG_2209.JPG\", \"Banff Town, CA\"],\n    [\"../images/IMG_2221.JPG\", \"Banff, Lake Louis, CA\"],\n    [\"../images/IMG_4200.JPG\", \"Waterloo, CA\"],\n    [\"../images/IMG_4201.JPG\", \"Niagara Falls, CA\"],\n    [\"../images/IMG_1331.JPG\", \"Waterloo, CA\"],\n    [\"../images/IMG_1333.JPG\", \"Waterloo, CA\"],\n    [\"../images/IMG_2151.JPG\", \"Niagara Falls, CA\"],\n    [\"../images/IMG_1891.JPG\", \"Montreal, CA\"],\n    [\"../images/IMG_0873.JPG\", \"Dali, CN\"],\n    [\"../images/IMG_0874.JPG\", \"Dali, CN\"],\n    [\"../images/IMG_0875.JPG\", \"Dali, CN\"]\n]\n---\n","updated":"2019-04-27T09:34:27.537Z","path":"gallery/index.html","comments":1,"layout":"page","_id":"cjvkl7rrt0003seaofjig4he9","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"A Brief Introduce to Redux Saga","date":"2019-04-28T05:35:50.000Z","photos":["../images/redux-saga.JPG"],"_content":"If you are quite experienced with redux, which is a predictable state container for JavaScript applications (**Note:** even thouth React and Redux is a popular combination to build fast and powerful apps, Redux is not necessarily combined with React), you are definitely feeling comfortable with its powerful store which manages all the global states and provides much cleaner logic flows to change them. If you are new to redux, [here](https://redux.js.org/introduction/getting-started) is the guide to dive before we start our topic.<!-- more -->\n\nIn a complex javascript application, asynchronous function is always one of the most annoying part where encounters tons of bugs. If not handle them properly, the app usually ends up with ***call back hell***.\n</br>\n\n## **Haven't heard of *CallBack Hell*?**\nWell, in javascript, the only way you can suspend a computation and have the rest operations doing later is to put the rest operations into a callback function. This callback function usually returns a **`Promise`** (And has a type of **`Promise<any>`**). In order to easily mark those async functions, after ***ES6*** javascript provides extra modifiers **`async`** and **`await`**, which actually wraps up the original utilities of promise and makes it more readable to programmers. Hummm, sounds like things are going better... ~~**NO!! It doesn't resolve anything!**~~ The core problem leads to a callback hell is the hierarchical async calls, for example\n\nyou have some simple synchronous functions which are in a chain to accomplish some logics:\n```javascript\na = getSomething();\nb = getMore(a);\nc = getMoreAndMore(b);\n...\n```\nIt looks fine for now, but what if they all turn out to be async? Then you have to follow the callback style to make them operate one right after another is done:\n```javascript\ngetSomthing(function(a) {\n    getMore(a, function(b) {\n        getMoreAndMore(b, function(c) {\n            //keep going...\n        });\n    });\n});\n```\nOr you prefer ***ES6***:\n```javascript\nasync function getSomething(a) {\n    await b = ToDo(a);\n    return await getMore((b) => {\n        return await ToDo(b);\n    }).then((c) => {\n        return await ToDo(c);\n    }).then(...);\n}\n```\nLooks really confused? This will getting even uglier if we are using callbacks in loops. \n</br>\n## Redux Thunks\nBack to our redux app, we usually want to update some states after an async call to inform the UI that the data is ready to be fetched. That is always achieved by dispatching an action from the component to the reducer:\n```javascript\nasync const callAPI = () => {\n    ...\n    return response;\n};\n...\nasync const updateUI = (...params) => {\n    const res = await callAPI();\n    if (res.status === 200)\n        dispatch({type: \"UPDATE\", isSuccess: true});\n};\n...\nrender({\n    ...\n    this.props.isSuccess?\n        showData() : showError()\n});\n```\nThis isn't bad, but we are always looking for something better. An advanced way to rewrite it is using redux middleware. ***Middleware*** is somewhere you can put the code after the framework receives a request and before it generates a response. For example, we want to add a logger in the redux store so that when the store catches an action, before it returns the new state, the logger can log the previous state and the new generated state. This is what can be added as a middleware:\n```javascript\nfunction logger(store) {\n    return function wrapDispatch (next) {\n        return function dispatchAndLog (action) {\n            console.log(\"dispatching.. \", action);\n            let result = next(action);\n            console.log(\"new state\", store.getState());\n            return result;\n        }\n    }\n}\n```\nThere are more advanced ways to add a logger. If you are interested, please refer to the [offical documentation](https://redux.js.org/advanced/middleware). With our middleware, the previous example can be written in a cleaner way:\n```javascript\nconst callAPI = () => {\n    return((dispatch) => {\n        dispatch(startCallingApiAction);\n        actualCallApi().then(data => {\n            dispatch(successAction(data));\n        }).fail(err => {\n            dispatch(failedAction(err));\n        });\n    });\n};\n```\nThe successful response data is wrapped in the payload of the action, sent to the reducer. Once the store updates the data, it will be mapped as a prop back to the component and request for a rerender. This middleware is also called ***thunk***. By applying thunk to decouple the presentation layer, we can get rid of most of the side effects in components, instead, managing and orchestrating side effects in thunks.\n\nThis is great, so why are we even considering ***saga***? Well, one of the advantages of middleware is that it can be chained. Every middleware mounted in redux store starts an individual thread (or something really looks like a thread in ***NodeJS***). When a middleware captures an action and handles its side effect, it can dispatch a new action to another middleware to do nested logics. This behavior of middleware indicates that thunks can be chained as well, for example thunkA forwards its return payload to thunkB and thunkB forwards its return payload to... **Wait! That sounds quite familiar!! Is that the case of callback hell??** Unfortunately, a good thing plus another good feature doesn't always end up with something better. ~~It could be some shit as well (笑)~~ In this case, true, this is exactly the callback hell.\n</br>\n\n## Redux Saga\nTo handle the possible endless callback functions and also to make it more easily to test in a component which has complicated logics, we need to change our previous thoughts. Just like shifting from Process Oriented Programming to Object Oriented Programming, instead of telling the application how to handle the side effects, suppose it already knows how to call a function and how to dispatch an action, all we need to do is to **give instructions about what to do next** and we don't care about how those instructions will be executed (Saga handles the executions).\n\nThen the thunks example can be changed as following:\n```javascript\nexport function* apiSideEffect(action) {\n    try{\n        const data = yield call(actualCallApi);\n        yield put({ type:\"SUCCESS\", payload: data });\n    } catch(err) {\n        yield put({ type:\"FAILED\", payload: err });\n    }\n}\n\nexport function* apiSaga() {\n    yield takeEvery(\"CLICK_TO_CALL_API\", apiSideEffect);\n}\n```\nThere are serval fucntions already being integrated in Saga:\n>**`Call`**: the method call will return only a plain object describing the operation so redux-saga can take care of the invocation and returns the result to the generator. The first parameter is the generator function ready to be called and the rest params are all the arguments in the generator.\n\n>**`Put`**: Instead of dispatching an action inside the generator (Don't ever ever do that), ***put*** Returns an object with instructions for the middleware to dispatch the action.\n\n>**`Select`**: Returns value from the selector function, similar with **`getState()`**. ***Note:*** It is not recommended to use this function because it returns the value corresponding to the contents of the store state tree, which is most likely a plain Javascript object and is **mutable** (Redux wants you to handle state immutably, which means return a new state instead of changing the old one).\n\n>**`Take`**: It creates a command object that tells the middleware to wait for a specific action. The resulting behavior of the call Effect is the same as when the middleware suspends the generator until a ***promise*** resolves. In the take case, it'll suspend the generator until a matching action is dispatched\n\nBy working with Saga, we make the side effects to be ***declarative*** rather than ***imperative***.\n>***Declarative:*** describing what the program must accomplish, rather than describe how to accomplish it\n\n>***Imperative:*** consists of commands for the computer to perform, focuses on describing how a program operates\n\nIn the case of take, the control is inverted. Instead of the actions being pushed to the handler tasks, the **Saga is pulling the action by itself**. An additional generator, known as ***watcher*** which contains ***take*** has to be created to watch a specific action and being triggered once the following action is dispatched in the application. There are two ways to create a watcher, one is using the buid-in functions (***Saga Helper***):\n```javascript\nfunction* watchFetchData() {\n    yield takeEvery(\"FETCH_REQUEST\", callFetchDataApi);\n}\n```\n***takeEvery*** allows multiple request to be proceeding at the same time. Or if you just want the latest request to be fired (the older one will be overrided during each time the watcher is triggered\n```javascript\nfunction* watchFetchData() {\n    yield takeLatest(\"FETCH_REQUEST\", callFetchDataApi);\n}\n```\nHowever by using ***take***, it is possible to fully control an action observation process to build complex control flow:\n```javascript\nfunction* watchFetchData() {\n    while(true) {\n        const action = yield take(\"FETCH_REQUEST\");\n        console.log(action);\n        yield call(callFetchDataApi, action.payload);\n    }\n}\n```\nAll right, now you have been exposed to everything you need to know before start trying redux saga on your own. Here is a short overall example that may also help:\nStore:\n```javascript\nconst sagaMiddleware = createSagaMiddleware();\nconst store = createStore(rootReducer, appluMiddleware(sagaMiddleware));    \nsagaMiddleware.run(watchFetch);\n```\nSagas:\n```javascript\nfunction* watchFetch(): Generator<*, *, *> {\n    yield takeEvery(\"FETCH_ACTION\", callFetchAPI);\n}\n\nfunction* callFetchAPI(): Generator<*, *, *> {\n    try {\n        yield put({ type: \"FETCHING\", payload: ... });\n        const data = yield call(actualCallApi);\n        yield put({ type: \"FETCH_SUCCESS\", payload: data });\n    } catch(err) {\n        yield put({ type: \"FETCH_FAILED\", payload: err });\n    }\n}\n```\nReducer:\n```javascript\nconst reducer = (state = initState, action) => {\n    switch(action) {\n        case \"FETCHING\":\n            return { loading: true, ...state };\n        case \"FETCH_SUCCESS\":\n            return { loading: false, success: true, data: action.payload, ...state };   \n        case \"FETCH_FAILED\":\n            return { loading: false, success: false, error: true, ...state };\n        default:\n            return { ...state };\n    }\n};\n```\nComponent:\n```javascript\nclass myComponent extends React.Component {\n    const mapStateToProps = ...\n    const mapDispatchToProps = ...\n    render() {\n        return (\n            <button onClick = { () => this.props.dispatch({type: \"FETCH_ACTION\"}) }/>   \n            {\n                this.props.loading?\n                    <p>Loading..</p> : this.props.error?\n                        <p>Error!</p> : <p>{this.props.data}</p>\n            }\n        );\n    }\n}\nexport default connect(mapStateToProps, mapDispatchToProps)(myComponent);\n\n```\nFor more advanced concepts, there is a well-organized [Saga offical documentation](https://redux-saga.js.org/docs/advanced/) you can refer to if you want to dive deeper.\n</br>\n\n## How to test Saga?\nA function that returns a simple object is easier to test than a function that directly makes an asynchronous call. For redux saga, each time you yield a function call will return a plain javascript object which makes the workflow much easier to test. You don’t need to use the real API, fake it, or mock it, instead just iterating over the generator function, asserting for equality on the values yielded.\n```javascript\ndescribe(\"fetch work flow\", () => {\n    const generator = cloneableGenerator(callFetchAPI)({ type: \"FETCH_ACTION\" });\n    expect(generator.next().value).toEqual(put({ type: \"FETCHING\", payload: ... }));    \n\n    test(\"fetch success\", () => {\n        const clone = generator.clone();\n        expect(clone.next().value).toEqual(put({ type: \"FETCH_SUCCESS\" }));\n        expect(generator.next().done).toEqual(true);\n    });\n});\n```\nIn the above example, we use **`clone()`** to test different control flows and **`next()`** to iterate to the next function ready be yielded. The mock return value can also be injected as an argument of **`next()`**:\n```javascript\nexpect(clone.next(false).value).toEqual( put(fetchFailedAction()) );      \n```\n</br>\n\n## Saga vs Observables\nRedux saga is not the only solution to our apps which may have complex control flows, they are other helpful tools providing different trade-offs which can also resolve the async problems. Here are some good [code snippets](https://hackmd.io/s/H1xLHUQ8e) of saga vs observables that can open your mind :D\n\n</br>\n</br>\n## References:\nhttps://redux-saga.js.org/\nhttps://stackoverflow.com/questions/25098066/what-is-callback-hell-and-how-and-why-rx-solves-it\nhttps://redux.js.org/advanced/middleware\nhttps://pub.dartlang.org/packages/redux_thunk\nhttps://codeburst.io/how-i-test-redux-saga-fcc425cda018\nhttps://engineering.universe.com/what-is-redux-saga-c1252fc2f4d1\nhttps://www.sitepoint.com/redux-without-react-state-management-vanilla-javascript/\nhttps://redux.js.org/introduction/getting-started\nhttps://blog.logrocket.com/understanding-redux-saga-from-action-creators-to-sagas-2587298b5e71\n","source":"_posts/A-Brief-Introduce-to-Redux-Saga.md","raw":"---\ntitle: A Brief Introduce to Redux Saga\ndate: 2019-04-28 14:35:50\ntags: [Redux, Saga, React]\nphotos: [\"../images/redux-saga.JPG\"]\n---\nIf you are quite experienced with redux, which is a predictable state container for JavaScript applications (**Note:** even thouth React and Redux is a popular combination to build fast and powerful apps, Redux is not necessarily combined with React), you are definitely feeling comfortable with its powerful store which manages all the global states and provides much cleaner logic flows to change them. If you are new to redux, [here](https://redux.js.org/introduction/getting-started) is the guide to dive before we start our topic.<!-- more -->\n\nIn a complex javascript application, asynchronous function is always one of the most annoying part where encounters tons of bugs. If not handle them properly, the app usually ends up with ***call back hell***.\n</br>\n\n## **Haven't heard of *CallBack Hell*?**\nWell, in javascript, the only way you can suspend a computation and have the rest operations doing later is to put the rest operations into a callback function. This callback function usually returns a **`Promise`** (And has a type of **`Promise<any>`**). In order to easily mark those async functions, after ***ES6*** javascript provides extra modifiers **`async`** and **`await`**, which actually wraps up the original utilities of promise and makes it more readable to programmers. Hummm, sounds like things are going better... ~~**NO!! It doesn't resolve anything!**~~ The core problem leads to a callback hell is the hierarchical async calls, for example\n\nyou have some simple synchronous functions which are in a chain to accomplish some logics:\n```javascript\na = getSomething();\nb = getMore(a);\nc = getMoreAndMore(b);\n...\n```\nIt looks fine for now, but what if they all turn out to be async? Then you have to follow the callback style to make them operate one right after another is done:\n```javascript\ngetSomthing(function(a) {\n    getMore(a, function(b) {\n        getMoreAndMore(b, function(c) {\n            //keep going...\n        });\n    });\n});\n```\nOr you prefer ***ES6***:\n```javascript\nasync function getSomething(a) {\n    await b = ToDo(a);\n    return await getMore((b) => {\n        return await ToDo(b);\n    }).then((c) => {\n        return await ToDo(c);\n    }).then(...);\n}\n```\nLooks really confused? This will getting even uglier if we are using callbacks in loops. \n</br>\n## Redux Thunks\nBack to our redux app, we usually want to update some states after an async call to inform the UI that the data is ready to be fetched. That is always achieved by dispatching an action from the component to the reducer:\n```javascript\nasync const callAPI = () => {\n    ...\n    return response;\n};\n...\nasync const updateUI = (...params) => {\n    const res = await callAPI();\n    if (res.status === 200)\n        dispatch({type: \"UPDATE\", isSuccess: true});\n};\n...\nrender({\n    ...\n    this.props.isSuccess?\n        showData() : showError()\n});\n```\nThis isn't bad, but we are always looking for something better. An advanced way to rewrite it is using redux middleware. ***Middleware*** is somewhere you can put the code after the framework receives a request and before it generates a response. For example, we want to add a logger in the redux store so that when the store catches an action, before it returns the new state, the logger can log the previous state and the new generated state. This is what can be added as a middleware:\n```javascript\nfunction logger(store) {\n    return function wrapDispatch (next) {\n        return function dispatchAndLog (action) {\n            console.log(\"dispatching.. \", action);\n            let result = next(action);\n            console.log(\"new state\", store.getState());\n            return result;\n        }\n    }\n}\n```\nThere are more advanced ways to add a logger. If you are interested, please refer to the [offical documentation](https://redux.js.org/advanced/middleware). With our middleware, the previous example can be written in a cleaner way:\n```javascript\nconst callAPI = () => {\n    return((dispatch) => {\n        dispatch(startCallingApiAction);\n        actualCallApi().then(data => {\n            dispatch(successAction(data));\n        }).fail(err => {\n            dispatch(failedAction(err));\n        });\n    });\n};\n```\nThe successful response data is wrapped in the payload of the action, sent to the reducer. Once the store updates the data, it will be mapped as a prop back to the component and request for a rerender. This middleware is also called ***thunk***. By applying thunk to decouple the presentation layer, we can get rid of most of the side effects in components, instead, managing and orchestrating side effects in thunks.\n\nThis is great, so why are we even considering ***saga***? Well, one of the advantages of middleware is that it can be chained. Every middleware mounted in redux store starts an individual thread (or something really looks like a thread in ***NodeJS***). When a middleware captures an action and handles its side effect, it can dispatch a new action to another middleware to do nested logics. This behavior of middleware indicates that thunks can be chained as well, for example thunkA forwards its return payload to thunkB and thunkB forwards its return payload to... **Wait! That sounds quite familiar!! Is that the case of callback hell??** Unfortunately, a good thing plus another good feature doesn't always end up with something better. ~~It could be some shit as well (笑)~~ In this case, true, this is exactly the callback hell.\n</br>\n\n## Redux Saga\nTo handle the possible endless callback functions and also to make it more easily to test in a component which has complicated logics, we need to change our previous thoughts. Just like shifting from Process Oriented Programming to Object Oriented Programming, instead of telling the application how to handle the side effects, suppose it already knows how to call a function and how to dispatch an action, all we need to do is to **give instructions about what to do next** and we don't care about how those instructions will be executed (Saga handles the executions).\n\nThen the thunks example can be changed as following:\n```javascript\nexport function* apiSideEffect(action) {\n    try{\n        const data = yield call(actualCallApi);\n        yield put({ type:\"SUCCESS\", payload: data });\n    } catch(err) {\n        yield put({ type:\"FAILED\", payload: err });\n    }\n}\n\nexport function* apiSaga() {\n    yield takeEvery(\"CLICK_TO_CALL_API\", apiSideEffect);\n}\n```\nThere are serval fucntions already being integrated in Saga:\n>**`Call`**: the method call will return only a plain object describing the operation so redux-saga can take care of the invocation and returns the result to the generator. The first parameter is the generator function ready to be called and the rest params are all the arguments in the generator.\n\n>**`Put`**: Instead of dispatching an action inside the generator (Don't ever ever do that), ***put*** Returns an object with instructions for the middleware to dispatch the action.\n\n>**`Select`**: Returns value from the selector function, similar with **`getState()`**. ***Note:*** It is not recommended to use this function because it returns the value corresponding to the contents of the store state tree, which is most likely a plain Javascript object and is **mutable** (Redux wants you to handle state immutably, which means return a new state instead of changing the old one).\n\n>**`Take`**: It creates a command object that tells the middleware to wait for a specific action. The resulting behavior of the call Effect is the same as when the middleware suspends the generator until a ***promise*** resolves. In the take case, it'll suspend the generator until a matching action is dispatched\n\nBy working with Saga, we make the side effects to be ***declarative*** rather than ***imperative***.\n>***Declarative:*** describing what the program must accomplish, rather than describe how to accomplish it\n\n>***Imperative:*** consists of commands for the computer to perform, focuses on describing how a program operates\n\nIn the case of take, the control is inverted. Instead of the actions being pushed to the handler tasks, the **Saga is pulling the action by itself**. An additional generator, known as ***watcher*** which contains ***take*** has to be created to watch a specific action and being triggered once the following action is dispatched in the application. There are two ways to create a watcher, one is using the buid-in functions (***Saga Helper***):\n```javascript\nfunction* watchFetchData() {\n    yield takeEvery(\"FETCH_REQUEST\", callFetchDataApi);\n}\n```\n***takeEvery*** allows multiple request to be proceeding at the same time. Or if you just want the latest request to be fired (the older one will be overrided during each time the watcher is triggered\n```javascript\nfunction* watchFetchData() {\n    yield takeLatest(\"FETCH_REQUEST\", callFetchDataApi);\n}\n```\nHowever by using ***take***, it is possible to fully control an action observation process to build complex control flow:\n```javascript\nfunction* watchFetchData() {\n    while(true) {\n        const action = yield take(\"FETCH_REQUEST\");\n        console.log(action);\n        yield call(callFetchDataApi, action.payload);\n    }\n}\n```\nAll right, now you have been exposed to everything you need to know before start trying redux saga on your own. Here is a short overall example that may also help:\nStore:\n```javascript\nconst sagaMiddleware = createSagaMiddleware();\nconst store = createStore(rootReducer, appluMiddleware(sagaMiddleware));    \nsagaMiddleware.run(watchFetch);\n```\nSagas:\n```javascript\nfunction* watchFetch(): Generator<*, *, *> {\n    yield takeEvery(\"FETCH_ACTION\", callFetchAPI);\n}\n\nfunction* callFetchAPI(): Generator<*, *, *> {\n    try {\n        yield put({ type: \"FETCHING\", payload: ... });\n        const data = yield call(actualCallApi);\n        yield put({ type: \"FETCH_SUCCESS\", payload: data });\n    } catch(err) {\n        yield put({ type: \"FETCH_FAILED\", payload: err });\n    }\n}\n```\nReducer:\n```javascript\nconst reducer = (state = initState, action) => {\n    switch(action) {\n        case \"FETCHING\":\n            return { loading: true, ...state };\n        case \"FETCH_SUCCESS\":\n            return { loading: false, success: true, data: action.payload, ...state };   \n        case \"FETCH_FAILED\":\n            return { loading: false, success: false, error: true, ...state };\n        default:\n            return { ...state };\n    }\n};\n```\nComponent:\n```javascript\nclass myComponent extends React.Component {\n    const mapStateToProps = ...\n    const mapDispatchToProps = ...\n    render() {\n        return (\n            <button onClick = { () => this.props.dispatch({type: \"FETCH_ACTION\"}) }/>   \n            {\n                this.props.loading?\n                    <p>Loading..</p> : this.props.error?\n                        <p>Error!</p> : <p>{this.props.data}</p>\n            }\n        );\n    }\n}\nexport default connect(mapStateToProps, mapDispatchToProps)(myComponent);\n\n```\nFor more advanced concepts, there is a well-organized [Saga offical documentation](https://redux-saga.js.org/docs/advanced/) you can refer to if you want to dive deeper.\n</br>\n\n## How to test Saga?\nA function that returns a simple object is easier to test than a function that directly makes an asynchronous call. For redux saga, each time you yield a function call will return a plain javascript object which makes the workflow much easier to test. You don’t need to use the real API, fake it, or mock it, instead just iterating over the generator function, asserting for equality on the values yielded.\n```javascript\ndescribe(\"fetch work flow\", () => {\n    const generator = cloneableGenerator(callFetchAPI)({ type: \"FETCH_ACTION\" });\n    expect(generator.next().value).toEqual(put({ type: \"FETCHING\", payload: ... }));    \n\n    test(\"fetch success\", () => {\n        const clone = generator.clone();\n        expect(clone.next().value).toEqual(put({ type: \"FETCH_SUCCESS\" }));\n        expect(generator.next().done).toEqual(true);\n    });\n});\n```\nIn the above example, we use **`clone()`** to test different control flows and **`next()`** to iterate to the next function ready be yielded. The mock return value can also be injected as an argument of **`next()`**:\n```javascript\nexpect(clone.next(false).value).toEqual( put(fetchFailedAction()) );      \n```\n</br>\n\n## Saga vs Observables\nRedux saga is not the only solution to our apps which may have complex control flows, they are other helpful tools providing different trade-offs which can also resolve the async problems. Here are some good [code snippets](https://hackmd.io/s/H1xLHUQ8e) of saga vs observables that can open your mind :D\n\n</br>\n</br>\n## References:\nhttps://redux-saga.js.org/\nhttps://stackoverflow.com/questions/25098066/what-is-callback-hell-and-how-and-why-rx-solves-it\nhttps://redux.js.org/advanced/middleware\nhttps://pub.dartlang.org/packages/redux_thunk\nhttps://codeburst.io/how-i-test-redux-saga-fcc425cda018\nhttps://engineering.universe.com/what-is-redux-saga-c1252fc2f4d1\nhttps://www.sitepoint.com/redux-without-react-state-management-vanilla-javascript/\nhttps://redux.js.org/introduction/getting-started\nhttps://blog.logrocket.com/understanding-redux-saga-from-action-creators-to-sagas-2587298b5e71\n","slug":"A-Brief-Introduce-to-Redux-Saga","published":1,"updated":"2019-05-10T10:01:52.394Z","comments":1,"layout":"post","link":"","_id":"cjvkl7rrn0000seaora5r7s1e","content":"<p>If you are quite experienced with redux, which is a predictable state container for JavaScript applications (<strong>Note:</strong> even thouth React and Redux is a popular combination to build fast and powerful apps, Redux is not necessarily combined with React), you are definitely feeling comfortable with its powerful store which manages all the global states and provides much cleaner logic flows to change them. If you are new to redux, <a href=\"https://redux.js.org/introduction/getting-started\" target=\"_blank\" rel=\"noopener\">here</a> is the guide to dive before we start our topic.<a id=\"more\"></a></p>\n<p>In a complex javascript application, asynchronous function is always one of the most annoying part where encounters tons of bugs. If not handle them properly, the app usually ends up with <strong><em>call back hell</em></strong>.<br><br></p>\n<h2 id=\"Haven’t-heard-of-CallBack-Hell\"><a href=\"#Haven’t-heard-of-CallBack-Hell\" class=\"headerlink\" title=\"Haven’t heard of CallBack Hell?\"></a><strong>Haven’t heard of <em>CallBack Hell</em>?</strong></h2><p>Well, in javascript, the only way you can suspend a computation and have the rest operations doing later is to put the rest operations into a callback function. This callback function usually returns a <strong><code>Promise</code></strong> (And has a type of <strong><code>Promise&lt;any&gt;</code></strong>). In order to easily mark those async functions, after <strong><em>ES6</em></strong> javascript provides extra modifiers <strong><code>async</code></strong> and <strong><code>await</code></strong>, which actually wraps up the original utilities of promise and makes it more readable to programmers. Hummm, sounds like things are going better… <del><strong>NO!! It doesn’t resolve anything!</strong></del> The core problem leads to a callback hell is the hierarchical async calls, for example</p>\n<p>you have some simple synchronous functions which are in a chain to accomplish some logics:</p>\n<pre><code class=\"javascript\">a = getSomething();\nb = getMore(a);\nc = getMoreAndMore(b);\n...\n</code></pre>\n<p>It looks fine for now, but what if they all turn out to be async? Then you have to follow the callback style to make them operate one right after another is done:</p>\n<pre><code class=\"javascript\">getSomthing(function(a) {\n    getMore(a, function(b) {\n        getMoreAndMore(b, function(c) {\n            //keep going...\n        });\n    });\n});\n</code></pre>\n<p>Or you prefer <strong><em>ES6</em></strong>:</p>\n<pre><code class=\"javascript\">async function getSomething(a) {\n    await b = ToDo(a);\n    return await getMore((b) =&gt; {\n        return await ToDo(b);\n    }).then((c) =&gt; {\n        return await ToDo(c);\n    }).then(...);\n}\n</code></pre>\n<p>Looks really confused? This will getting even uglier if we are using callbacks in loops.<br><br></p>\n<h2 id=\"Redux-Thunks\"><a href=\"#Redux-Thunks\" class=\"headerlink\" title=\"Redux Thunks\"></a>Redux Thunks</h2><p>Back to our redux app, we usually want to update some states after an async call to inform the UI that the data is ready to be fetched. That is always achieved by dispatching an action from the component to the reducer:</p>\n<pre><code class=\"javascript\">async const callAPI = () =&gt; {\n    ...\n    return response;\n};\n...\nasync const updateUI = (...params) =&gt; {\n    const res = await callAPI();\n    if (res.status === 200)\n        dispatch({type: &quot;UPDATE&quot;, isSuccess: true});\n};\n...\nrender({\n    ...\n    this.props.isSuccess?\n        showData() : showError()\n});\n</code></pre>\n<p>This isn’t bad, but we are always looking for something better. An advanced way to rewrite it is using redux middleware. <strong><em>Middleware</em></strong> is somewhere you can put the code after the framework receives a request and before it generates a response. For example, we want to add a logger in the redux store so that when the store catches an action, before it returns the new state, the logger can log the previous state and the new generated state. This is what can be added as a middleware:</p>\n<pre><code class=\"javascript\">function logger(store) {\n    return function wrapDispatch (next) {\n        return function dispatchAndLog (action) {\n            console.log(&quot;dispatching.. &quot;, action);\n            let result = next(action);\n            console.log(&quot;new state&quot;, store.getState());\n            return result;\n        }\n    }\n}\n</code></pre>\n<p>There are more advanced ways to add a logger. If you are interested, please refer to the <a href=\"https://redux.js.org/advanced/middleware\" target=\"_blank\" rel=\"noopener\">offical documentation</a>. With our middleware, the previous example can be written in a cleaner way:</p>\n<pre><code class=\"javascript\">const callAPI = () =&gt; {\n    return((dispatch) =&gt; {\n        dispatch(startCallingApiAction);\n        actualCallApi().then(data =&gt; {\n            dispatch(successAction(data));\n        }).fail(err =&gt; {\n            dispatch(failedAction(err));\n        });\n    });\n};\n</code></pre>\n<p>The successful response data is wrapped in the payload of the action, sent to the reducer. Once the store updates the data, it will be mapped as a prop back to the component and request for a rerender. This middleware is also called <strong><em>thunk</em></strong>. By applying thunk to decouple the presentation layer, we can get rid of most of the side effects in components, instead, managing and orchestrating side effects in thunks.</p>\n<p>This is great, so why are we even considering <strong><em>saga</em></strong>? Well, one of the advantages of middleware is that it can be chained. Every middleware mounted in redux store starts an individual thread (or something really looks like a thread in <strong><em>NodeJS</em></strong>). When a middleware captures an action and handles its side effect, it can dispatch a new action to another middleware to do nested logics. This behavior of middleware indicates that thunks can be chained as well, for example thunkA forwards its return payload to thunkB and thunkB forwards its return payload to… <strong>Wait! That sounds quite familiar!! Is that the case of callback hell??</strong> Unfortunately, a good thing plus another good feature doesn’t always end up with something better. <del>It could be some shit as well (笑)</del> In this case, true, this is exactly the callback hell.<br><br></p>\n<h2 id=\"Redux-Saga\"><a href=\"#Redux-Saga\" class=\"headerlink\" title=\"Redux Saga\"></a>Redux Saga</h2><p>To handle the possible endless callback functions and also to make it more easily to test in a component which has complicated logics, we need to change our previous thoughts. Just like shifting from Process Oriented Programming to Object Oriented Programming, instead of telling the application how to handle the side effects, suppose it already knows how to call a function and how to dispatch an action, all we need to do is to <strong>give instructions about what to do next</strong> and we don’t care about how those instructions will be executed (Saga handles the executions).</p>\n<p>Then the thunks example can be changed as following:</p>\n<pre><code class=\"javascript\">export function* apiSideEffect(action) {\n    try{\n        const data = yield call(actualCallApi);\n        yield put({ type:&quot;SUCCESS&quot;, payload: data });\n    } catch(err) {\n        yield put({ type:&quot;FAILED&quot;, payload: err });\n    }\n}\n\nexport function* apiSaga() {\n    yield takeEvery(&quot;CLICK_TO_CALL_API&quot;, apiSideEffect);\n}\n</code></pre>\n<p>There are serval fucntions already being integrated in Saga:</p>\n<blockquote>\n<p><strong><code>Call</code></strong>: the method call will return only a plain object describing the operation so redux-saga can take care of the invocation and returns the result to the generator. The first parameter is the generator function ready to be called and the rest params are all the arguments in the generator.</p>\n</blockquote>\n<blockquote>\n<p><strong><code>Put</code></strong>: Instead of dispatching an action inside the generator (Don’t ever ever do that), <strong><em>put</em></strong> Returns an object with instructions for the middleware to dispatch the action.</p>\n</blockquote>\n<blockquote>\n<p><strong><code>Select</code></strong>: Returns value from the selector function, similar with <strong><code>getState()</code></strong>. <strong><em>Note:</em></strong> It is not recommended to use this function because it returns the value corresponding to the contents of the store state tree, which is most likely a plain Javascript object and is <strong>mutable</strong> (Redux wants you to handle state immutably, which means return a new state instead of changing the old one).</p>\n</blockquote>\n<blockquote>\n<p><strong><code>Take</code></strong>: It creates a command object that tells the middleware to wait for a specific action. The resulting behavior of the call Effect is the same as when the middleware suspends the generator until a <strong><em>promise</em></strong> resolves. In the take case, it’ll suspend the generator until a matching action is dispatched</p>\n</blockquote>\n<p>By working with Saga, we make the side effects to be <strong><em>declarative</em></strong> rather than <strong><em>imperative</em></strong>.</p>\n<blockquote>\n<p><strong><em>Declarative:</em></strong> describing what the program must accomplish, rather than describe how to accomplish it</p>\n</blockquote>\n<blockquote>\n<p><strong><em>Imperative:</em></strong> consists of commands for the computer to perform, focuses on describing how a program operates</p>\n</blockquote>\n<p>In the case of take, the control is inverted. Instead of the actions being pushed to the handler tasks, the <strong>Saga is pulling the action by itself</strong>. An additional generator, known as <strong><em>watcher</em></strong> which contains <strong><em>take</em></strong> has to be created to watch a specific action and being triggered once the following action is dispatched in the application. There are two ways to create a watcher, one is using the buid-in functions (<strong><em>Saga Helper</em></strong>):</p>\n<pre><code class=\"javascript\">function* watchFetchData() {\n    yield takeEvery(&quot;FETCH_REQUEST&quot;, callFetchDataApi);\n}\n</code></pre>\n<p><strong><em>takeEvery</em></strong> allows multiple request to be proceeding at the same time. Or if you just want the latest request to be fired (the older one will be overrided during each time the watcher is triggered</p>\n<pre><code class=\"javascript\">function* watchFetchData() {\n    yield takeLatest(&quot;FETCH_REQUEST&quot;, callFetchDataApi);\n}\n</code></pre>\n<p>However by using <strong><em>take</em></strong>, it is possible to fully control an action observation process to build complex control flow:</p>\n<pre><code class=\"javascript\">function* watchFetchData() {\n    while(true) {\n        const action = yield take(&quot;FETCH_REQUEST&quot;);\n        console.log(action);\n        yield call(callFetchDataApi, action.payload);\n    }\n}\n</code></pre>\n<p>All right, now you have been exposed to everything you need to know before start trying redux saga on your own. Here is a short overall example that may also help:<br>Store:</p>\n<pre><code class=\"javascript\">const sagaMiddleware = createSagaMiddleware();\nconst store = createStore(rootReducer, appluMiddleware(sagaMiddleware));    \nsagaMiddleware.run(watchFetch);\n</code></pre>\n<p>Sagas:</p>\n<pre><code class=\"javascript\">function* watchFetch(): Generator&lt;*, *, *&gt; {\n    yield takeEvery(&quot;FETCH_ACTION&quot;, callFetchAPI);\n}\n\nfunction* callFetchAPI(): Generator&lt;*, *, *&gt; {\n    try {\n        yield put({ type: &quot;FETCHING&quot;, payload: ... });\n        const data = yield call(actualCallApi);\n        yield put({ type: &quot;FETCH_SUCCESS&quot;, payload: data });\n    } catch(err) {\n        yield put({ type: &quot;FETCH_FAILED&quot;, payload: err });\n    }\n}\n</code></pre>\n<p>Reducer:</p>\n<pre><code class=\"javascript\">const reducer = (state = initState, action) =&gt; {\n    switch(action) {\n        case &quot;FETCHING&quot;:\n            return { loading: true, ...state };\n        case &quot;FETCH_SUCCESS&quot;:\n            return { loading: false, success: true, data: action.payload, ...state };   \n        case &quot;FETCH_FAILED&quot;:\n            return { loading: false, success: false, error: true, ...state };\n        default:\n            return { ...state };\n    }\n};\n</code></pre>\n<p>Component:</p>\n<pre><code class=\"javascript\">class myComponent extends React.Component {\n    const mapStateToProps = ...\n    const mapDispatchToProps = ...\n    render() {\n        return (\n            &lt;button onClick = { () =&gt; this.props.dispatch({type: &quot;FETCH_ACTION&quot;}) }/&gt;   \n            {\n                this.props.loading?\n                    &lt;p&gt;Loading..&lt;/p&gt; : this.props.error?\n                        &lt;p&gt;Error!&lt;/p&gt; : &lt;p&gt;{this.props.data}&lt;/p&gt;\n            }\n        );\n    }\n}\nexport default connect(mapStateToProps, mapDispatchToProps)(myComponent);\n\n</code></pre>\n<p>For more advanced concepts, there is a well-organized <a href=\"https://redux-saga.js.org/docs/advanced/\" target=\"_blank\" rel=\"noopener\">Saga offical documentation</a> you can refer to if you want to dive deeper.<br><br></p>\n<h2 id=\"How-to-test-Saga\"><a href=\"#How-to-test-Saga\" class=\"headerlink\" title=\"How to test Saga?\"></a>How to test Saga?</h2><p>A function that returns a simple object is easier to test than a function that directly makes an asynchronous call. For redux saga, each time you yield a function call will return a plain javascript object which makes the workflow much easier to test. You don’t need to use the real API, fake it, or mock it, instead just iterating over the generator function, asserting for equality on the values yielded.</p>\n<pre><code class=\"javascript\">describe(&quot;fetch work flow&quot;, () =&gt; {\n    const generator = cloneableGenerator(callFetchAPI)({ type: &quot;FETCH_ACTION&quot; });\n    expect(generator.next().value).toEqual(put({ type: &quot;FETCHING&quot;, payload: ... }));    \n\n    test(&quot;fetch success&quot;, () =&gt; {\n        const clone = generator.clone();\n        expect(clone.next().value).toEqual(put({ type: &quot;FETCH_SUCCESS&quot; }));\n        expect(generator.next().done).toEqual(true);\n    });\n});\n</code></pre>\n<p>In the above example, we use <strong><code>clone()</code></strong> to test different control flows and <strong><code>next()</code></strong> to iterate to the next function ready be yielded. The mock return value can also be injected as an argument of <strong><code>next()</code></strong>:</p>\n<pre><code class=\"javascript\">expect(clone.next(false).value).toEqual( put(fetchFailedAction()) );      \n</code></pre>\n<p><br></p>\n<h2 id=\"Saga-vs-Observables\"><a href=\"#Saga-vs-Observables\" class=\"headerlink\" title=\"Saga vs Observables\"></a>Saga vs Observables</h2><p>Redux saga is not the only solution to our apps which may have complex control flows, they are other helpful tools providing different trade-offs which can also resolve the async problems. Here are some good <a href=\"https://hackmd.io/s/H1xLHUQ8e\" target=\"_blank\" rel=\"noopener\">code snippets</a> of saga vs observables that can open your mind :D</p>\n<p><br><br><br></p>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References:\"></a>References:</h2><p><a href=\"https://redux-saga.js.org/\" target=\"_blank\" rel=\"noopener\">https://redux-saga.js.org/</a><br><a href=\"https://stackoverflow.com/questions/25098066/what-is-callback-hell-and-how-and-why-rx-solves-it\" target=\"_blank\" rel=\"noopener\">https://stackoverflow.com/questions/25098066/what-is-callback-hell-and-how-and-why-rx-solves-it</a><br><a href=\"https://redux.js.org/advanced/middleware\" target=\"_blank\" rel=\"noopener\">https://redux.js.org/advanced/middleware</a><br><a href=\"https://pub.dartlang.org/packages/redux_thunk\" target=\"_blank\" rel=\"noopener\">https://pub.dartlang.org/packages/redux_thunk</a><br><a href=\"https://codeburst.io/how-i-test-redux-saga-fcc425cda018\" target=\"_blank\" rel=\"noopener\">https://codeburst.io/how-i-test-redux-saga-fcc425cda018</a><br><a href=\"https://engineering.universe.com/what-is-redux-saga-c1252fc2f4d1\" target=\"_blank\" rel=\"noopener\">https://engineering.universe.com/what-is-redux-saga-c1252fc2f4d1</a><br><a href=\"https://www.sitepoint.com/redux-without-react-state-management-vanilla-javascript/\" target=\"_blank\" rel=\"noopener\">https://www.sitepoint.com/redux-without-react-state-management-vanilla-javascript/</a><br><a href=\"https://redux.js.org/introduction/getting-started\" target=\"_blank\" rel=\"noopener\">https://redux.js.org/introduction/getting-started</a><br><a href=\"https://blog.logrocket.com/understanding-redux-saga-from-action-creators-to-sagas-2587298b5e71\" target=\"_blank\" rel=\"noopener\">https://blog.logrocket.com/understanding-redux-saga-from-action-creators-to-sagas-2587298b5e71</a></p>\n","site":{"data":{}},"excerpt":"<p>If you are quite experienced with redux, which is a predictable state container for JavaScript applications (<strong>Note:</strong> even thouth React and Redux is a popular combination to build fast and powerful apps, Redux is not necessarily combined with React), you are definitely feeling comfortable with its powerful store which manages all the global states and provides much cleaner logic flows to change them. If you are new to redux, <a href=\"https://redux.js.org/introduction/getting-started\" target=\"_blank\" rel=\"noopener\">here</a> is the guide to dive before we start our topic.","more":"</p>\n<p>In a complex javascript application, asynchronous function is always one of the most annoying part where encounters tons of bugs. If not handle them properly, the app usually ends up with <strong><em>call back hell</em></strong>.<br><br></p>\n<h2 id=\"Haven’t-heard-of-CallBack-Hell\"><a href=\"#Haven’t-heard-of-CallBack-Hell\" class=\"headerlink\" title=\"Haven’t heard of CallBack Hell?\"></a><strong>Haven’t heard of <em>CallBack Hell</em>?</strong></h2><p>Well, in javascript, the only way you can suspend a computation and have the rest operations doing later is to put the rest operations into a callback function. This callback function usually returns a <strong><code>Promise</code></strong> (And has a type of <strong><code>Promise&lt;any&gt;</code></strong>). In order to easily mark those async functions, after <strong><em>ES6</em></strong> javascript provides extra modifiers <strong><code>async</code></strong> and <strong><code>await</code></strong>, which actually wraps up the original utilities of promise and makes it more readable to programmers. Hummm, sounds like things are going better… <del><strong>NO!! It doesn’t resolve anything!</strong></del> The core problem leads to a callback hell is the hierarchical async calls, for example</p>\n<p>you have some simple synchronous functions which are in a chain to accomplish some logics:</p>\n<pre><code class=\"javascript\">a = getSomething();\nb = getMore(a);\nc = getMoreAndMore(b);\n...\n</code></pre>\n<p>It looks fine for now, but what if they all turn out to be async? Then you have to follow the callback style to make them operate one right after another is done:</p>\n<pre><code class=\"javascript\">getSomthing(function(a) {\n    getMore(a, function(b) {\n        getMoreAndMore(b, function(c) {\n            //keep going...\n        });\n    });\n});\n</code></pre>\n<p>Or you prefer <strong><em>ES6</em></strong>:</p>\n<pre><code class=\"javascript\">async function getSomething(a) {\n    await b = ToDo(a);\n    return await getMore((b) =&gt; {\n        return await ToDo(b);\n    }).then((c) =&gt; {\n        return await ToDo(c);\n    }).then(...);\n}\n</code></pre>\n<p>Looks really confused? This will getting even uglier if we are using callbacks in loops.<br><br></p>\n<h2 id=\"Redux-Thunks\"><a href=\"#Redux-Thunks\" class=\"headerlink\" title=\"Redux Thunks\"></a>Redux Thunks</h2><p>Back to our redux app, we usually want to update some states after an async call to inform the UI that the data is ready to be fetched. That is always achieved by dispatching an action from the component to the reducer:</p>\n<pre><code class=\"javascript\">async const callAPI = () =&gt; {\n    ...\n    return response;\n};\n...\nasync const updateUI = (...params) =&gt; {\n    const res = await callAPI();\n    if (res.status === 200)\n        dispatch({type: &quot;UPDATE&quot;, isSuccess: true});\n};\n...\nrender({\n    ...\n    this.props.isSuccess?\n        showData() : showError()\n});\n</code></pre>\n<p>This isn’t bad, but we are always looking for something better. An advanced way to rewrite it is using redux middleware. <strong><em>Middleware</em></strong> is somewhere you can put the code after the framework receives a request and before it generates a response. For example, we want to add a logger in the redux store so that when the store catches an action, before it returns the new state, the logger can log the previous state and the new generated state. This is what can be added as a middleware:</p>\n<pre><code class=\"javascript\">function logger(store) {\n    return function wrapDispatch (next) {\n        return function dispatchAndLog (action) {\n            console.log(&quot;dispatching.. &quot;, action);\n            let result = next(action);\n            console.log(&quot;new state&quot;, store.getState());\n            return result;\n        }\n    }\n}\n</code></pre>\n<p>There are more advanced ways to add a logger. If you are interested, please refer to the <a href=\"https://redux.js.org/advanced/middleware\" target=\"_blank\" rel=\"noopener\">offical documentation</a>. With our middleware, the previous example can be written in a cleaner way:</p>\n<pre><code class=\"javascript\">const callAPI = () =&gt; {\n    return((dispatch) =&gt; {\n        dispatch(startCallingApiAction);\n        actualCallApi().then(data =&gt; {\n            dispatch(successAction(data));\n        }).fail(err =&gt; {\n            dispatch(failedAction(err));\n        });\n    });\n};\n</code></pre>\n<p>The successful response data is wrapped in the payload of the action, sent to the reducer. Once the store updates the data, it will be mapped as a prop back to the component and request for a rerender. This middleware is also called <strong><em>thunk</em></strong>. By applying thunk to decouple the presentation layer, we can get rid of most of the side effects in components, instead, managing and orchestrating side effects in thunks.</p>\n<p>This is great, so why are we even considering <strong><em>saga</em></strong>? Well, one of the advantages of middleware is that it can be chained. Every middleware mounted in redux store starts an individual thread (or something really looks like a thread in <strong><em>NodeJS</em></strong>). When a middleware captures an action and handles its side effect, it can dispatch a new action to another middleware to do nested logics. This behavior of middleware indicates that thunks can be chained as well, for example thunkA forwards its return payload to thunkB and thunkB forwards its return payload to… <strong>Wait! That sounds quite familiar!! Is that the case of callback hell??</strong> Unfortunately, a good thing plus another good feature doesn’t always end up with something better. <del>It could be some shit as well (笑)</del> In this case, true, this is exactly the callback hell.<br><br></p>\n<h2 id=\"Redux-Saga\"><a href=\"#Redux-Saga\" class=\"headerlink\" title=\"Redux Saga\"></a>Redux Saga</h2><p>To handle the possible endless callback functions and also to make it more easily to test in a component which has complicated logics, we need to change our previous thoughts. Just like shifting from Process Oriented Programming to Object Oriented Programming, instead of telling the application how to handle the side effects, suppose it already knows how to call a function and how to dispatch an action, all we need to do is to <strong>give instructions about what to do next</strong> and we don’t care about how those instructions will be executed (Saga handles the executions).</p>\n<p>Then the thunks example can be changed as following:</p>\n<pre><code class=\"javascript\">export function* apiSideEffect(action) {\n    try{\n        const data = yield call(actualCallApi);\n        yield put({ type:&quot;SUCCESS&quot;, payload: data });\n    } catch(err) {\n        yield put({ type:&quot;FAILED&quot;, payload: err });\n    }\n}\n\nexport function* apiSaga() {\n    yield takeEvery(&quot;CLICK_TO_CALL_API&quot;, apiSideEffect);\n}\n</code></pre>\n<p>There are serval fucntions already being integrated in Saga:</p>\n<blockquote>\n<p><strong><code>Call</code></strong>: the method call will return only a plain object describing the operation so redux-saga can take care of the invocation and returns the result to the generator. The first parameter is the generator function ready to be called and the rest params are all the arguments in the generator.</p>\n</blockquote>\n<blockquote>\n<p><strong><code>Put</code></strong>: Instead of dispatching an action inside the generator (Don’t ever ever do that), <strong><em>put</em></strong> Returns an object with instructions for the middleware to dispatch the action.</p>\n</blockquote>\n<blockquote>\n<p><strong><code>Select</code></strong>: Returns value from the selector function, similar with <strong><code>getState()</code></strong>. <strong><em>Note:</em></strong> It is not recommended to use this function because it returns the value corresponding to the contents of the store state tree, which is most likely a plain Javascript object and is <strong>mutable</strong> (Redux wants you to handle state immutably, which means return a new state instead of changing the old one).</p>\n</blockquote>\n<blockquote>\n<p><strong><code>Take</code></strong>: It creates a command object that tells the middleware to wait for a specific action. The resulting behavior of the call Effect is the same as when the middleware suspends the generator until a <strong><em>promise</em></strong> resolves. In the take case, it’ll suspend the generator until a matching action is dispatched</p>\n</blockquote>\n<p>By working with Saga, we make the side effects to be <strong><em>declarative</em></strong> rather than <strong><em>imperative</em></strong>.</p>\n<blockquote>\n<p><strong><em>Declarative:</em></strong> describing what the program must accomplish, rather than describe how to accomplish it</p>\n</blockquote>\n<blockquote>\n<p><strong><em>Imperative:</em></strong> consists of commands for the computer to perform, focuses on describing how a program operates</p>\n</blockquote>\n<p>In the case of take, the control is inverted. Instead of the actions being pushed to the handler tasks, the <strong>Saga is pulling the action by itself</strong>. An additional generator, known as <strong><em>watcher</em></strong> which contains <strong><em>take</em></strong> has to be created to watch a specific action and being triggered once the following action is dispatched in the application. There are two ways to create a watcher, one is using the buid-in functions (<strong><em>Saga Helper</em></strong>):</p>\n<pre><code class=\"javascript\">function* watchFetchData() {\n    yield takeEvery(&quot;FETCH_REQUEST&quot;, callFetchDataApi);\n}\n</code></pre>\n<p><strong><em>takeEvery</em></strong> allows multiple request to be proceeding at the same time. Or if you just want the latest request to be fired (the older one will be overrided during each time the watcher is triggered</p>\n<pre><code class=\"javascript\">function* watchFetchData() {\n    yield takeLatest(&quot;FETCH_REQUEST&quot;, callFetchDataApi);\n}\n</code></pre>\n<p>However by using <strong><em>take</em></strong>, it is possible to fully control an action observation process to build complex control flow:</p>\n<pre><code class=\"javascript\">function* watchFetchData() {\n    while(true) {\n        const action = yield take(&quot;FETCH_REQUEST&quot;);\n        console.log(action);\n        yield call(callFetchDataApi, action.payload);\n    }\n}\n</code></pre>\n<p>All right, now you have been exposed to everything you need to know before start trying redux saga on your own. Here is a short overall example that may also help:<br>Store:</p>\n<pre><code class=\"javascript\">const sagaMiddleware = createSagaMiddleware();\nconst store = createStore(rootReducer, appluMiddleware(sagaMiddleware));    \nsagaMiddleware.run(watchFetch);\n</code></pre>\n<p>Sagas:</p>\n<pre><code class=\"javascript\">function* watchFetch(): Generator&lt;*, *, *&gt; {\n    yield takeEvery(&quot;FETCH_ACTION&quot;, callFetchAPI);\n}\n\nfunction* callFetchAPI(): Generator&lt;*, *, *&gt; {\n    try {\n        yield put({ type: &quot;FETCHING&quot;, payload: ... });\n        const data = yield call(actualCallApi);\n        yield put({ type: &quot;FETCH_SUCCESS&quot;, payload: data });\n    } catch(err) {\n        yield put({ type: &quot;FETCH_FAILED&quot;, payload: err });\n    }\n}\n</code></pre>\n<p>Reducer:</p>\n<pre><code class=\"javascript\">const reducer = (state = initState, action) =&gt; {\n    switch(action) {\n        case &quot;FETCHING&quot;:\n            return { loading: true, ...state };\n        case &quot;FETCH_SUCCESS&quot;:\n            return { loading: false, success: true, data: action.payload, ...state };   \n        case &quot;FETCH_FAILED&quot;:\n            return { loading: false, success: false, error: true, ...state };\n        default:\n            return { ...state };\n    }\n};\n</code></pre>\n<p>Component:</p>\n<pre><code class=\"javascript\">class myComponent extends React.Component {\n    const mapStateToProps = ...\n    const mapDispatchToProps = ...\n    render() {\n        return (\n            &lt;button onClick = { () =&gt; this.props.dispatch({type: &quot;FETCH_ACTION&quot;}) }/&gt;   \n            {\n                this.props.loading?\n                    &lt;p&gt;Loading..&lt;/p&gt; : this.props.error?\n                        &lt;p&gt;Error!&lt;/p&gt; : &lt;p&gt;{this.props.data}&lt;/p&gt;\n            }\n        );\n    }\n}\nexport default connect(mapStateToProps, mapDispatchToProps)(myComponent);\n\n</code></pre>\n<p>For more advanced concepts, there is a well-organized <a href=\"https://redux-saga.js.org/docs/advanced/\" target=\"_blank\" rel=\"noopener\">Saga offical documentation</a> you can refer to if you want to dive deeper.<br><br></p>\n<h2 id=\"How-to-test-Saga\"><a href=\"#How-to-test-Saga\" class=\"headerlink\" title=\"How to test Saga?\"></a>How to test Saga?</h2><p>A function that returns a simple object is easier to test than a function that directly makes an asynchronous call. For redux saga, each time you yield a function call will return a plain javascript object which makes the workflow much easier to test. You don’t need to use the real API, fake it, or mock it, instead just iterating over the generator function, asserting for equality on the values yielded.</p>\n<pre><code class=\"javascript\">describe(&quot;fetch work flow&quot;, () =&gt; {\n    const generator = cloneableGenerator(callFetchAPI)({ type: &quot;FETCH_ACTION&quot; });\n    expect(generator.next().value).toEqual(put({ type: &quot;FETCHING&quot;, payload: ... }));    \n\n    test(&quot;fetch success&quot;, () =&gt; {\n        const clone = generator.clone();\n        expect(clone.next().value).toEqual(put({ type: &quot;FETCH_SUCCESS&quot; }));\n        expect(generator.next().done).toEqual(true);\n    });\n});\n</code></pre>\n<p>In the above example, we use <strong><code>clone()</code></strong> to test different control flows and <strong><code>next()</code></strong> to iterate to the next function ready be yielded. The mock return value can also be injected as an argument of <strong><code>next()</code></strong>:</p>\n<pre><code class=\"javascript\">expect(clone.next(false).value).toEqual( put(fetchFailedAction()) );      \n</code></pre>\n<p><br></p>\n<h2 id=\"Saga-vs-Observables\"><a href=\"#Saga-vs-Observables\" class=\"headerlink\" title=\"Saga vs Observables\"></a>Saga vs Observables</h2><p>Redux saga is not the only solution to our apps which may have complex control flows, they are other helpful tools providing different trade-offs which can also resolve the async problems. Here are some good <a href=\"https://hackmd.io/s/H1xLHUQ8e\" target=\"_blank\" rel=\"noopener\">code snippets</a> of saga vs observables that can open your mind :D</p>\n<p><br><br><br></p>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References:\"></a>References:</h2><p><a href=\"https://redux-saga.js.org/\" target=\"_blank\" rel=\"noopener\">https://redux-saga.js.org/</a><br><a href=\"https://stackoverflow.com/questions/25098066/what-is-callback-hell-and-how-and-why-rx-solves-it\" target=\"_blank\" rel=\"noopener\">https://stackoverflow.com/questions/25098066/what-is-callback-hell-and-how-and-why-rx-solves-it</a><br><a href=\"https://redux.js.org/advanced/middleware\" target=\"_blank\" rel=\"noopener\">https://redux.js.org/advanced/middleware</a><br><a href=\"https://pub.dartlang.org/packages/redux_thunk\" target=\"_blank\" rel=\"noopener\">https://pub.dartlang.org/packages/redux_thunk</a><br><a href=\"https://codeburst.io/how-i-test-redux-saga-fcc425cda018\" target=\"_blank\" rel=\"noopener\">https://codeburst.io/how-i-test-redux-saga-fcc425cda018</a><br><a href=\"https://engineering.universe.com/what-is-redux-saga-c1252fc2f4d1\" target=\"_blank\" rel=\"noopener\">https://engineering.universe.com/what-is-redux-saga-c1252fc2f4d1</a><br><a href=\"https://www.sitepoint.com/redux-without-react-state-management-vanilla-javascript/\" target=\"_blank\" rel=\"noopener\">https://www.sitepoint.com/redux-without-react-state-management-vanilla-javascript/</a><br><a href=\"https://redux.js.org/introduction/getting-started\" target=\"_blank\" rel=\"noopener\">https://redux.js.org/introduction/getting-started</a><br><a href=\"https://blog.logrocket.com/understanding-redux-saga-from-action-creators-to-sagas-2587298b5e71\" target=\"_blank\" rel=\"noopener\">https://blog.logrocket.com/understanding-redux-saga-from-action-creators-to-sagas-2587298b5e71</a></p>"},{"title":"How to Check Open TCP/IP Ports in Mac OS X","date":"2019-05-06T08:48:23.000Z","photos":["../images/cli.JPG"],"_content":"The core of Mac OS is Darwin and we can use most of the CLI tools in Mac OS just like how it feels like in Linux. If we want to check out the current ports in usage, the command **`netstat`** is useful:\n```\nnetstat -ap tcp | grep -i \"listen\"\n```\n<!-- more -->\nThat will print out something like this in the console:\n```\nAchive Internet connections(including servers)\nProto     Recv-Q      Send-Q       Local Address       Foreign Address     (state)     \ntcp4      0           0            localhost.25035     *.*                  LISTEN\n```\nThat works but the problem is that it doesn't show up the names of the procedures which occupy the ports. Sometimes we want to know precisely which program is exposing the port. \n\nThen found out that there is another command **`lsof`**:\n```\nsudo lsof -nP -iTCP:PortNumber -sTCP:LISTEN\n```\nwhich prints out all the processes running in a given port with specific names:\n```\nCOMMAND    PID    USER    FD    TYPE    DEVICE    SIZE/OFF    NODE       NAME\nsyslogd    350    root    5w    VREG    222,5     0           440818     /var/adm/messages     \nsyslogd    350    root    6w    VREG    222,5     339098      6248       /var/log/syslog\ncron       353    root    cwd   VDIR    222,5     512         254550     /var -- atjobs\n```\n\n**`-n`** : No dns (no host name)\n**`-P`** : List port number instead of its name\n**`-i `** : Lists IP sockets\n\nTo view the port associated with a daemon:\n```\nlsof -i -n -P | grep python\n```\n\nIf we just want to see the name:\n```\nsudo lsof -i :PortNumber | grep LISTEN\n```\n\nGet all running **PID** in a specific port:\n```\nsudo lsof -i :PortNumber| grep LISTEN | awk '{ print $2; }' | head -n 2 | grep -v PID   \n```\n\nAnd then we can kill all the processes:\n```\nsudo kill -9 $(sudo lsof -i :PortNumber| grep LISTEN | awk '{ print $2; }' | head -n 2 | grep -v PID)   \n```\n\nlist all commands:\n```\nlsof -h\n```\n","source":"_posts/How-to-Check-Open-TCP-IP-Ports-in-Mac-OS-X.md","raw":"---\ntitle: How to Check Open TCP/IP Ports in Mac OS X\ndate: 2019-05-06 17:48:23\ntags: [CLI, Mac OS, port]\nphotos: [\"../images/cli.JPG\"]\n---\nThe core of Mac OS is Darwin and we can use most of the CLI tools in Mac OS just like how it feels like in Linux. If we want to check out the current ports in usage, the command **`netstat`** is useful:\n```\nnetstat -ap tcp | grep -i \"listen\"\n```\n<!-- more -->\nThat will print out something like this in the console:\n```\nAchive Internet connections(including servers)\nProto     Recv-Q      Send-Q       Local Address       Foreign Address     (state)     \ntcp4      0           0            localhost.25035     *.*                  LISTEN\n```\nThat works but the problem is that it doesn't show up the names of the procedures which occupy the ports. Sometimes we want to know precisely which program is exposing the port. \n\nThen found out that there is another command **`lsof`**:\n```\nsudo lsof -nP -iTCP:PortNumber -sTCP:LISTEN\n```\nwhich prints out all the processes running in a given port with specific names:\n```\nCOMMAND    PID    USER    FD    TYPE    DEVICE    SIZE/OFF    NODE       NAME\nsyslogd    350    root    5w    VREG    222,5     0           440818     /var/adm/messages     \nsyslogd    350    root    6w    VREG    222,5     339098      6248       /var/log/syslog\ncron       353    root    cwd   VDIR    222,5     512         254550     /var -- atjobs\n```\n\n**`-n`** : No dns (no host name)\n**`-P`** : List port number instead of its name\n**`-i `** : Lists IP sockets\n\nTo view the port associated with a daemon:\n```\nlsof -i -n -P | grep python\n```\n\nIf we just want to see the name:\n```\nsudo lsof -i :PortNumber | grep LISTEN\n```\n\nGet all running **PID** in a specific port:\n```\nsudo lsof -i :PortNumber| grep LISTEN | awk '{ print $2; }' | head -n 2 | grep -v PID   \n```\n\nAnd then we can kill all the processes:\n```\nsudo kill -9 $(sudo lsof -i :PortNumber| grep LISTEN | awk '{ print $2; }' | head -n 2 | grep -v PID)   \n```\n\nlist all commands:\n```\nlsof -h\n```\n","slug":"How-to-Check-Open-TCP-IP-Ports-in-Mac-OS-X","published":1,"updated":"2019-05-10T09:00:12.697Z","comments":1,"layout":"post","link":"","_id":"cjvkl7rrr0002seaozt5hxsmv","content":"<p>The core of Mac OS is Darwin and we can use most of the CLI tools in Mac OS just like how it feels like in Linux. If we want to check out the current ports in usage, the command <strong><code>netstat</code></strong> is useful:</p>\n<pre><code>netstat -ap tcp | grep -i &quot;listen&quot;\n</code></pre><a id=\"more\"></a>\n<p>That will print out something like this in the console:</p>\n<pre><code>Achive Internet connections(including servers)\nProto     Recv-Q      Send-Q       Local Address       Foreign Address     (state)     \ntcp4      0           0            localhost.25035     *.*                  LISTEN\n</code></pre><p>That works but the problem is that it doesn’t show up the names of the procedures which occupy the ports. Sometimes we want to know precisely which program is exposing the port. </p>\n<p>Then found out that there is another command <strong><code>lsof</code></strong>:</p>\n<pre><code>sudo lsof -nP -iTCP:PortNumber -sTCP:LISTEN\n</code></pre><p>which prints out all the processes running in a given port with specific names:</p>\n<pre><code>COMMAND    PID    USER    FD    TYPE    DEVICE    SIZE/OFF    NODE       NAME\nsyslogd    350    root    5w    VREG    222,5     0           440818     /var/adm/messages     \nsyslogd    350    root    6w    VREG    222,5     339098      6248       /var/log/syslog\ncron       353    root    cwd   VDIR    222,5     512         254550     /var -- atjobs\n</code></pre><p><strong><code>-n</code></strong> : No dns (no host name)<br><strong><code>-P</code></strong> : List port number instead of its name<br><strong><code>-i</code></strong> : Lists IP sockets</p>\n<p>To view the port associated with a daemon:</p>\n<pre><code>lsof -i -n -P | grep python\n</code></pre><p>If we just want to see the name:</p>\n<pre><code>sudo lsof -i :PortNumber | grep LISTEN\n</code></pre><p>Get all running <strong>PID</strong> in a specific port:</p>\n<pre><code>sudo lsof -i :PortNumber| grep LISTEN | awk &#39;{ print $2; }&#39; | head -n 2 | grep -v PID   \n</code></pre><p>And then we can kill all the processes:</p>\n<pre><code>sudo kill -9 $(sudo lsof -i :PortNumber| grep LISTEN | awk &#39;{ print $2; }&#39; | head -n 2 | grep -v PID)   \n</code></pre><p>list all commands:</p>\n<pre><code>lsof -h\n</code></pre>","site":{"data":{}},"excerpt":"<p>The core of Mac OS is Darwin and we can use most of the CLI tools in Mac OS just like how it feels like in Linux. If we want to check out the current ports in usage, the command <strong><code>netstat</code></strong> is useful:</p>\n<pre><code>netstat -ap tcp | grep -i &quot;listen&quot;\n</code></pre>","more":"<p>That will print out something like this in the console:</p>\n<pre><code>Achive Internet connections(including servers)\nProto     Recv-Q      Send-Q       Local Address       Foreign Address     (state)     \ntcp4      0           0            localhost.25035     *.*                  LISTEN\n</code></pre><p>That works but the problem is that it doesn’t show up the names of the procedures which occupy the ports. Sometimes we want to know precisely which program is exposing the port. </p>\n<p>Then found out that there is another command <strong><code>lsof</code></strong>:</p>\n<pre><code>sudo lsof -nP -iTCP:PortNumber -sTCP:LISTEN\n</code></pre><p>which prints out all the processes running in a given port with specific names:</p>\n<pre><code>COMMAND    PID    USER    FD    TYPE    DEVICE    SIZE/OFF    NODE       NAME\nsyslogd    350    root    5w    VREG    222,5     0           440818     /var/adm/messages     \nsyslogd    350    root    6w    VREG    222,5     339098      6248       /var/log/syslog\ncron       353    root    cwd   VDIR    222,5     512         254550     /var -- atjobs\n</code></pre><p><strong><code>-n</code></strong> : No dns (no host name)<br><strong><code>-P</code></strong> : List port number instead of its name<br><strong><code>-i</code></strong> : Lists IP sockets</p>\n<p>To view the port associated with a daemon:</p>\n<pre><code>lsof -i -n -P | grep python\n</code></pre><p>If we just want to see the name:</p>\n<pre><code>sudo lsof -i :PortNumber | grep LISTEN\n</code></pre><p>Get all running <strong>PID</strong> in a specific port:</p>\n<pre><code>sudo lsof -i :PortNumber| grep LISTEN | awk &#39;{ print $2; }&#39; | head -n 2 | grep -v PID   \n</code></pre><p>And then we can kill all the processes:</p>\n<pre><code>sudo kill -9 $(sudo lsof -i :PortNumber| grep LISTEN | awk &#39;{ print $2; }&#39; | head -n 2 | grep -v PID)   \n</code></pre><p>list all commands:</p>\n<pre><code>lsof -h\n</code></pre>"},{"title":"How to debug NodeJS on VS Code","date":"2019-05-08T02:50:53.000Z","photos":["../images/vscode.JPG"],"_content":"Here are the steps to start debug mode in VS Code:\n\n1. On the left side bar, click \"debug\" icon to switch to debug viewlet\n\n2. On the top left, click the gear icon\n\n3. Then `launch.json` will be opened in the editor\n\n4. Replace the content of the file to be:\n<!-- more -->\n```json\n{\n\t\"version\": \"0.2.0\",\n\t\"configurations\": [\n\t\t{\n\t\t\t\"type\": \"node\",\n\t\t\t\"request\": \"launch\",\n\t\t\t\"name\": \"Launch app.js\",\n\t\t\t\"program\": \"${workspaceRoot}/app.js\",\n\t\t\t\"stopOnEntry\": true,\n\t\t\t\"args\": [\n\t\t\t\t\"arg1\", \"arg2\", \"arg3\"\n\t\t\t]\n\t\t}\n\t]\n}\n```\n\n5. Replace the command line arguments to whatever you need\n\n6. Start the debugger or press `F5`\n\nYou are all good to go!\n\nIf your program reads from **stdin**, please add a \"console\" attribute to the launch config:\n```json\n{\n\t\"version\": \"0.2.0\",\n\t\"configurations\": [\n\t\t{\n\t\t\t\"type\": \"node\",\n\t\t\t\"request\": \"launch\",\n\t\t\t\"name\": \"Launch app.js\",\n\t\t\t\"program\": \"${workspaceRoot}/app.js\",\n\t\t\t\"stopOnEntry\": true,\n\t\t\t\"args\": [\n\t\t\t\t\"arg1\", \"arg2\", \"arg3\"\n\t\t\t],\n\t\t\t\"console\": \"integratedTerminal\"\n\t\t}\n\t]\n}\n```\n\nIf you are running the program in the **terminal**, you can change the content alternatively to be:\n```json\n{\n\t\"version\": \"0.2.0\",\n\t\"configurations\": [\n\t\t{\n\t\t\t\"type\": \"node\",\n\t\t\t\"request\": \"attach\",\n\t\t\t\"name\": \"Attach to app.js\",\n\t\t\t\"port\": \"5858\"\n\t\t}\n\t]\n}\n```\nThe port is the **debug port** and it has nothing to do with your program (no matter it is a service or not). Then in the terminal, run the command:\n```shell\nnode --debug-brk app.js arg1 arg2 arg3...\n```\n>The `--debug-brk` lets your program wait for the debugger to attach to. So there is no problem that it terminates before the debugger could attach.\n\n</br>\n\nRunning such command, you may encounter a warning below:\n```\n(node:31245) [DEP0062] DeprecationWarning: `node --inspect --debug-brk` is deprecated. Please use `node --inspect-brk` instead.     \n```\nAs discussed in [microsoft github offical repository](https://github.com/Microsoft/vscode/issues/32529), currently there is **no way** to prevent this happening. The reason why using `--inspect --debug-brk` is explained [here](https://github.com/microsoft/vscode/issues/27731):\n>This combination of args is the only way to enter debug mode across all node versions. At some point I'll switch to inspect-brk if we don't want to support node 6.x anymore, or will do version detection for it and do something for runtimeExecutable scenarios.\n\n>The problem is that we do not really know what version of node a user is using, so we cannot adapt the flags we use to the node version in order to minimize the resulting deprecation warnings.\n\n","source":"_posts/How-to-debug-NodeJS-on-VS-Code.md","raw":"---\ntitle: How to debug NodeJS on VS Code\ndate: 2019-05-08 11:50:53\ntags: [VS Code, NodeJS]\nphotos: [\"../images/vscode.JPG\"]\n---\nHere are the steps to start debug mode in VS Code:\n\n1. On the left side bar, click \"debug\" icon to switch to debug viewlet\n\n2. On the top left, click the gear icon\n\n3. Then `launch.json` will be opened in the editor\n\n4. Replace the content of the file to be:\n<!-- more -->\n```json\n{\n\t\"version\": \"0.2.0\",\n\t\"configurations\": [\n\t\t{\n\t\t\t\"type\": \"node\",\n\t\t\t\"request\": \"launch\",\n\t\t\t\"name\": \"Launch app.js\",\n\t\t\t\"program\": \"${workspaceRoot}/app.js\",\n\t\t\t\"stopOnEntry\": true,\n\t\t\t\"args\": [\n\t\t\t\t\"arg1\", \"arg2\", \"arg3\"\n\t\t\t]\n\t\t}\n\t]\n}\n```\n\n5. Replace the command line arguments to whatever you need\n\n6. Start the debugger or press `F5`\n\nYou are all good to go!\n\nIf your program reads from **stdin**, please add a \"console\" attribute to the launch config:\n```json\n{\n\t\"version\": \"0.2.0\",\n\t\"configurations\": [\n\t\t{\n\t\t\t\"type\": \"node\",\n\t\t\t\"request\": \"launch\",\n\t\t\t\"name\": \"Launch app.js\",\n\t\t\t\"program\": \"${workspaceRoot}/app.js\",\n\t\t\t\"stopOnEntry\": true,\n\t\t\t\"args\": [\n\t\t\t\t\"arg1\", \"arg2\", \"arg3\"\n\t\t\t],\n\t\t\t\"console\": \"integratedTerminal\"\n\t\t}\n\t]\n}\n```\n\nIf you are running the program in the **terminal**, you can change the content alternatively to be:\n```json\n{\n\t\"version\": \"0.2.0\",\n\t\"configurations\": [\n\t\t{\n\t\t\t\"type\": \"node\",\n\t\t\t\"request\": \"attach\",\n\t\t\t\"name\": \"Attach to app.js\",\n\t\t\t\"port\": \"5858\"\n\t\t}\n\t]\n}\n```\nThe port is the **debug port** and it has nothing to do with your program (no matter it is a service or not). Then in the terminal, run the command:\n```shell\nnode --debug-brk app.js arg1 arg2 arg3...\n```\n>The `--debug-brk` lets your program wait for the debugger to attach to. So there is no problem that it terminates before the debugger could attach.\n\n</br>\n\nRunning such command, you may encounter a warning below:\n```\n(node:31245) [DEP0062] DeprecationWarning: `node --inspect --debug-brk` is deprecated. Please use `node --inspect-brk` instead.     \n```\nAs discussed in [microsoft github offical repository](https://github.com/Microsoft/vscode/issues/32529), currently there is **no way** to prevent this happening. The reason why using `--inspect --debug-brk` is explained [here](https://github.com/microsoft/vscode/issues/27731):\n>This combination of args is the only way to enter debug mode across all node versions. At some point I'll switch to inspect-brk if we don't want to support node 6.x anymore, or will do version detection for it and do something for runtimeExecutable scenarios.\n\n>The problem is that we do not really know what version of node a user is using, so we cannot adapt the flags we use to the node version in order to minimize the resulting deprecation warnings.\n\n","slug":"How-to-debug-NodeJS-on-VS-Code","published":1,"updated":"2019-05-10T09:52:58.626Z","comments":1,"layout":"post","link":"","_id":"cjvkl7rrw0005seaog6udk8bo","content":"<p>Here are the steps to start debug mode in VS Code:</p>\n<ol>\n<li><p>On the left side bar, click “debug” icon to switch to debug viewlet</p>\n</li>\n<li><p>On the top left, click the gear icon</p>\n</li>\n<li><p>Then <code>launch.json</code> will be opened in the editor</p>\n</li>\n<li><p>Replace the content of the file to be:</p>\n<a id=\"more\"></a>\n<pre><code class=\"json\">{\n &quot;version&quot;: &quot;0.2.0&quot;,\n &quot;configurations&quot;: [\n     {\n         &quot;type&quot;: &quot;node&quot;,\n         &quot;request&quot;: &quot;launch&quot;,\n         &quot;name&quot;: &quot;Launch app.js&quot;,\n         &quot;program&quot;: &quot;${workspaceRoot}/app.js&quot;,\n         &quot;stopOnEntry&quot;: true,\n         &quot;args&quot;: [\n             &quot;arg1&quot;, &quot;arg2&quot;, &quot;arg3&quot;\n         ]\n     }\n ]\n}\n</code></pre>\n</li>\n<li><p>Replace the command line arguments to whatever you need</p>\n</li>\n<li><p>Start the debugger or press <code>F5</code></p>\n</li>\n</ol>\n<p>You are all good to go!</p>\n<p>If your program reads from <strong>stdin</strong>, please add a “console” attribute to the launch config:</p>\n<pre><code class=\"json\">{\n    &quot;version&quot;: &quot;0.2.0&quot;,\n    &quot;configurations&quot;: [\n        {\n            &quot;type&quot;: &quot;node&quot;,\n            &quot;request&quot;: &quot;launch&quot;,\n            &quot;name&quot;: &quot;Launch app.js&quot;,\n            &quot;program&quot;: &quot;${workspaceRoot}/app.js&quot;,\n            &quot;stopOnEntry&quot;: true,\n            &quot;args&quot;: [\n                &quot;arg1&quot;, &quot;arg2&quot;, &quot;arg3&quot;\n            ],\n            &quot;console&quot;: &quot;integratedTerminal&quot;\n        }\n    ]\n}\n</code></pre>\n<p>If you are running the program in the <strong>terminal</strong>, you can change the content alternatively to be:</p>\n<pre><code class=\"json\">{\n    &quot;version&quot;: &quot;0.2.0&quot;,\n    &quot;configurations&quot;: [\n        {\n            &quot;type&quot;: &quot;node&quot;,\n            &quot;request&quot;: &quot;attach&quot;,\n            &quot;name&quot;: &quot;Attach to app.js&quot;,\n            &quot;port&quot;: &quot;5858&quot;\n        }\n    ]\n}\n</code></pre>\n<p>The port is the <strong>debug port</strong> and it has nothing to do with your program (no matter it is a service or not). Then in the terminal, run the command:</p>\n<pre><code class=\"shell\">node --debug-brk app.js arg1 arg2 arg3...\n</code></pre>\n<blockquote>\n<p>The <code>--debug-brk</code> lets your program wait for the debugger to attach to. So there is no problem that it terminates before the debugger could attach.</p>\n</blockquote>\n<p><br></p>\n<p>Running such command, you may encounter a warning below:</p>\n<pre><code>(node:31245) [DEP0062] DeprecationWarning: `node --inspect --debug-brk` is deprecated. Please use `node --inspect-brk` instead.     \n</code></pre><p>As discussed in <a href=\"https://github.com/Microsoft/vscode/issues/32529\" target=\"_blank\" rel=\"noopener\">microsoft github offical repository</a>, currently there is <strong>no way</strong> to prevent this happening. The reason why using <code>--inspect --debug-brk</code> is explained <a href=\"https://github.com/microsoft/vscode/issues/27731\" target=\"_blank\" rel=\"noopener\">here</a>:</p>\n<blockquote>\n<p>This combination of args is the only way to enter debug mode across all node versions. At some point I’ll switch to inspect-brk if we don’t want to support node 6.x anymore, or will do version detection for it and do something for runtimeExecutable scenarios.</p>\n</blockquote>\n<blockquote>\n<p>The problem is that we do not really know what version of node a user is using, so we cannot adapt the flags we use to the node version in order to minimize the resulting deprecation warnings.</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"<p>Here are the steps to start debug mode in VS Code:</p>\n<ol>\n<li><p>On the left side bar, click “debug” icon to switch to debug viewlet</p>\n</li>\n<li><p>On the top left, click the gear icon</p>\n</li>\n<li><p>Then <code>launch.json</code> will be opened in the editor</p>\n</li>\n<li><p>Replace the content of the file to be:</p>","more":"<pre><code class=\"json\">{\n &quot;version&quot;: &quot;0.2.0&quot;,\n &quot;configurations&quot;: [\n     {\n         &quot;type&quot;: &quot;node&quot;,\n         &quot;request&quot;: &quot;launch&quot;,\n         &quot;name&quot;: &quot;Launch app.js&quot;,\n         &quot;program&quot;: &quot;${workspaceRoot}/app.js&quot;,\n         &quot;stopOnEntry&quot;: true,\n         &quot;args&quot;: [\n             &quot;arg1&quot;, &quot;arg2&quot;, &quot;arg3&quot;\n         ]\n     }\n ]\n}\n</code></pre>\n</li>\n<li><p>Replace the command line arguments to whatever you need</p>\n</li>\n<li><p>Start the debugger or press <code>F5</code></p>\n</li>\n</ol>\n<p>You are all good to go!</p>\n<p>If your program reads from <strong>stdin</strong>, please add a “console” attribute to the launch config:</p>\n<pre><code class=\"json\">{\n    &quot;version&quot;: &quot;0.2.0&quot;,\n    &quot;configurations&quot;: [\n        {\n            &quot;type&quot;: &quot;node&quot;,\n            &quot;request&quot;: &quot;launch&quot;,\n            &quot;name&quot;: &quot;Launch app.js&quot;,\n            &quot;program&quot;: &quot;${workspaceRoot}/app.js&quot;,\n            &quot;stopOnEntry&quot;: true,\n            &quot;args&quot;: [\n                &quot;arg1&quot;, &quot;arg2&quot;, &quot;arg3&quot;\n            ],\n            &quot;console&quot;: &quot;integratedTerminal&quot;\n        }\n    ]\n}\n</code></pre>\n<p>If you are running the program in the <strong>terminal</strong>, you can change the content alternatively to be:</p>\n<pre><code class=\"json\">{\n    &quot;version&quot;: &quot;0.2.0&quot;,\n    &quot;configurations&quot;: [\n        {\n            &quot;type&quot;: &quot;node&quot;,\n            &quot;request&quot;: &quot;attach&quot;,\n            &quot;name&quot;: &quot;Attach to app.js&quot;,\n            &quot;port&quot;: &quot;5858&quot;\n        }\n    ]\n}\n</code></pre>\n<p>The port is the <strong>debug port</strong> and it has nothing to do with your program (no matter it is a service or not). Then in the terminal, run the command:</p>\n<pre><code class=\"shell\">node --debug-brk app.js arg1 arg2 arg3...\n</code></pre>\n<blockquote>\n<p>The <code>--debug-brk</code> lets your program wait for the debugger to attach to. So there is no problem that it terminates before the debugger could attach.</p>\n</blockquote>\n<p><br></p>\n<p>Running such command, you may encounter a warning below:</p>\n<pre><code>(node:31245) [DEP0062] DeprecationWarning: `node --inspect --debug-brk` is deprecated. Please use `node --inspect-brk` instead.     \n</code></pre><p>As discussed in <a href=\"https://github.com/Microsoft/vscode/issues/32529\" target=\"_blank\" rel=\"noopener\">microsoft github offical repository</a>, currently there is <strong>no way</strong> to prevent this happening. The reason why using <code>--inspect --debug-brk</code> is explained <a href=\"https://github.com/microsoft/vscode/issues/27731\" target=\"_blank\" rel=\"noopener\">here</a>:</p>\n<blockquote>\n<p>This combination of args is the only way to enter debug mode across all node versions. At some point I’ll switch to inspect-brk if we don’t want to support node 6.x anymore, or will do version detection for it and do something for runtimeExecutable scenarios.</p>\n</blockquote>\n<blockquote>\n<p>The problem is that we do not really know what version of node a user is using, so we cannot adapt the flags we use to the node version in order to minimize the resulting deprecation warnings.</p>\n</blockquote>"},{"title":"Memory Leaks in Serveral Commonly Used Programming Languages","date":"2019-05-05T06:37:22.000Z","photos":["../images/Memory-Leaks.JPG"],"_content":"Usually when we talk about memory leaks we are actually talking about the memory leaks in heap memory. When an object is initialized, it will be dynamically allocated to a piece of memory in the heap and ready to be manipulated. After we perform some operations and the whole procedure is finished, the object stored in heap should also be erased; however in the case of memory leak, that piece of memory is not released but still held in the heap, marked as occupied but no reference refers to it.<!-- more -->\n\nWiki's Def:\n>[**Memory leak**](https://en.wikipedia.org/wiki/Memory_leak) is a type of resource leak that occurs when a computer program incorrectly manages memory allocations in such a way that: \n- memory which is no longer needed is not released\n- an object is stored in memory but cannot be accessed by the running code\n\nWe usually encounter this issue in programming languages that don't have [**GC**](https://en.wikipedia.org/wiki/Garbage_collection_(computer_science), for example C++ and C. For such languages, we have to manage the memory by ourselves which, if not done properly, will expose the risks of memory leaks.\n</br>\n\n## This is really common in C++\nLet's take a look in C++. There are literally hundreds of ways that can cause memory leaks and most of them won't be detected during compilation and even in runtime. Only a few leaks will not have any impact on the system; however if we are running a huge application and those leaks accumulate, that will significantly reduce the real runtime performance of the whole system.\n\nWe all know that when we allocate an object, we have to release the memory if this object is not used anymore. The way we release the memory is simply call the buid-in function **`free()`** or **`delete[]`**. However in C++ the procedure can exit anywhere. An exception can be thrown in the half way so that the code doesn't ever reach the line to release memory:\n```c++\nint sample(int n) {\n    void  *ptr = malloc(16);\n    if (n)\n        return -1; //memory leak here\n    free(ptr);\n    return 0;\n}\n```\nor:\n```c++\nclass Sample {\n    public:\n        init() { int *n = new int;  throw any_exception(); }\n        ~init() { delete n; }\n    private:\n        int *n;\n};\nSample *n = new Sample; //memory leak here\n```\nThe solution to the above examples is also really simple: check control flows and **do remember to call the destructor before anywhere the procedure may exit**. Well if you want to do it in a fancy way, you can use ***smart pointer*** alternatively:\n```c++\nclass Sample {\n    public:\n        init() { n = std::make_shared<int>(new int) }\n        ~init() {}\n    private:\n        std::shared_ptr<int> n;\n};\n```\nSmart pointer helps you manage this object and if it is not referred anymore, release its memory.\n</br>\n\n## free( )/delete is not enough\nNow your program has such a concrete control flow that **free( )** or **delete** is called before all the possible drop out. That is great but still not enough. **free( )** and **delete** can **only release the memory where the pointer is currently pointing to but not the pointer itself!** The pointer will still point to the original memory address but the content has been already removed. In this circumstance, the value of the pointer does not equal to **NULL**, instead some random values that cannot be predicted.\n```c++\nint main() {\n    char *p = (char*) malloc(sizeof(char) * 100);\n    strcpy(p, \"hello\");\n    free(p);\n    if (p != NULL) //doesn't prevent issue\n        strcpy(p, \"world\"); // error\n}\n```\nThis pointer p is called [***dangling pointer***](https://en.wikipedia.org/wiki/Dangling_pointer) or [***wild pointer***](https://en.wikipedia.org/wiki/Dangling_pointer) and will only be erased after the whole procedure is finished or terminated. The wild pointer is really risky because of its random behavior. Imagine there is something in your room that sometimes can be observed sometimes cannot, randomly breaks your stuff but never leaves footprint. In programming it is called wild pointer, and in real life it is called [**cat**](https://en.wikipedia.org/wiki/Cat). To prevent it, we should **always set the pointer to be NULL when it is not used/the memory is released**.\n\n***Note***: when you define a pointer without setting up its initial value, that pointer will also be a **wild pointer** and has a value of some random number (which doesn't equal to **NULL**). Hence it is necessary to set the value of a pointer to be **NULL** if it cannot be asigned a value at the beginning.\n\nFor some simple pointers, they can be reasigned to **NULL** to prevent **wild pointer**, however for a pointer referring to a hierarchical object, simply setting to **NULL** cannot resolve the potential issues. For example, you are using a **`vector`** in C++ :\n```c++\nvector <string> v\nint main() {\n    for (int i=0; i<1000000; i++)\n        v.push_back(\"test\");\n    \n    cout << v.capacity() << endl;  //memory usage: 54M\n    v.clear();\n    cout << v.capacity() << endl;  //memory usage: still 54M\n}\n```\nEven though we have cleared the vector and all its elements were indeed released, the capacity of the vector is still unchanged. **`clear()`** removed all its element but cannot shrink the size of the container. The same thing happens to other containers such as **`deque`**. To handle this, before **C++ 11**, we can swap the pointers:\n```c++\nint main() {\n    ...\n    v.clear();\n    vector<string>(v).swap(v); //new a vector with the same content and swap    \n    cout << v.capacity() << endl;  //memory usage: 0\n}\n```\nafter C++ 11, it provides function **`shrink_to_fit()`** to remove the extra allocated memory.\n</br>\n\n## GC doesn't avoid memory leaks\nIt's not suprising that GC can prevent most cases of memory leaks because it is runnig in an individual thread, checking the memory regularly and removing the unreferred objects. It is so powerful that porgrammers rarely pay attention to memory management and be aware of the memory leaks. **Java** is such language which has powerful and unruly GC that can be hardly controlled (call **`System.gc()`** doesn't certainly invoke GC). It helps to manage the memory in jvm, but it cannot avoid memory leaks.\n\nThere are mainly two cases that can lead to memory leaks in Java. One is the object which has a longer lifecycle keeps a reference to another object which has a shorter lifecycle:\n```java\npublic class Sample {\n    Object object;\n    public void anymethod(){\n        object = new Object();\n        ...\n    }\n    ...\n}\n```\nIf ***object*** is only used inside ***anymethod( )***, then after stack pops ***anymethod( )***, the lifecycle of ***object*** should also be ended. But for here, because class ***Sample*** is still proceeding and keeps the reference of ***object***, ***object*** cannot be collected by GC and hence leaks the memory. The solution will be either init ***object*** inside ***anymethod( )*** (as a local varible) or set ***object*** to be ***null*** after ***anymethod*** is finished.\n\nAnother case is the use of **`HashSet`**. ***HashSet*** is the implementation of hash-table and it stores elements according to their different hash values. In order to push and withdraw the same object in the ***HashSet***, we need to override the method **`HashCode()`** so that the same object has the same hash vaule and being stored in the same place in ***HashSet***. However, if we push something into the ***HashSet*** and then change some properties of this object (those properties are most likely to be used to calculate the hashcode), the hashcode of this object may vary and when we refer this object back to our ***HashSet*** to do some operations, for example delete this object from the ***HashSet***, this object might not be found in the set and hence cannot be deleted:\n```java\n    HashSet<Obejct> set = new HashSet<Object>();\n    Object something = new Object();\n    set.add(something);\n    something.doSomethingChanges();\n    set.contains(something);  //this may return false\n    set.remove(something);  //'something' cannot be removed if the previous line returns false      \n```\n</br>\n\n## Python\n\n","source":"_posts/Memory-Leak-in-Serveral-Commonly-Used-Programming-Languages.md","raw":"---\ntitle: Memory Leaks in Serveral Commonly Used Programming Languages\ndate: 2019-05-05 15:37:22\ntags: [C++, Java, Python, NodeJS]\nphotos: [\"../images/Memory-Leaks.JPG\"]\n---\nUsually when we talk about memory leaks we are actually talking about the memory leaks in heap memory. When an object is initialized, it will be dynamically allocated to a piece of memory in the heap and ready to be manipulated. After we perform some operations and the whole procedure is finished, the object stored in heap should also be erased; however in the case of memory leak, that piece of memory is not released but still held in the heap, marked as occupied but no reference refers to it.<!-- more -->\n\nWiki's Def:\n>[**Memory leak**](https://en.wikipedia.org/wiki/Memory_leak) is a type of resource leak that occurs when a computer program incorrectly manages memory allocations in such a way that: \n- memory which is no longer needed is not released\n- an object is stored in memory but cannot be accessed by the running code\n\nWe usually encounter this issue in programming languages that don't have [**GC**](https://en.wikipedia.org/wiki/Garbage_collection_(computer_science), for example C++ and C. For such languages, we have to manage the memory by ourselves which, if not done properly, will expose the risks of memory leaks.\n</br>\n\n## This is really common in C++\nLet's take a look in C++. There are literally hundreds of ways that can cause memory leaks and most of them won't be detected during compilation and even in runtime. Only a few leaks will not have any impact on the system; however if we are running a huge application and those leaks accumulate, that will significantly reduce the real runtime performance of the whole system.\n\nWe all know that when we allocate an object, we have to release the memory if this object is not used anymore. The way we release the memory is simply call the buid-in function **`free()`** or **`delete[]`**. However in C++ the procedure can exit anywhere. An exception can be thrown in the half way so that the code doesn't ever reach the line to release memory:\n```c++\nint sample(int n) {\n    void  *ptr = malloc(16);\n    if (n)\n        return -1; //memory leak here\n    free(ptr);\n    return 0;\n}\n```\nor:\n```c++\nclass Sample {\n    public:\n        init() { int *n = new int;  throw any_exception(); }\n        ~init() { delete n; }\n    private:\n        int *n;\n};\nSample *n = new Sample; //memory leak here\n```\nThe solution to the above examples is also really simple: check control flows and **do remember to call the destructor before anywhere the procedure may exit**. Well if you want to do it in a fancy way, you can use ***smart pointer*** alternatively:\n```c++\nclass Sample {\n    public:\n        init() { n = std::make_shared<int>(new int) }\n        ~init() {}\n    private:\n        std::shared_ptr<int> n;\n};\n```\nSmart pointer helps you manage this object and if it is not referred anymore, release its memory.\n</br>\n\n## free( )/delete is not enough\nNow your program has such a concrete control flow that **free( )** or **delete** is called before all the possible drop out. That is great but still not enough. **free( )** and **delete** can **only release the memory where the pointer is currently pointing to but not the pointer itself!** The pointer will still point to the original memory address but the content has been already removed. In this circumstance, the value of the pointer does not equal to **NULL**, instead some random values that cannot be predicted.\n```c++\nint main() {\n    char *p = (char*) malloc(sizeof(char) * 100);\n    strcpy(p, \"hello\");\n    free(p);\n    if (p != NULL) //doesn't prevent issue\n        strcpy(p, \"world\"); // error\n}\n```\nThis pointer p is called [***dangling pointer***](https://en.wikipedia.org/wiki/Dangling_pointer) or [***wild pointer***](https://en.wikipedia.org/wiki/Dangling_pointer) and will only be erased after the whole procedure is finished or terminated. The wild pointer is really risky because of its random behavior. Imagine there is something in your room that sometimes can be observed sometimes cannot, randomly breaks your stuff but never leaves footprint. In programming it is called wild pointer, and in real life it is called [**cat**](https://en.wikipedia.org/wiki/Cat). To prevent it, we should **always set the pointer to be NULL when it is not used/the memory is released**.\n\n***Note***: when you define a pointer without setting up its initial value, that pointer will also be a **wild pointer** and has a value of some random number (which doesn't equal to **NULL**). Hence it is necessary to set the value of a pointer to be **NULL** if it cannot be asigned a value at the beginning.\n\nFor some simple pointers, they can be reasigned to **NULL** to prevent **wild pointer**, however for a pointer referring to a hierarchical object, simply setting to **NULL** cannot resolve the potential issues. For example, you are using a **`vector`** in C++ :\n```c++\nvector <string> v\nint main() {\n    for (int i=0; i<1000000; i++)\n        v.push_back(\"test\");\n    \n    cout << v.capacity() << endl;  //memory usage: 54M\n    v.clear();\n    cout << v.capacity() << endl;  //memory usage: still 54M\n}\n```\nEven though we have cleared the vector and all its elements were indeed released, the capacity of the vector is still unchanged. **`clear()`** removed all its element but cannot shrink the size of the container. The same thing happens to other containers such as **`deque`**. To handle this, before **C++ 11**, we can swap the pointers:\n```c++\nint main() {\n    ...\n    v.clear();\n    vector<string>(v).swap(v); //new a vector with the same content and swap    \n    cout << v.capacity() << endl;  //memory usage: 0\n}\n```\nafter C++ 11, it provides function **`shrink_to_fit()`** to remove the extra allocated memory.\n</br>\n\n## GC doesn't avoid memory leaks\nIt's not suprising that GC can prevent most cases of memory leaks because it is runnig in an individual thread, checking the memory regularly and removing the unreferred objects. It is so powerful that porgrammers rarely pay attention to memory management and be aware of the memory leaks. **Java** is such language which has powerful and unruly GC that can be hardly controlled (call **`System.gc()`** doesn't certainly invoke GC). It helps to manage the memory in jvm, but it cannot avoid memory leaks.\n\nThere are mainly two cases that can lead to memory leaks in Java. One is the object which has a longer lifecycle keeps a reference to another object which has a shorter lifecycle:\n```java\npublic class Sample {\n    Object object;\n    public void anymethod(){\n        object = new Object();\n        ...\n    }\n    ...\n}\n```\nIf ***object*** is only used inside ***anymethod( )***, then after stack pops ***anymethod( )***, the lifecycle of ***object*** should also be ended. But for here, because class ***Sample*** is still proceeding and keeps the reference of ***object***, ***object*** cannot be collected by GC and hence leaks the memory. The solution will be either init ***object*** inside ***anymethod( )*** (as a local varible) or set ***object*** to be ***null*** after ***anymethod*** is finished.\n\nAnother case is the use of **`HashSet`**. ***HashSet*** is the implementation of hash-table and it stores elements according to their different hash values. In order to push and withdraw the same object in the ***HashSet***, we need to override the method **`HashCode()`** so that the same object has the same hash vaule and being stored in the same place in ***HashSet***. However, if we push something into the ***HashSet*** and then change some properties of this object (those properties are most likely to be used to calculate the hashcode), the hashcode of this object may vary and when we refer this object back to our ***HashSet*** to do some operations, for example delete this object from the ***HashSet***, this object might not be found in the set and hence cannot be deleted:\n```java\n    HashSet<Obejct> set = new HashSet<Object>();\n    Object something = new Object();\n    set.add(something);\n    something.doSomethingChanges();\n    set.contains(something);  //this may return false\n    set.remove(something);  //'something' cannot be removed if the previous line returns false      \n```\n</br>\n\n## Python\n\n","slug":"Memory-Leak-in-Serveral-Commonly-Used-Programming-Languages","published":1,"updated":"2019-05-10T10:13:39.539Z","comments":1,"layout":"post","link":"","_id":"cjvkl7rry0006seaort6wvbm2","content":"<p>Usually when we talk about memory leaks we are actually talking about the memory leaks in heap memory. When an object is initialized, it will be dynamically allocated to a piece of memory in the heap and ready to be manipulated. After we perform some operations and the whole procedure is finished, the object stored in heap should also be erased; however in the case of memory leak, that piece of memory is not released but still held in the heap, marked as occupied but no reference refers to it.<a id=\"more\"></a></p>\n<p>Wiki’s Def:</p>\n<blockquote>\n<p><a href=\"https://en.wikipedia.org/wiki/Memory_leak\" target=\"_blank\" rel=\"noopener\"><strong>Memory leak</strong></a> is a type of resource leak that occurs when a computer program incorrectly manages memory allocations in such a way that: </p>\n<ul>\n<li>memory which is no longer needed is not released</li>\n<li>an object is stored in memory but cannot be accessed by the running code</li>\n</ul>\n</blockquote>\n<p>We usually encounter this issue in programming languages that don’t have <a href=\"https://en.wikipedia.org/wiki/Garbage_collection_(computer_science\" target=\"_blank\" rel=\"noopener\"><strong>GC</strong></a>, for example C++ and C. For such languages, we have to manage the memory by ourselves which, if not done properly, will expose the risks of memory leaks.<br><br></p>\n<h2 id=\"This-is-really-common-in-C\"><a href=\"#This-is-really-common-in-C\" class=\"headerlink\" title=\"This is really common in C++\"></a>This is really common in C++</h2><p>Let’s take a look in C++. There are literally hundreds of ways that can cause memory leaks and most of them won’t be detected during compilation and even in runtime. Only a few leaks will not have any impact on the system; however if we are running a huge application and those leaks accumulate, that will significantly reduce the real runtime performance of the whole system.</p>\n<p>We all know that when we allocate an object, we have to release the memory if this object is not used anymore. The way we release the memory is simply call the buid-in function <strong><code>free()</code></strong> or <strong><code>delete[]</code></strong>. However in C++ the procedure can exit anywhere. An exception can be thrown in the half way so that the code doesn’t ever reach the line to release memory:</p>\n<pre><code class=\"c++\">int sample(int n) {\n    void  *ptr = malloc(16);\n    if (n)\n        return -1; //memory leak here\n    free(ptr);\n    return 0;\n}\n</code></pre>\n<p>or:</p>\n<pre><code class=\"c++\">class Sample {\n    public:\n        init() { int *n = new int;  throw any_exception(); }\n        ~init() { delete n; }\n    private:\n        int *n;\n};\nSample *n = new Sample; //memory leak here\n</code></pre>\n<p>The solution to the above examples is also really simple: check control flows and <strong>do remember to call the destructor before anywhere the procedure may exit</strong>. Well if you want to do it in a fancy way, you can use <strong><em>smart pointer</em></strong> alternatively:</p>\n<pre><code class=\"c++\">class Sample {\n    public:\n        init() { n = std::make_shared&lt;int&gt;(new int) }\n        ~init() {}\n    private:\n        std::shared_ptr&lt;int&gt; n;\n};\n</code></pre>\n<p>Smart pointer helps you manage this object and if it is not referred anymore, release its memory.<br><br></p>\n<h2 id=\"free-delete-is-not-enough\"><a href=\"#free-delete-is-not-enough\" class=\"headerlink\" title=\"free( )/delete is not enough\"></a>free( )/delete is not enough</h2><p>Now your program has such a concrete control flow that <strong>free( )</strong> or <strong>delete</strong> is called before all the possible drop out. That is great but still not enough. <strong>free( )</strong> and <strong>delete</strong> can <strong>only release the memory where the pointer is currently pointing to but not the pointer itself!</strong> The pointer will still point to the original memory address but the content has been already removed. In this circumstance, the value of the pointer does not equal to <strong>NULL</strong>, instead some random values that cannot be predicted.</p>\n<pre><code class=\"c++\">int main() {\n    char *p = (char*) malloc(sizeof(char) * 100);\n    strcpy(p, &quot;hello&quot;);\n    free(p);\n    if (p != NULL) //doesn&#39;t prevent issue\n        strcpy(p, &quot;world&quot;); // error\n}\n</code></pre>\n<p>This pointer p is called <a href=\"https://en.wikipedia.org/wiki/Dangling_pointer\" target=\"_blank\" rel=\"noopener\"><strong><em>dangling pointer</em></strong></a> or <a href=\"https://en.wikipedia.org/wiki/Dangling_pointer\" target=\"_blank\" rel=\"noopener\"><strong><em>wild pointer</em></strong></a> and will only be erased after the whole procedure is finished or terminated. The wild pointer is really risky because of its random behavior. Imagine there is something in your room that sometimes can be observed sometimes cannot, randomly breaks your stuff but never leaves footprint. In programming it is called wild pointer, and in real life it is called <a href=\"https://en.wikipedia.org/wiki/Cat\" target=\"_blank\" rel=\"noopener\"><strong>cat</strong></a>. To prevent it, we should <strong>always set the pointer to be NULL when it is not used/the memory is released</strong>.</p>\n<p><strong><em>Note</em></strong>: when you define a pointer without setting up its initial value, that pointer will also be a <strong>wild pointer</strong> and has a value of some random number (which doesn’t equal to <strong>NULL</strong>). Hence it is necessary to set the value of a pointer to be <strong>NULL</strong> if it cannot be asigned a value at the beginning.</p>\n<p>For some simple pointers, they can be reasigned to <strong>NULL</strong> to prevent <strong>wild pointer</strong>, however for a pointer referring to a hierarchical object, simply setting to <strong>NULL</strong> cannot resolve the potential issues. For example, you are using a <strong><code>vector</code></strong> in C++ :</p>\n<pre><code class=\"c++\">vector &lt;string&gt; v\nint main() {\n    for (int i=0; i&lt;1000000; i++)\n        v.push_back(&quot;test&quot;);\n\n    cout &lt;&lt; v.capacity() &lt;&lt; endl;  //memory usage: 54M\n    v.clear();\n    cout &lt;&lt; v.capacity() &lt;&lt; endl;  //memory usage: still 54M\n}\n</code></pre>\n<p>Even though we have cleared the vector and all its elements were indeed released, the capacity of the vector is still unchanged. <strong><code>clear()</code></strong> removed all its element but cannot shrink the size of the container. The same thing happens to other containers such as <strong><code>deque</code></strong>. To handle this, before <strong>C++ 11</strong>, we can swap the pointers:</p>\n<pre><code class=\"c++\">int main() {\n    ...\n    v.clear();\n    vector&lt;string&gt;(v).swap(v); //new a vector with the same content and swap    \n    cout &lt;&lt; v.capacity() &lt;&lt; endl;  //memory usage: 0\n}\n</code></pre>\n<p>after C++ 11, it provides function <strong><code>shrink_to_fit()</code></strong> to remove the extra allocated memory.<br><br></p>\n<h2 id=\"GC-doesn’t-avoid-memory-leaks\"><a href=\"#GC-doesn’t-avoid-memory-leaks\" class=\"headerlink\" title=\"GC doesn’t avoid memory leaks\"></a>GC doesn’t avoid memory leaks</h2><p>It’s not suprising that GC can prevent most cases of memory leaks because it is runnig in an individual thread, checking the memory regularly and removing the unreferred objects. It is so powerful that porgrammers rarely pay attention to memory management and be aware of the memory leaks. <strong>Java</strong> is such language which has powerful and unruly GC that can be hardly controlled (call <strong><code>System.gc()</code></strong> doesn’t certainly invoke GC). It helps to manage the memory in jvm, but it cannot avoid memory leaks.</p>\n<p>There are mainly two cases that can lead to memory leaks in Java. One is the object which has a longer lifecycle keeps a reference to another object which has a shorter lifecycle:</p>\n<pre><code class=\"java\">public class Sample {\n    Object object;\n    public void anymethod(){\n        object = new Object();\n        ...\n    }\n    ...\n}\n</code></pre>\n<p>If <strong><em>object</em></strong> is only used inside <strong><em>anymethod( )</em></strong>, then after stack pops <strong><em>anymethod( )</em></strong>, the lifecycle of <strong><em>object</em></strong> should also be ended. But for here, because class <strong><em>Sample</em></strong> is still proceeding and keeps the reference of <strong><em>object</em></strong>, <strong><em>object</em></strong> cannot be collected by GC and hence leaks the memory. The solution will be either init <strong><em>object</em></strong> inside <strong><em>anymethod( )</em></strong> (as a local varible) or set <strong><em>object</em></strong> to be <strong><em>null</em></strong> after <strong><em>anymethod</em></strong> is finished.</p>\n<p>Another case is the use of <strong><code>HashSet</code></strong>. <strong><em>HashSet</em></strong> is the implementation of hash-table and it stores elements according to their different hash values. In order to push and withdraw the same object in the <strong><em>HashSet</em></strong>, we need to override the method <strong><code>HashCode()</code></strong> so that the same object has the same hash vaule and being stored in the same place in <strong><em>HashSet</em></strong>. However, if we push something into the <strong><em>HashSet</em></strong> and then change some properties of this object (those properties are most likely to be used to calculate the hashcode), the hashcode of this object may vary and when we refer this object back to our <strong><em>HashSet</em></strong> to do some operations, for example delete this object from the <strong><em>HashSet</em></strong>, this object might not be found in the set and hence cannot be deleted:</p>\n<pre><code class=\"java\">    HashSet&lt;Obejct&gt; set = new HashSet&lt;Object&gt;();\n    Object something = new Object();\n    set.add(something);\n    something.doSomethingChanges();\n    set.contains(something);  //this may return false\n    set.remove(something);  //&#39;something&#39; cannot be removed if the previous line returns false      \n</code></pre>\n<p><br></p>\n<h2 id=\"Python\"><a href=\"#Python\" class=\"headerlink\" title=\"Python\"></a>Python</h2>","site":{"data":{}},"excerpt":"<p>Usually when we talk about memory leaks we are actually talking about the memory leaks in heap memory. When an object is initialized, it will be dynamically allocated to a piece of memory in the heap and ready to be manipulated. After we perform some operations and the whole procedure is finished, the object stored in heap should also be erased; however in the case of memory leak, that piece of memory is not released but still held in the heap, marked as occupied but no reference refers to it.","more":"</p>\n<p>Wiki’s Def:</p>\n<blockquote>\n<p><a href=\"https://en.wikipedia.org/wiki/Memory_leak\" target=\"_blank\" rel=\"noopener\"><strong>Memory leak</strong></a> is a type of resource leak that occurs when a computer program incorrectly manages memory allocations in such a way that: </p>\n<ul>\n<li>memory which is no longer needed is not released</li>\n<li>an object is stored in memory but cannot be accessed by the running code</li>\n</ul>\n</blockquote>\n<p>We usually encounter this issue in programming languages that don’t have <a href=\"https://en.wikipedia.org/wiki/Garbage_collection_(computer_science\" target=\"_blank\" rel=\"noopener\"><strong>GC</strong></a>, for example C++ and C. For such languages, we have to manage the memory by ourselves which, if not done properly, will expose the risks of memory leaks.<br><br></p>\n<h2 id=\"This-is-really-common-in-C\"><a href=\"#This-is-really-common-in-C\" class=\"headerlink\" title=\"This is really common in C++\"></a>This is really common in C++</h2><p>Let’s take a look in C++. There are literally hundreds of ways that can cause memory leaks and most of them won’t be detected during compilation and even in runtime. Only a few leaks will not have any impact on the system; however if we are running a huge application and those leaks accumulate, that will significantly reduce the real runtime performance of the whole system.</p>\n<p>We all know that when we allocate an object, we have to release the memory if this object is not used anymore. The way we release the memory is simply call the buid-in function <strong><code>free()</code></strong> or <strong><code>delete[]</code></strong>. However in C++ the procedure can exit anywhere. An exception can be thrown in the half way so that the code doesn’t ever reach the line to release memory:</p>\n<pre><code class=\"c++\">int sample(int n) {\n    void  *ptr = malloc(16);\n    if (n)\n        return -1; //memory leak here\n    free(ptr);\n    return 0;\n}\n</code></pre>\n<p>or:</p>\n<pre><code class=\"c++\">class Sample {\n    public:\n        init() { int *n = new int;  throw any_exception(); }\n        ~init() { delete n; }\n    private:\n        int *n;\n};\nSample *n = new Sample; //memory leak here\n</code></pre>\n<p>The solution to the above examples is also really simple: check control flows and <strong>do remember to call the destructor before anywhere the procedure may exit</strong>. Well if you want to do it in a fancy way, you can use <strong><em>smart pointer</em></strong> alternatively:</p>\n<pre><code class=\"c++\">class Sample {\n    public:\n        init() { n = std::make_shared&lt;int&gt;(new int) }\n        ~init() {}\n    private:\n        std::shared_ptr&lt;int&gt; n;\n};\n</code></pre>\n<p>Smart pointer helps you manage this object and if it is not referred anymore, release its memory.<br><br></p>\n<h2 id=\"free-delete-is-not-enough\"><a href=\"#free-delete-is-not-enough\" class=\"headerlink\" title=\"free( )/delete is not enough\"></a>free( )/delete is not enough</h2><p>Now your program has such a concrete control flow that <strong>free( )</strong> or <strong>delete</strong> is called before all the possible drop out. That is great but still not enough. <strong>free( )</strong> and <strong>delete</strong> can <strong>only release the memory where the pointer is currently pointing to but not the pointer itself!</strong> The pointer will still point to the original memory address but the content has been already removed. In this circumstance, the value of the pointer does not equal to <strong>NULL</strong>, instead some random values that cannot be predicted.</p>\n<pre><code class=\"c++\">int main() {\n    char *p = (char*) malloc(sizeof(char) * 100);\n    strcpy(p, &quot;hello&quot;);\n    free(p);\n    if (p != NULL) //doesn&#39;t prevent issue\n        strcpy(p, &quot;world&quot;); // error\n}\n</code></pre>\n<p>This pointer p is called <a href=\"https://en.wikipedia.org/wiki/Dangling_pointer\" target=\"_blank\" rel=\"noopener\"><strong><em>dangling pointer</em></strong></a> or <a href=\"https://en.wikipedia.org/wiki/Dangling_pointer\" target=\"_blank\" rel=\"noopener\"><strong><em>wild pointer</em></strong></a> and will only be erased after the whole procedure is finished or terminated. The wild pointer is really risky because of its random behavior. Imagine there is something in your room that sometimes can be observed sometimes cannot, randomly breaks your stuff but never leaves footprint. In programming it is called wild pointer, and in real life it is called <a href=\"https://en.wikipedia.org/wiki/Cat\" target=\"_blank\" rel=\"noopener\"><strong>cat</strong></a>. To prevent it, we should <strong>always set the pointer to be NULL when it is not used/the memory is released</strong>.</p>\n<p><strong><em>Note</em></strong>: when you define a pointer without setting up its initial value, that pointer will also be a <strong>wild pointer</strong> and has a value of some random number (which doesn’t equal to <strong>NULL</strong>). Hence it is necessary to set the value of a pointer to be <strong>NULL</strong> if it cannot be asigned a value at the beginning.</p>\n<p>For some simple pointers, they can be reasigned to <strong>NULL</strong> to prevent <strong>wild pointer</strong>, however for a pointer referring to a hierarchical object, simply setting to <strong>NULL</strong> cannot resolve the potential issues. For example, you are using a <strong><code>vector</code></strong> in C++ :</p>\n<pre><code class=\"c++\">vector &lt;string&gt; v\nint main() {\n    for (int i=0; i&lt;1000000; i++)\n        v.push_back(&quot;test&quot;);\n\n    cout &lt;&lt; v.capacity() &lt;&lt; endl;  //memory usage: 54M\n    v.clear();\n    cout &lt;&lt; v.capacity() &lt;&lt; endl;  //memory usage: still 54M\n}\n</code></pre>\n<p>Even though we have cleared the vector and all its elements were indeed released, the capacity of the vector is still unchanged. <strong><code>clear()</code></strong> removed all its element but cannot shrink the size of the container. The same thing happens to other containers such as <strong><code>deque</code></strong>. To handle this, before <strong>C++ 11</strong>, we can swap the pointers:</p>\n<pre><code class=\"c++\">int main() {\n    ...\n    v.clear();\n    vector&lt;string&gt;(v).swap(v); //new a vector with the same content and swap    \n    cout &lt;&lt; v.capacity() &lt;&lt; endl;  //memory usage: 0\n}\n</code></pre>\n<p>after C++ 11, it provides function <strong><code>shrink_to_fit()</code></strong> to remove the extra allocated memory.<br><br></p>\n<h2 id=\"GC-doesn’t-avoid-memory-leaks\"><a href=\"#GC-doesn’t-avoid-memory-leaks\" class=\"headerlink\" title=\"GC doesn’t avoid memory leaks\"></a>GC doesn’t avoid memory leaks</h2><p>It’s not suprising that GC can prevent most cases of memory leaks because it is runnig in an individual thread, checking the memory regularly and removing the unreferred objects. It is so powerful that porgrammers rarely pay attention to memory management and be aware of the memory leaks. <strong>Java</strong> is such language which has powerful and unruly GC that can be hardly controlled (call <strong><code>System.gc()</code></strong> doesn’t certainly invoke GC). It helps to manage the memory in jvm, but it cannot avoid memory leaks.</p>\n<p>There are mainly two cases that can lead to memory leaks in Java. One is the object which has a longer lifecycle keeps a reference to another object which has a shorter lifecycle:</p>\n<pre><code class=\"java\">public class Sample {\n    Object object;\n    public void anymethod(){\n        object = new Object();\n        ...\n    }\n    ...\n}\n</code></pre>\n<p>If <strong><em>object</em></strong> is only used inside <strong><em>anymethod( )</em></strong>, then after stack pops <strong><em>anymethod( )</em></strong>, the lifecycle of <strong><em>object</em></strong> should also be ended. But for here, because class <strong><em>Sample</em></strong> is still proceeding and keeps the reference of <strong><em>object</em></strong>, <strong><em>object</em></strong> cannot be collected by GC and hence leaks the memory. The solution will be either init <strong><em>object</em></strong> inside <strong><em>anymethod( )</em></strong> (as a local varible) or set <strong><em>object</em></strong> to be <strong><em>null</em></strong> after <strong><em>anymethod</em></strong> is finished.</p>\n<p>Another case is the use of <strong><code>HashSet</code></strong>. <strong><em>HashSet</em></strong> is the implementation of hash-table and it stores elements according to their different hash values. In order to push and withdraw the same object in the <strong><em>HashSet</em></strong>, we need to override the method <strong><code>HashCode()</code></strong> so that the same object has the same hash vaule and being stored in the same place in <strong><em>HashSet</em></strong>. However, if we push something into the <strong><em>HashSet</em></strong> and then change some properties of this object (those properties are most likely to be used to calculate the hashcode), the hashcode of this object may vary and when we refer this object back to our <strong><em>HashSet</em></strong> to do some operations, for example delete this object from the <strong><em>HashSet</em></strong>, this object might not be found in the set and hence cannot be deleted:</p>\n<pre><code class=\"java\">    HashSet&lt;Obejct&gt; set = new HashSet&lt;Object&gt;();\n    Object something = new Object();\n    set.add(something);\n    something.doSomethingChanges();\n    set.contains(something);  //this may return false\n    set.remove(something);  //&#39;something&#39; cannot be removed if the previous line returns false      \n</code></pre>\n<p><br></p>\n<h2 id=\"Python\"><a href=\"#Python\" class=\"headerlink\" title=\"Python\"></a>Python</h2>"},{"title":"Prefix Notation","date":"2019-04-30T02:11:21.000Z","photos":["../images/lisp.JPG"],"_content":"```python\n( 20 + 5 )\n( 16 / 4 )\n```\nSuch expressions which denote procedures, are called ***combinations***. The left and the right elements are called ***operands***, and the element in the middle to indicate the operation is called ***operator***. This is the most common style we have seen by now; however there is another way to construct a procedure known as ***prefix notation***:\n```python\n( + 20 5 )\n( / 16 4 )\n```\nInstead of injecting the operator between operands, which is a more human readable style, the prefix notation requires the operator always to be at the left most.<!-- more -->\n\nconditions:\n```python\n( define ( abs x )\n    ( cond (( > x 0 ) x )\n           (( = x 0 ) 0 )\n           (( < x 0 ) ( - x ))))\n```\nThe general form can be expressed as:\n>( cond (<\\P1> <\\E1>)\n>       (<\\P2> <\\E2>)\n>            ...\n>       (<\\Pn> <\\En>))\n\nIf none of them is evaluated to be **true**, then the value of the **cond** will be **undefined**. It can also be simplified by using ***else***:\n```python\n( define ( abs x )\n    ( cond (( < x 0 ) ( - x ))\n           ( else  x )))\n```\nIf there is only two ***predicates*** (the expression to be interpreted as either true of false), then it can use a special form ***if***:\n```python\n( define ( abs x )\n    ( if ( < x 0 )\n         ( - x )\n         x ))\n```\nThe general form of an ***if*** expression is:\n>( if <\\predicate> <\\consequent> <\\alternative> )\n\nThe logic operators:\n>( and <\\E1> ... <\\En> )\n>( or <\\E1> ... <\\En> )\n>( not <E> )\n\nThen use the logic operators to define a predicate to evaluate if a number id larger or equal to the other one:\n```python\n( define ( >= x y )\n    ( or ( > x y ) ( = x y ))\n```\nThat is all the syntax, **there is no loop in a functional programming language!**</br></br>\n## Recursion\nConsidering the factorial function:\n> n! = n ⋅ (n-1) ⋅ (n-2) ⋅ ... ⋅2⋅1\n\nWhich can be computed as:\n> n! = n ⋅ (n-1)!\n\nIf we end it up with **1!**, then simply output **1**. Then the factorial function can be implemented in ***linear recursion***:\n```python\n( define ( factorial n )\n    ( if ( = n 1 )\n        1\n        ( * n ( factorial ( - n 1 )))))\n```\n***Linear recursion*** defines that the computation chains of operations is proportional to n and hence grows linearly. There is also another pattern of recursion, known as ***Tree Recursion***. The best example will be the Fibonacci series, in which each element is the sum of the previous two:\n```python\n( define ( fib n )\n    ( cond ( = n 0 ) 0 )\n           ( = n 1 ) 1 )\n           ( else ( + ( fib ( - n 1 ) )\n                      ( fib ( - n 2 ) )))))\n```\nYou may find out that this procedure is not really efficient because to compute **fib( - n 1)**, **fib( - n 2)** has to be computed one more time which causes duplicated work.\n![Tree Recursion](../images/treeRecursion.png)\nTherefore, instead of ***Tree Recursion***, let's try to convert it to be ***Linear Recursion***. Reasign the sum of **a** and **b** to **a**, and the previous **a** to **b**:\n```python\n( define ( fib n )\n    ( iterate 1 0 n ))\n\n( define ( iterate a b count )\n    ( if ( = count 0 )\n        b\n        ( iterate ( + a b ) a ( - count 1 ))))\n```\n</br>\n## Lambda\nInstead of defining some trivial procedures so that we can pass them as arguments of the other procedures, functional programming provides ***Lambda Expression***:\n>( lambda ( <\\formal-param> ) <\\body> )\n\nFor instance,\n```python\n( define ( Add a b ) ( + a b ))\n```\ncan be written as:\n```python\n( define add ( lambda ( a b ) ( + a b )))\n```\nAnd operators can also be represented by ***Lambda Expression***:\n```python\n(( lambda ( a b ) ( + ( * a a ) ( * b b ))) 2 3 )\n```\nAnother use of ***Lambda Expression*** is creating local variables. An expression can be binded with a specific name by using keyword ***let***. The above example then can be interpreted as:\n```python\n( define ( sumsqr x y )\n    ( let ( a ( * x x ))\n          ( b ( * y y ))\n        ( + a b )))\n```\n***Note:*** The scope of a variable specified by a ***let*** is only applied to the **body** of the ***let***. For example, if the evalue of **x** is **2**, then the expression:\n```python\n( let (( x 3 )\n        ( y ( + x 2 )))\n    ( * x y ))\n```\nThe value of **y** will be **4** as being outside of the **let** body, and the output will be **3 * 4 = 12**. It seems like ***let*** is really similar to ***define***; however, in the most cases, we much prefer using ***let*** and only apply ***define*** to **internal procedures**.","source":"_posts/Prefix-Notation.md","raw":"---\ntitle: Prefix Notation\ndate: 2019-04-30 11:11:21\ntags: [Lisp, Scheme, Prefix Notation, Functional Programming]\nphotos: [\"../images/lisp.JPG\"]\n---\n```python\n( 20 + 5 )\n( 16 / 4 )\n```\nSuch expressions which denote procedures, are called ***combinations***. The left and the right elements are called ***operands***, and the element in the middle to indicate the operation is called ***operator***. This is the most common style we have seen by now; however there is another way to construct a procedure known as ***prefix notation***:\n```python\n( + 20 5 )\n( / 16 4 )\n```\nInstead of injecting the operator between operands, which is a more human readable style, the prefix notation requires the operator always to be at the left most.<!-- more -->\n\nconditions:\n```python\n( define ( abs x )\n    ( cond (( > x 0 ) x )\n           (( = x 0 ) 0 )\n           (( < x 0 ) ( - x ))))\n```\nThe general form can be expressed as:\n>( cond (<\\P1> <\\E1>)\n>       (<\\P2> <\\E2>)\n>            ...\n>       (<\\Pn> <\\En>))\n\nIf none of them is evaluated to be **true**, then the value of the **cond** will be **undefined**. It can also be simplified by using ***else***:\n```python\n( define ( abs x )\n    ( cond (( < x 0 ) ( - x ))\n           ( else  x )))\n```\nIf there is only two ***predicates*** (the expression to be interpreted as either true of false), then it can use a special form ***if***:\n```python\n( define ( abs x )\n    ( if ( < x 0 )\n         ( - x )\n         x ))\n```\nThe general form of an ***if*** expression is:\n>( if <\\predicate> <\\consequent> <\\alternative> )\n\nThe logic operators:\n>( and <\\E1> ... <\\En> )\n>( or <\\E1> ... <\\En> )\n>( not <E> )\n\nThen use the logic operators to define a predicate to evaluate if a number id larger or equal to the other one:\n```python\n( define ( >= x y )\n    ( or ( > x y ) ( = x y ))\n```\nThat is all the syntax, **there is no loop in a functional programming language!**</br></br>\n## Recursion\nConsidering the factorial function:\n> n! = n ⋅ (n-1) ⋅ (n-2) ⋅ ... ⋅2⋅1\n\nWhich can be computed as:\n> n! = n ⋅ (n-1)!\n\nIf we end it up with **1!**, then simply output **1**. Then the factorial function can be implemented in ***linear recursion***:\n```python\n( define ( factorial n )\n    ( if ( = n 1 )\n        1\n        ( * n ( factorial ( - n 1 )))))\n```\n***Linear recursion*** defines that the computation chains of operations is proportional to n and hence grows linearly. There is also another pattern of recursion, known as ***Tree Recursion***. The best example will be the Fibonacci series, in which each element is the sum of the previous two:\n```python\n( define ( fib n )\n    ( cond ( = n 0 ) 0 )\n           ( = n 1 ) 1 )\n           ( else ( + ( fib ( - n 1 ) )\n                      ( fib ( - n 2 ) )))))\n```\nYou may find out that this procedure is not really efficient because to compute **fib( - n 1)**, **fib( - n 2)** has to be computed one more time which causes duplicated work.\n![Tree Recursion](../images/treeRecursion.png)\nTherefore, instead of ***Tree Recursion***, let's try to convert it to be ***Linear Recursion***. Reasign the sum of **a** and **b** to **a**, and the previous **a** to **b**:\n```python\n( define ( fib n )\n    ( iterate 1 0 n ))\n\n( define ( iterate a b count )\n    ( if ( = count 0 )\n        b\n        ( iterate ( + a b ) a ( - count 1 ))))\n```\n</br>\n## Lambda\nInstead of defining some trivial procedures so that we can pass them as arguments of the other procedures, functional programming provides ***Lambda Expression***:\n>( lambda ( <\\formal-param> ) <\\body> )\n\nFor instance,\n```python\n( define ( Add a b ) ( + a b ))\n```\ncan be written as:\n```python\n( define add ( lambda ( a b ) ( + a b )))\n```\nAnd operators can also be represented by ***Lambda Expression***:\n```python\n(( lambda ( a b ) ( + ( * a a ) ( * b b ))) 2 3 )\n```\nAnother use of ***Lambda Expression*** is creating local variables. An expression can be binded with a specific name by using keyword ***let***. The above example then can be interpreted as:\n```python\n( define ( sumsqr x y )\n    ( let ( a ( * x x ))\n          ( b ( * y y ))\n        ( + a b )))\n```\n***Note:*** The scope of a variable specified by a ***let*** is only applied to the **body** of the ***let***. For example, if the evalue of **x** is **2**, then the expression:\n```python\n( let (( x 3 )\n        ( y ( + x 2 )))\n    ( * x y ))\n```\nThe value of **y** will be **4** as being outside of the **let** body, and the output will be **3 * 4 = 12**. It seems like ***let*** is really similar to ***define***; however, in the most cases, we much prefer using ***let*** and only apply ***define*** to **internal procedures**.","slug":"Prefix-Notation","published":1,"updated":"2019-05-10T08:46:16.855Z","comments":1,"layout":"post","link":"","_id":"cjvkl7rrz0007seaozqmw76jr","content":"<pre><code class=\"python\">( 20 + 5 )\n( 16 / 4 )\n</code></pre>\n<p>Such expressions which denote procedures, are called <strong><em>combinations</em></strong>. The left and the right elements are called <strong><em>operands</em></strong>, and the element in the middle to indicate the operation is called <strong><em>operator</em></strong>. This is the most common style we have seen by now; however there is another way to construct a procedure known as <strong><em>prefix notation</em></strong>:</p>\n<pre><code class=\"python\">( + 20 5 )\n( / 16 4 )\n</code></pre>\n<p>Instead of injecting the operator between operands, which is a more human readable style, the prefix notation requires the operator always to be at the left most.<a id=\"more\"></a></p>\n<p>conditions:</p>\n<pre><code class=\"python\">( define ( abs x )\n    ( cond (( &gt; x 0 ) x )\n           (( = x 0 ) 0 )\n           (( &lt; x 0 ) ( - x ))))\n</code></pre>\n<p>The general form can be expressed as:</p>\n<blockquote>\n<p>( cond (&lt;\\P1&gt; &lt;\\E1&gt;)<br>      (&lt;\\P2&gt; &lt;\\E2&gt;)<br>           …<br>      (&lt;\\Pn&gt; &lt;\\En&gt;))</p>\n</blockquote>\n<p>If none of them is evaluated to be <strong>true</strong>, then the value of the <strong>cond</strong> will be <strong>undefined</strong>. It can also be simplified by using <strong><em>else</em></strong>:</p>\n<pre><code class=\"python\">( define ( abs x )\n    ( cond (( &lt; x 0 ) ( - x ))\n           ( else  x )))\n</code></pre>\n<p>If there is only two <strong><em>predicates</em></strong> (the expression to be interpreted as either true of false), then it can use a special form <strong><em>if</em></strong>:</p>\n<pre><code class=\"python\">( define ( abs x )\n    ( if ( &lt; x 0 )\n         ( - x )\n         x ))\n</code></pre>\n<p>The general form of an <strong><em>if</em></strong> expression is:</p>\n<blockquote>\n<p>( if &lt;\\predicate&gt; &lt;\\consequent&gt; &lt;\\alternative&gt; )</p>\n</blockquote>\n<p>The logic operators:</p>\n<blockquote>\n<p>( and &lt;\\E1&gt; … &lt;\\En&gt; )<br>( or &lt;\\E1&gt; … &lt;\\En&gt; )<br>( not <e> )</e></p>\n</blockquote>\n<p>Then use the logic operators to define a predicate to evaluate if a number id larger or equal to the other one:</p>\n<pre><code class=\"python\">( define ( &gt;= x y )\n    ( or ( &gt; x y ) ( = x y ))\n</code></pre>\n<p>That is all the syntax, <strong>there is no loop in a functional programming language!</strong><br><br></p>\n<h2 id=\"Recursion\"><a href=\"#Recursion\" class=\"headerlink\" title=\"Recursion\"></a>Recursion</h2><p>Considering the factorial function:</p>\n<blockquote>\n<p>n! = n ⋅ (n-1) ⋅ (n-2) ⋅ … ⋅2⋅1</p>\n</blockquote>\n<p>Which can be computed as:</p>\n<blockquote>\n<p>n! = n ⋅ (n-1)!</p>\n</blockquote>\n<p>If we end it up with <strong>1!</strong>, then simply output <strong>1</strong>. Then the factorial function can be implemented in <strong><em>linear recursion</em></strong>:</p>\n<pre><code class=\"python\">( define ( factorial n )\n    ( if ( = n 1 )\n        1\n        ( * n ( factorial ( - n 1 )))))\n</code></pre>\n<p><strong><em>Linear recursion</em></strong> defines that the computation chains of operations is proportional to n and hence grows linearly. There is also another pattern of recursion, known as <strong><em>Tree Recursion</em></strong>. The best example will be the Fibonacci series, in which each element is the sum of the previous two:</p>\n<pre><code class=\"python\">( define ( fib n )\n    ( cond ( = n 0 ) 0 )\n           ( = n 1 ) 1 )\n           ( else ( + ( fib ( - n 1 ) )\n                      ( fib ( - n 2 ) )))))\n</code></pre>\n<p>You may find out that this procedure is not really efficient because to compute <strong>fib( - n 1)</strong>, <strong>fib( - n 2)</strong> has to be computed one more time which causes duplicated work.<br><img src=\"../images/treeRecursion.png\" alt=\"Tree Recursion\"><br>Therefore, instead of <strong><em>Tree Recursion</em></strong>, let’s try to convert it to be <strong><em>Linear Recursion</em></strong>. Reasign the sum of <strong>a</strong> and <strong>b</strong> to <strong>a</strong>, and the previous <strong>a</strong> to <strong>b</strong>:</p>\n<pre><code class=\"python\">( define ( fib n )\n    ( iterate 1 0 n ))\n\n( define ( iterate a b count )\n    ( if ( = count 0 )\n        b\n        ( iterate ( + a b ) a ( - count 1 ))))\n</code></pre>\n<p><br></p>\n<h2 id=\"Lambda\"><a href=\"#Lambda\" class=\"headerlink\" title=\"Lambda\"></a>Lambda</h2><p>Instead of defining some trivial procedures so that we can pass them as arguments of the other procedures, functional programming provides <strong><em>Lambda Expression</em></strong>:</p>\n<blockquote>\n<p>( lambda ( &lt;\\formal-param&gt; ) &lt;\\body&gt; )</p>\n</blockquote>\n<p>For instance,</p>\n<pre><code class=\"python\">( define ( Add a b ) ( + a b ))\n</code></pre>\n<p>can be written as:</p>\n<pre><code class=\"python\">( define add ( lambda ( a b ) ( + a b )))\n</code></pre>\n<p>And operators can also be represented by <strong><em>Lambda Expression</em></strong>:</p>\n<pre><code class=\"python\">(( lambda ( a b ) ( + ( * a a ) ( * b b ))) 2 3 )\n</code></pre>\n<p>Another use of <strong><em>Lambda Expression</em></strong> is creating local variables. An expression can be binded with a specific name by using keyword <strong><em>let</em></strong>. The above example then can be interpreted as:</p>\n<pre><code class=\"python\">( define ( sumsqr x y )\n    ( let ( a ( * x x ))\n          ( b ( * y y ))\n        ( + a b )))\n</code></pre>\n<p><strong><em>Note:</em></strong> The scope of a variable specified by a <strong><em>let</em></strong> is only applied to the <strong>body</strong> of the <strong><em>let</em></strong>. For example, if the evalue of <strong>x</strong> is <strong>2</strong>, then the expression:</p>\n<pre><code class=\"python\">( let (( x 3 )\n        ( y ( + x 2 )))\n    ( * x y ))\n</code></pre>\n<p>The value of <strong>y</strong> will be <strong>4</strong> as being outside of the <strong>let</strong> body, and the output will be <strong>3 * 4 = 12</strong>. It seems like <strong><em>let</em></strong> is really similar to <strong><em>define</em></strong>; however, in the most cases, we much prefer using <strong><em>let</em></strong> and only apply <strong><em>define</em></strong> to <strong>internal procedures</strong>.</p>\n","site":{"data":{}},"excerpt":"<pre><code class=\"python\">( 20 + 5 )\n( 16 / 4 )\n</code></pre>\n<p>Such expressions which denote procedures, are called <strong><em>combinations</em></strong>. The left and the right elements are called <strong><em>operands</em></strong>, and the element in the middle to indicate the operation is called <strong><em>operator</em></strong>. This is the most common style we have seen by now; however there is another way to construct a procedure known as <strong><em>prefix notation</em></strong>:</p>\n<pre><code class=\"python\">( + 20 5 )\n( / 16 4 )\n</code></pre>\n<p>Instead of injecting the operator between operands, which is a more human readable style, the prefix notation requires the operator always to be at the left most.","more":"</p>\n<p>conditions:</p>\n<pre><code class=\"python\">( define ( abs x )\n    ( cond (( &gt; x 0 ) x )\n           (( = x 0 ) 0 )\n           (( &lt; x 0 ) ( - x ))))\n</code></pre>\n<p>The general form can be expressed as:</p>\n<blockquote>\n<p>( cond (&lt;\\P1&gt; &lt;\\E1&gt;)<br>      (&lt;\\P2&gt; &lt;\\E2&gt;)<br>           …<br>      (&lt;\\Pn&gt; &lt;\\En&gt;))</p>\n</blockquote>\n<p>If none of them is evaluated to be <strong>true</strong>, then the value of the <strong>cond</strong> will be <strong>undefined</strong>. It can also be simplified by using <strong><em>else</em></strong>:</p>\n<pre><code class=\"python\">( define ( abs x )\n    ( cond (( &lt; x 0 ) ( - x ))\n           ( else  x )))\n</code></pre>\n<p>If there is only two <strong><em>predicates</em></strong> (the expression to be interpreted as either true of false), then it can use a special form <strong><em>if</em></strong>:</p>\n<pre><code class=\"python\">( define ( abs x )\n    ( if ( &lt; x 0 )\n         ( - x )\n         x ))\n</code></pre>\n<p>The general form of an <strong><em>if</em></strong> expression is:</p>\n<blockquote>\n<p>( if &lt;\\predicate&gt; &lt;\\consequent&gt; &lt;\\alternative&gt; )</p>\n</blockquote>\n<p>The logic operators:</p>\n<blockquote>\n<p>( and &lt;\\E1&gt; … &lt;\\En&gt; )<br>( or &lt;\\E1&gt; … &lt;\\En&gt; )<br>( not <e> )</e></p>\n</blockquote>\n<p>Then use the logic operators to define a predicate to evaluate if a number id larger or equal to the other one:</p>\n<pre><code class=\"python\">( define ( &gt;= x y )\n    ( or ( &gt; x y ) ( = x y ))\n</code></pre>\n<p>That is all the syntax, <strong>there is no loop in a functional programming language!</strong><br><br></p>\n<h2 id=\"Recursion\"><a href=\"#Recursion\" class=\"headerlink\" title=\"Recursion\"></a>Recursion</h2><p>Considering the factorial function:</p>\n<blockquote>\n<p>n! = n ⋅ (n-1) ⋅ (n-2) ⋅ … ⋅2⋅1</p>\n</blockquote>\n<p>Which can be computed as:</p>\n<blockquote>\n<p>n! = n ⋅ (n-1)!</p>\n</blockquote>\n<p>If we end it up with <strong>1!</strong>, then simply output <strong>1</strong>. Then the factorial function can be implemented in <strong><em>linear recursion</em></strong>:</p>\n<pre><code class=\"python\">( define ( factorial n )\n    ( if ( = n 1 )\n        1\n        ( * n ( factorial ( - n 1 )))))\n</code></pre>\n<p><strong><em>Linear recursion</em></strong> defines that the computation chains of operations is proportional to n and hence grows linearly. There is also another pattern of recursion, known as <strong><em>Tree Recursion</em></strong>. The best example will be the Fibonacci series, in which each element is the sum of the previous two:</p>\n<pre><code class=\"python\">( define ( fib n )\n    ( cond ( = n 0 ) 0 )\n           ( = n 1 ) 1 )\n           ( else ( + ( fib ( - n 1 ) )\n                      ( fib ( - n 2 ) )))))\n</code></pre>\n<p>You may find out that this procedure is not really efficient because to compute <strong>fib( - n 1)</strong>, <strong>fib( - n 2)</strong> has to be computed one more time which causes duplicated work.<br><img src=\"../images/treeRecursion.png\" alt=\"Tree Recursion\"><br>Therefore, instead of <strong><em>Tree Recursion</em></strong>, let’s try to convert it to be <strong><em>Linear Recursion</em></strong>. Reasign the sum of <strong>a</strong> and <strong>b</strong> to <strong>a</strong>, and the previous <strong>a</strong> to <strong>b</strong>:</p>\n<pre><code class=\"python\">( define ( fib n )\n    ( iterate 1 0 n ))\n\n( define ( iterate a b count )\n    ( if ( = count 0 )\n        b\n        ( iterate ( + a b ) a ( - count 1 ))))\n</code></pre>\n<p><br></p>\n<h2 id=\"Lambda\"><a href=\"#Lambda\" class=\"headerlink\" title=\"Lambda\"></a>Lambda</h2><p>Instead of defining some trivial procedures so that we can pass them as arguments of the other procedures, functional programming provides <strong><em>Lambda Expression</em></strong>:</p>\n<blockquote>\n<p>( lambda ( &lt;\\formal-param&gt; ) &lt;\\body&gt; )</p>\n</blockquote>\n<p>For instance,</p>\n<pre><code class=\"python\">( define ( Add a b ) ( + a b ))\n</code></pre>\n<p>can be written as:</p>\n<pre><code class=\"python\">( define add ( lambda ( a b ) ( + a b )))\n</code></pre>\n<p>And operators can also be represented by <strong><em>Lambda Expression</em></strong>:</p>\n<pre><code class=\"python\">(( lambda ( a b ) ( + ( * a a ) ( * b b ))) 2 3 )\n</code></pre>\n<p>Another use of <strong><em>Lambda Expression</em></strong> is creating local variables. An expression can be binded with a specific name by using keyword <strong><em>let</em></strong>. The above example then can be interpreted as:</p>\n<pre><code class=\"python\">( define ( sumsqr x y )\n    ( let ( a ( * x x ))\n          ( b ( * y y ))\n        ( + a b )))\n</code></pre>\n<p><strong><em>Note:</em></strong> The scope of a variable specified by a <strong><em>let</em></strong> is only applied to the <strong>body</strong> of the <strong><em>let</em></strong>. For example, if the evalue of <strong>x</strong> is <strong>2</strong>, then the expression:</p>\n<pre><code class=\"python\">( let (( x 3 )\n        ( y ( + x 2 )))\n    ( * x y ))\n</code></pre>\n<p>The value of <strong>y</strong> will be <strong>4</strong> as being outside of the <strong>let</strong> body, and the output will be <strong>3 * 4 = 12</strong>. It seems like <strong><em>let</em></strong> is really similar to <strong><em>define</em></strong>; however, in the most cases, we much prefer using <strong><em>let</em></strong> and only apply <strong><em>define</em></strong> to <strong>internal procedures</strong>.</p>"},{"title":"Slice in Golang","date":"2019-05-12T06:35:54.000Z","photos":["../images/GoSlice.JPG"],"_content":"This article is a summary from [Andrew Gerrand's blog](https://blog.golang.org/go-slices-usage-and-internals)\n\nGolang has an unique type **slice** which is an abstraction built on top of Go's **array** type. They are really similar but providing different means of working with sequences of typed data. So to understand slices we must first understand arrays.<!-- more -->\n</br>\n\n## Arrays in Go\nAn array in Go has to specify its **length** and **element type**. **The size of the array is fixed and its length is part of its type**. For example `[4]int` and `[5]int` are distinct and have different types even though they all store integers. And contrary to **C/C++**, the initial value of an array will be filled with **0** if it is not initialized.\n```Go\nvar a [4]int\na[0] = 1\ni := a[0]\nj := a[1]\n//i == 1\n//j == 0\n```\nGo's arrays are values. **An array variable denotes the entire array**; it is not a pointer to the first array element (as would be the case in C/C++). This means that when you assign or pass around an array value you will make a copy of its contents. (To avoid the copy you could pass a pointer to the array, but then that's a pointer to an array, not an array)\n\nAn array literal can be specified like so:\n```Go\nb := [2]string{\"aa\", \"bb\"}\n```\nOr, you can have the compiler counting the array elements for you:\n```Go\nb := [...]string{\"aa\", \"bb\"}\n```\nIn both cases, the type of b is **[2]string**.\n</br>\n\n## Slices in Go\nArrays are a bit inflexible, so you don't see them too often in the code. Slices, though, are everywhere. Unlike an array type, a slice type has no specific length:\n```Go\nb := []string{\"aa\", \"bb\"}\n```\nWe can use build-in function `make()` to define a slice:\n```Go\nfunc make([]T, len, cap) []T\n```\n**T** represent the type of the elements. Function **make** accepts type, length and capacity(optional) as parameters. When it is called, **make** will allocate an array and returns a slice that refers to that array\n```Go\nvar s []byte\ns = make([]byte, 5, 5)\n//s == []byte{0, 0, 0, 0, 0}\n```\nIf **cap** is not specified, it will be init as the value of **len**. We can use the build-in functions `len()` and `cap()` to check the length and capacity of a slice:\n```Go\nlen(s) == 5\ncap(s) == 5\n```\nThe zero value of a slice is **nil**. The len and cap functions will both return **0** for a nil slice.\n\nA slice can also be formed by \"slicing\" an existing slice or array, for example, the expression b[1:4] creates a slice including elements 1 through 3 of b:\n```Go\nb := []byte{'a', 'b', 'c', 'd', 'e', 'f'}\n// b[1:4] == []byte{'b', 'c', 'd'}, sharing the same storage as b\n```\nThe start and end indices of a slice expression are optional; they default to zero and the slice's length respectively:\n```Go\n// b[:2] == []byte{'a', 'b'}\n// b[2:] == []byte{'c', 'd', 'e', 'f'}\n// b[:] == b\n```\nThis is also the syntax to create a slice given an array:\n```Go\nx := [3]string{\"Лайка\", \"Белка\", \"Стрелка\"}\ns := x[:] // a slice referencing the storage of x\n```\n\nSlicing does not copy the slice's data. It creates a new slice value that points to the original array. This makes slice operations as efficient as manipulating array indices. Therefore, modifying the elements of a re-slice modifies the elements of the original slice:\n```Go\nd := []byte{'a', 'b', 'c', 'd'}\ne := d[2:]\n// e == []byte{'c', 'd'}\n\n// now change the re-slice will also change the original slice  \ne[1] = 'm'\n// e == []byte{'c', 'm'}\n// d == []byte{'a', 'b', 'c', 'm'}\n```\nA slice cannot be grown beyond its capacity. Attempting to do so will cause a ***runtime panic***, just as when indexing outside the bounds of a slice or array. Similarly, slices cannot be re-sliced below zero to access earlier elements in the array.\n</br>\n\n## Double the capacity of a slice\nTo increase the capacity of a slice, we must create a new, larger slice and **copy** the contents of the original slice into it. The belowing example shows how to create a new slice **t** whihc doubles the capacity of **s**:\n```Go\nt := make([]byte, len(s), (cap(s) * 2))\nfor i:= range s {\n    t[i] = s[i]\n}\ns = t   //reassign s to t\n```\nThe loop can be replaced by the build-in function `copy()`, which copies the data from source and returns the number of elements copied:\n```Go\nfunc copy(dst, src []T) int\n```\nThe function **copy** supports copying between slices of different lengths (it will copy only up to the smaller number of elements) and the case that two slices refer to the same array. Using **copy**, the above double size code snippet can be rewritten as:\n```Go\nt := make([]byte, len(s), (cap(s) * 2))\ncopy(t, s)\ns = t\n```\nA common operation is to append new data to the tail of a slice:\n```Go\nfunc AppendByte(slice []byte, data ...type) []byte {\n    m := len(slice)\n    n := m + len(data)\n    if n > cap(slice) { //if the original capacity is not big enough     \n        newSlice := make([]byte, (n + 1) * 2)\n        copy(newSlice, slice)\n        slice = newSlice\n    }\n    slice = slice[0:n] //shrink the capacity to the length of data  \n    copy(slice[m:n], data)\n    return slice\n}\n```\nThis customized AppendByte function is really useful because we can fully control the size of a slice. However most programs do need such complete control. Go provides a build-in function `append()` which appends slice x to the end of slice s, expanding s if needed:\n```Go\nfunc append(s []T, x ...T) []T\n```\nUsing **...** to append one slice to the end of another:\n```Go\na := []string{\"aa\", \"bb\"}\nb := []string{\"cc\", \"dd\"}\na = append(a, b...) //same as append(a, b[0], b[1], b[2])   \n```\nAnother example of append:\n```Go\nfunc Filter(s []int, fn func(int) bool) []int {\n    var p []int // p == nil\n    for _, v := range s {\n        if fn(v) {\n            p = append(p, v)\n        }\n    }\n    return p\n}\n```\n\n\n\n\n","source":"_posts/Type-slice-in-Golang.md","raw":"---\ntitle: Slice in Golang\ndate: 2019-05-12 15:35:54\ntags: Golang Array Slice\nphotos: [\"../images/GoSlice.JPG\"]\n---\nThis article is a summary from [Andrew Gerrand's blog](https://blog.golang.org/go-slices-usage-and-internals)\n\nGolang has an unique type **slice** which is an abstraction built on top of Go's **array** type. They are really similar but providing different means of working with sequences of typed data. So to understand slices we must first understand arrays.<!-- more -->\n</br>\n\n## Arrays in Go\nAn array in Go has to specify its **length** and **element type**. **The size of the array is fixed and its length is part of its type**. For example `[4]int` and `[5]int` are distinct and have different types even though they all store integers. And contrary to **C/C++**, the initial value of an array will be filled with **0** if it is not initialized.\n```Go\nvar a [4]int\na[0] = 1\ni := a[0]\nj := a[1]\n//i == 1\n//j == 0\n```\nGo's arrays are values. **An array variable denotes the entire array**; it is not a pointer to the first array element (as would be the case in C/C++). This means that when you assign or pass around an array value you will make a copy of its contents. (To avoid the copy you could pass a pointer to the array, but then that's a pointer to an array, not an array)\n\nAn array literal can be specified like so:\n```Go\nb := [2]string{\"aa\", \"bb\"}\n```\nOr, you can have the compiler counting the array elements for you:\n```Go\nb := [...]string{\"aa\", \"bb\"}\n```\nIn both cases, the type of b is **[2]string**.\n</br>\n\n## Slices in Go\nArrays are a bit inflexible, so you don't see them too often in the code. Slices, though, are everywhere. Unlike an array type, a slice type has no specific length:\n```Go\nb := []string{\"aa\", \"bb\"}\n```\nWe can use build-in function `make()` to define a slice:\n```Go\nfunc make([]T, len, cap) []T\n```\n**T** represent the type of the elements. Function **make** accepts type, length and capacity(optional) as parameters. When it is called, **make** will allocate an array and returns a slice that refers to that array\n```Go\nvar s []byte\ns = make([]byte, 5, 5)\n//s == []byte{0, 0, 0, 0, 0}\n```\nIf **cap** is not specified, it will be init as the value of **len**. We can use the build-in functions `len()` and `cap()` to check the length and capacity of a slice:\n```Go\nlen(s) == 5\ncap(s) == 5\n```\nThe zero value of a slice is **nil**. The len and cap functions will both return **0** for a nil slice.\n\nA slice can also be formed by \"slicing\" an existing slice or array, for example, the expression b[1:4] creates a slice including elements 1 through 3 of b:\n```Go\nb := []byte{'a', 'b', 'c', 'd', 'e', 'f'}\n// b[1:4] == []byte{'b', 'c', 'd'}, sharing the same storage as b\n```\nThe start and end indices of a slice expression are optional; they default to zero and the slice's length respectively:\n```Go\n// b[:2] == []byte{'a', 'b'}\n// b[2:] == []byte{'c', 'd', 'e', 'f'}\n// b[:] == b\n```\nThis is also the syntax to create a slice given an array:\n```Go\nx := [3]string{\"Лайка\", \"Белка\", \"Стрелка\"}\ns := x[:] // a slice referencing the storage of x\n```\n\nSlicing does not copy the slice's data. It creates a new slice value that points to the original array. This makes slice operations as efficient as manipulating array indices. Therefore, modifying the elements of a re-slice modifies the elements of the original slice:\n```Go\nd := []byte{'a', 'b', 'c', 'd'}\ne := d[2:]\n// e == []byte{'c', 'd'}\n\n// now change the re-slice will also change the original slice  \ne[1] = 'm'\n// e == []byte{'c', 'm'}\n// d == []byte{'a', 'b', 'c', 'm'}\n```\nA slice cannot be grown beyond its capacity. Attempting to do so will cause a ***runtime panic***, just as when indexing outside the bounds of a slice or array. Similarly, slices cannot be re-sliced below zero to access earlier elements in the array.\n</br>\n\n## Double the capacity of a slice\nTo increase the capacity of a slice, we must create a new, larger slice and **copy** the contents of the original slice into it. The belowing example shows how to create a new slice **t** whihc doubles the capacity of **s**:\n```Go\nt := make([]byte, len(s), (cap(s) * 2))\nfor i:= range s {\n    t[i] = s[i]\n}\ns = t   //reassign s to t\n```\nThe loop can be replaced by the build-in function `copy()`, which copies the data from source and returns the number of elements copied:\n```Go\nfunc copy(dst, src []T) int\n```\nThe function **copy** supports copying between slices of different lengths (it will copy only up to the smaller number of elements) and the case that two slices refer to the same array. Using **copy**, the above double size code snippet can be rewritten as:\n```Go\nt := make([]byte, len(s), (cap(s) * 2))\ncopy(t, s)\ns = t\n```\nA common operation is to append new data to the tail of a slice:\n```Go\nfunc AppendByte(slice []byte, data ...type) []byte {\n    m := len(slice)\n    n := m + len(data)\n    if n > cap(slice) { //if the original capacity is not big enough     \n        newSlice := make([]byte, (n + 1) * 2)\n        copy(newSlice, slice)\n        slice = newSlice\n    }\n    slice = slice[0:n] //shrink the capacity to the length of data  \n    copy(slice[m:n], data)\n    return slice\n}\n```\nThis customized AppendByte function is really useful because we can fully control the size of a slice. However most programs do need such complete control. Go provides a build-in function `append()` which appends slice x to the end of slice s, expanding s if needed:\n```Go\nfunc append(s []T, x ...T) []T\n```\nUsing **...** to append one slice to the end of another:\n```Go\na := []string{\"aa\", \"bb\"}\nb := []string{\"cc\", \"dd\"}\na = append(a, b...) //same as append(a, b[0], b[1], b[2])   \n```\nAnother example of append:\n```Go\nfunc Filter(s []int, fn func(int) bool) []int {\n    var p []int // p == nil\n    for _, v := range s {\n        if fn(v) {\n            p = append(p, v)\n        }\n    }\n    return p\n}\n```\n\n\n\n\n","slug":"Type-slice-in-Golang","published":1,"updated":"2019-05-12T08:25:48.418Z","_id":"cjvkl7rs10009seaog4oahdsz","comments":1,"layout":"post","link":"","content":"<p>This article is a summary from <a href=\"https://blog.golang.org/go-slices-usage-and-internals\" target=\"_blank\" rel=\"noopener\">Andrew Gerrand’s blog</a></p>\n<p>Golang has an unique type <strong>slice</strong> which is an abstraction built on top of Go’s <strong>array</strong> type. They are really similar but providing different means of working with sequences of typed data. So to understand slices we must first understand arrays.<a id=\"more\"></a><br><br></p>\n<h2 id=\"Arrays-in-Go\"><a href=\"#Arrays-in-Go\" class=\"headerlink\" title=\"Arrays in Go\"></a>Arrays in Go</h2><p>An array in Go has to specify its <strong>length</strong> and <strong>element type</strong>. <strong>The size of the array is fixed and its length is part of its type</strong>. For example <code>[4]int</code> and <code>[5]int</code> are distinct and have different types even though they all store integers. And contrary to <strong>C/C++</strong>, the initial value of an array will be filled with <strong>0</strong> if it is not initialized.</p>\n<pre><code class=\"Go\">var a [4]int\na[0] = 1\ni := a[0]\nj := a[1]\n//i == 1\n//j == 0\n</code></pre>\n<p>Go’s arrays are values. <strong>An array variable denotes the entire array</strong>; it is not a pointer to the first array element (as would be the case in C/C++). This means that when you assign or pass around an array value you will make a copy of its contents. (To avoid the copy you could pass a pointer to the array, but then that’s a pointer to an array, not an array)</p>\n<p>An array literal can be specified like so:</p>\n<pre><code class=\"Go\">b := [2]string{&quot;aa&quot;, &quot;bb&quot;}\n</code></pre>\n<p>Or, you can have the compiler counting the array elements for you:</p>\n<pre><code class=\"Go\">b := [...]string{&quot;aa&quot;, &quot;bb&quot;}\n</code></pre>\n<p>In both cases, the type of b is <strong>[2]string</strong>.<br><br></p>\n<h2 id=\"Slices-in-Go\"><a href=\"#Slices-in-Go\" class=\"headerlink\" title=\"Slices in Go\"></a>Slices in Go</h2><p>Arrays are a bit inflexible, so you don’t see them too often in the code. Slices, though, are everywhere. Unlike an array type, a slice type has no specific length:</p>\n<pre><code class=\"Go\">b := []string{&quot;aa&quot;, &quot;bb&quot;}\n</code></pre>\n<p>We can use build-in function <code>make()</code> to define a slice:</p>\n<pre><code class=\"Go\">func make([]T, len, cap) []T\n</code></pre>\n<p><strong>T</strong> represent the type of the elements. Function <strong>make</strong> accepts type, length and capacity(optional) as parameters. When it is called, <strong>make</strong> will allocate an array and returns a slice that refers to that array</p>\n<pre><code class=\"Go\">var s []byte\ns = make([]byte, 5, 5)\n//s == []byte{0, 0, 0, 0, 0}\n</code></pre>\n<p>If <strong>cap</strong> is not specified, it will be init as the value of <strong>len</strong>. We can use the build-in functions <code>len()</code> and <code>cap()</code> to check the length and capacity of a slice:</p>\n<pre><code class=\"Go\">len(s) == 5\ncap(s) == 5\n</code></pre>\n<p>The zero value of a slice is <strong>nil</strong>. The len and cap functions will both return <strong>0</strong> for a nil slice.</p>\n<p>A slice can also be formed by “slicing” an existing slice or array, for example, the expression b[1:4] creates a slice including elements 1 through 3 of b:</p>\n<pre><code class=\"Go\">b := []byte{&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;}\n// b[1:4] == []byte{&#39;b&#39;, &#39;c&#39;, &#39;d&#39;}, sharing the same storage as b\n</code></pre>\n<p>The start and end indices of a slice expression are optional; they default to zero and the slice’s length respectively:</p>\n<pre><code class=\"Go\">// b[:2] == []byte{&#39;a&#39;, &#39;b&#39;}\n// b[2:] == []byte{&#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;}\n// b[:] == b\n</code></pre>\n<p>This is also the syntax to create a slice given an array:</p>\n<pre><code class=\"Go\">x := [3]string{&quot;Лайка&quot;, &quot;Белка&quot;, &quot;Стрелка&quot;}\ns := x[:] // a slice referencing the storage of x\n</code></pre>\n<p>Slicing does not copy the slice’s data. It creates a new slice value that points to the original array. This makes slice operations as efficient as manipulating array indices. Therefore, modifying the elements of a re-slice modifies the elements of the original slice:</p>\n<pre><code class=\"Go\">d := []byte{&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;}\ne := d[2:]\n// e == []byte{&#39;c&#39;, &#39;d&#39;}\n\n// now change the re-slice will also change the original slice  \ne[1] = &#39;m&#39;\n// e == []byte{&#39;c&#39;, &#39;m&#39;}\n// d == []byte{&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;m&#39;}\n</code></pre>\n<p>A slice cannot be grown beyond its capacity. Attempting to do so will cause a <strong><em>runtime panic</em></strong>, just as when indexing outside the bounds of a slice or array. Similarly, slices cannot be re-sliced below zero to access earlier elements in the array.<br><br></p>\n<h2 id=\"Double-the-capacity-of-a-slice\"><a href=\"#Double-the-capacity-of-a-slice\" class=\"headerlink\" title=\"Double the capacity of a slice\"></a>Double the capacity of a slice</h2><p>To increase the capacity of a slice, we must create a new, larger slice and <strong>copy</strong> the contents of the original slice into it. The belowing example shows how to create a new slice <strong>t</strong> whihc doubles the capacity of <strong>s</strong>:</p>\n<pre><code class=\"Go\">t := make([]byte, len(s), (cap(s) * 2))\nfor i:= range s {\n    t[i] = s[i]\n}\ns = t   //reassign s to t\n</code></pre>\n<p>The loop can be replaced by the build-in function <code>copy()</code>, which copies the data from source and returns the number of elements copied:</p>\n<pre><code class=\"Go\">func copy(dst, src []T) int\n</code></pre>\n<p>The function <strong>copy</strong> supports copying between slices of different lengths (it will copy only up to the smaller number of elements) and the case that two slices refer to the same array. Using <strong>copy</strong>, the above double size code snippet can be rewritten as:</p>\n<pre><code class=\"Go\">t := make([]byte, len(s), (cap(s) * 2))\ncopy(t, s)\ns = t\n</code></pre>\n<p>A common operation is to append new data to the tail of a slice:</p>\n<pre><code class=\"Go\">func AppendByte(slice []byte, data ...type) []byte {\n    m := len(slice)\n    n := m + len(data)\n    if n &gt; cap(slice) { //if the original capacity is not big enough     \n        newSlice := make([]byte, (n + 1) * 2)\n        copy(newSlice, slice)\n        slice = newSlice\n    }\n    slice = slice[0:n] //shrink the capacity to the length of data  \n    copy(slice[m:n], data)\n    return slice\n}\n</code></pre>\n<p>This customized AppendByte function is really useful because we can fully control the size of a slice. However most programs do need such complete control. Go provides a build-in function <code>append()</code> which appends slice x to the end of slice s, expanding s if needed:</p>\n<pre><code class=\"Go\">func append(s []T, x ...T) []T\n</code></pre>\n<p>Using <strong>…</strong> to append one slice to the end of another:</p>\n<pre><code class=\"Go\">a := []string{&quot;aa&quot;, &quot;bb&quot;}\nb := []string{&quot;cc&quot;, &quot;dd&quot;}\na = append(a, b...) //same as append(a, b[0], b[1], b[2])   \n</code></pre>\n<p>Another example of append:</p>\n<pre><code class=\"Go\">func Filter(s []int, fn func(int) bool) []int {\n    var p []int // p == nil\n    for _, v := range s {\n        if fn(v) {\n            p = append(p, v)\n        }\n    }\n    return p\n}\n</code></pre>\n","site":{"data":{}},"excerpt":"<p>This article is a summary from <a href=\"https://blog.golang.org/go-slices-usage-and-internals\" target=\"_blank\" rel=\"noopener\">Andrew Gerrand’s blog</a></p>\n<p>Golang has an unique type <strong>slice</strong> which is an abstraction built on top of Go’s <strong>array</strong> type. They are really similar but providing different means of working with sequences of typed data. So to understand slices we must first understand arrays.","more":"<br><br></p>\n<h2 id=\"Arrays-in-Go\"><a href=\"#Arrays-in-Go\" class=\"headerlink\" title=\"Arrays in Go\"></a>Arrays in Go</h2><p>An array in Go has to specify its <strong>length</strong> and <strong>element type</strong>. <strong>The size of the array is fixed and its length is part of its type</strong>. For example <code>[4]int</code> and <code>[5]int</code> are distinct and have different types even though they all store integers. And contrary to <strong>C/C++</strong>, the initial value of an array will be filled with <strong>0</strong> if it is not initialized.</p>\n<pre><code class=\"Go\">var a [4]int\na[0] = 1\ni := a[0]\nj := a[1]\n//i == 1\n//j == 0\n</code></pre>\n<p>Go’s arrays are values. <strong>An array variable denotes the entire array</strong>; it is not a pointer to the first array element (as would be the case in C/C++). This means that when you assign or pass around an array value you will make a copy of its contents. (To avoid the copy you could pass a pointer to the array, but then that’s a pointer to an array, not an array)</p>\n<p>An array literal can be specified like so:</p>\n<pre><code class=\"Go\">b := [2]string{&quot;aa&quot;, &quot;bb&quot;}\n</code></pre>\n<p>Or, you can have the compiler counting the array elements for you:</p>\n<pre><code class=\"Go\">b := [...]string{&quot;aa&quot;, &quot;bb&quot;}\n</code></pre>\n<p>In both cases, the type of b is <strong>[2]string</strong>.<br><br></p>\n<h2 id=\"Slices-in-Go\"><a href=\"#Slices-in-Go\" class=\"headerlink\" title=\"Slices in Go\"></a>Slices in Go</h2><p>Arrays are a bit inflexible, so you don’t see them too often in the code. Slices, though, are everywhere. Unlike an array type, a slice type has no specific length:</p>\n<pre><code class=\"Go\">b := []string{&quot;aa&quot;, &quot;bb&quot;}\n</code></pre>\n<p>We can use build-in function <code>make()</code> to define a slice:</p>\n<pre><code class=\"Go\">func make([]T, len, cap) []T\n</code></pre>\n<p><strong>T</strong> represent the type of the elements. Function <strong>make</strong> accepts type, length and capacity(optional) as parameters. When it is called, <strong>make</strong> will allocate an array and returns a slice that refers to that array</p>\n<pre><code class=\"Go\">var s []byte\ns = make([]byte, 5, 5)\n//s == []byte{0, 0, 0, 0, 0}\n</code></pre>\n<p>If <strong>cap</strong> is not specified, it will be init as the value of <strong>len</strong>. We can use the build-in functions <code>len()</code> and <code>cap()</code> to check the length and capacity of a slice:</p>\n<pre><code class=\"Go\">len(s) == 5\ncap(s) == 5\n</code></pre>\n<p>The zero value of a slice is <strong>nil</strong>. The len and cap functions will both return <strong>0</strong> for a nil slice.</p>\n<p>A slice can also be formed by “slicing” an existing slice or array, for example, the expression b[1:4] creates a slice including elements 1 through 3 of b:</p>\n<pre><code class=\"Go\">b := []byte{&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;}\n// b[1:4] == []byte{&#39;b&#39;, &#39;c&#39;, &#39;d&#39;}, sharing the same storage as b\n</code></pre>\n<p>The start and end indices of a slice expression are optional; they default to zero and the slice’s length respectively:</p>\n<pre><code class=\"Go\">// b[:2] == []byte{&#39;a&#39;, &#39;b&#39;}\n// b[2:] == []byte{&#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;}\n// b[:] == b\n</code></pre>\n<p>This is also the syntax to create a slice given an array:</p>\n<pre><code class=\"Go\">x := [3]string{&quot;Лайка&quot;, &quot;Белка&quot;, &quot;Стрелка&quot;}\ns := x[:] // a slice referencing the storage of x\n</code></pre>\n<p>Slicing does not copy the slice’s data. It creates a new slice value that points to the original array. This makes slice operations as efficient as manipulating array indices. Therefore, modifying the elements of a re-slice modifies the elements of the original slice:</p>\n<pre><code class=\"Go\">d := []byte{&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;}\ne := d[2:]\n// e == []byte{&#39;c&#39;, &#39;d&#39;}\n\n// now change the re-slice will also change the original slice  \ne[1] = &#39;m&#39;\n// e == []byte{&#39;c&#39;, &#39;m&#39;}\n// d == []byte{&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;m&#39;}\n</code></pre>\n<p>A slice cannot be grown beyond its capacity. Attempting to do so will cause a <strong><em>runtime panic</em></strong>, just as when indexing outside the bounds of a slice or array. Similarly, slices cannot be re-sliced below zero to access earlier elements in the array.<br><br></p>\n<h2 id=\"Double-the-capacity-of-a-slice\"><a href=\"#Double-the-capacity-of-a-slice\" class=\"headerlink\" title=\"Double the capacity of a slice\"></a>Double the capacity of a slice</h2><p>To increase the capacity of a slice, we must create a new, larger slice and <strong>copy</strong> the contents of the original slice into it. The belowing example shows how to create a new slice <strong>t</strong> whihc doubles the capacity of <strong>s</strong>:</p>\n<pre><code class=\"Go\">t := make([]byte, len(s), (cap(s) * 2))\nfor i:= range s {\n    t[i] = s[i]\n}\ns = t   //reassign s to t\n</code></pre>\n<p>The loop can be replaced by the build-in function <code>copy()</code>, which copies the data from source and returns the number of elements copied:</p>\n<pre><code class=\"Go\">func copy(dst, src []T) int\n</code></pre>\n<p>The function <strong>copy</strong> supports copying between slices of different lengths (it will copy only up to the smaller number of elements) and the case that two slices refer to the same array. Using <strong>copy</strong>, the above double size code snippet can be rewritten as:</p>\n<pre><code class=\"Go\">t := make([]byte, len(s), (cap(s) * 2))\ncopy(t, s)\ns = t\n</code></pre>\n<p>A common operation is to append new data to the tail of a slice:</p>\n<pre><code class=\"Go\">func AppendByte(slice []byte, data ...type) []byte {\n    m := len(slice)\n    n := m + len(data)\n    if n &gt; cap(slice) { //if the original capacity is not big enough     \n        newSlice := make([]byte, (n + 1) * 2)\n        copy(newSlice, slice)\n        slice = newSlice\n    }\n    slice = slice[0:n] //shrink the capacity to the length of data  \n    copy(slice[m:n], data)\n    return slice\n}\n</code></pre>\n<p>This customized AppendByte function is really useful because we can fully control the size of a slice. However most programs do need such complete control. Go provides a build-in function <code>append()</code> which appends slice x to the end of slice s, expanding s if needed:</p>\n<pre><code class=\"Go\">func append(s []T, x ...T) []T\n</code></pre>\n<p>Using <strong>…</strong> to append one slice to the end of another:</p>\n<pre><code class=\"Go\">a := []string{&quot;aa&quot;, &quot;bb&quot;}\nb := []string{&quot;cc&quot;, &quot;dd&quot;}\na = append(a, b...) //same as append(a, b[0], b[1], b[2])   \n</code></pre>\n<p>Another example of append:</p>\n<pre><code class=\"Go\">func Filter(s []int, fn func(int) bool) []int {\n    var p []int // p == nil\n    for _, v := range s {\n        if fn(v) {\n            p = append(p, v)\n        }\n    }\n    return p\n}\n</code></pre>"},{"title":"Hello World","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).<!-- more -->\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).<!-- more -->\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","slug":"hello-world","published":1,"date":"2019-04-27T07:51:40.239Z","updated":"2019-04-29T07:18:13.367Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjvkl7rs2000aseaovy54wljw","content":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.<a id=\"more\"></a></p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><pre><code class=\"bash\">$ hexo new &quot;My New Post&quot;\n</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><pre><code class=\"bash\">$ hexo server\n</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><pre><code class=\"bash\">$ hexo generate\n</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><pre><code class=\"bash\">$ hexo deploy\n</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>\n","site":{"data":{}},"excerpt":"<p>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.","more":"</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><pre><code class=\"bash\">$ hexo new &quot;My New Post&quot;\n</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><pre><code class=\"bash\">$ hexo server\n</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><pre><code class=\"bash\">$ hexo generate\n</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><pre><code class=\"bash\">$ hexo deploy\n</code></pre>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"cjvkl7rrn0000seaora5r7s1e","tag_id":"cjvkl7rrv0004seao004akv1z","_id":"cjvkl7rs6000dseaons3rje2k"},{"post_id":"cjvkl7rrn0000seaora5r7s1e","tag_id":"cjvkl7rs00008seao78sn1w8d","_id":"cjvkl7rs6000eseaoors5mvf7"},{"post_id":"cjvkl7rrn0000seaora5r7s1e","tag_id":"cjvkl7rs5000bseao50mil14r","_id":"cjvkl7rs6000gseaohqjnjlh3"},{"post_id":"cjvkl7rrr0002seaozt5hxsmv","tag_id":"cjvkl7rs5000cseaok58f10s1","_id":"cjvkl7rs7000jseaokqqmfml3"},{"post_id":"cjvkl7rrr0002seaozt5hxsmv","tag_id":"cjvkl7rs6000fseao19bppkip","_id":"cjvkl7rs7000kseao77h2l5qy"},{"post_id":"cjvkl7rrr0002seaozt5hxsmv","tag_id":"cjvkl7rs6000hseao2r4eawxw","_id":"cjvkl7rs7000mseaoz2f87y5t"},{"post_id":"cjvkl7rrw0005seaog6udk8bo","tag_id":"cjvkl7rs6000iseaoxm72q84x","_id":"cjvkl7rs7000oseaoi0kr9uji"},{"post_id":"cjvkl7rrw0005seaog6udk8bo","tag_id":"cjvkl7rs7000lseaovlsszloe","_id":"cjvkl7rs7000pseaon96u6hvu"},{"post_id":"cjvkl7rry0006seaort6wvbm2","tag_id":"cjvkl7rs7000nseaogiid2r4q","_id":"cjvkl7rsb000useaoe6mo4o45"},{"post_id":"cjvkl7rry0006seaort6wvbm2","tag_id":"cjvkl7rs8000qseaoattp5tle","_id":"cjvkl7rsb000vseaou2lc81mc"},{"post_id":"cjvkl7rry0006seaort6wvbm2","tag_id":"cjvkl7rs8000rseao09lsvohd","_id":"cjvkl7rsb000xseaohu9d3xto"},{"post_id":"cjvkl7rry0006seaort6wvbm2","tag_id":"cjvkl7rs7000lseaovlsszloe","_id":"cjvkl7rsb000yseaora03t0dk"},{"post_id":"cjvkl7rrz0007seaozqmw76jr","tag_id":"cjvkl7rsa000tseaowwnx3mvc","_id":"cjvkl7rsc0011seaohcu9v1ah"},{"post_id":"cjvkl7rrz0007seaozqmw76jr","tag_id":"cjvkl7rsb000wseao71r4lm8w","_id":"cjvkl7rsc0012seaodm21zxga"},{"post_id":"cjvkl7rrz0007seaozqmw76jr","tag_id":"cjvkl7rsb000zseaofzvptucx","_id":"cjvkl7rsc0013seaoqxxvteko"},{"post_id":"cjvkl7rrz0007seaozqmw76jr","tag_id":"cjvkl7rsb0010seaowxz42s25","_id":"cjvkl7rsc0014seaoxf0q25ck"},{"post_id":"cjvkl7rs10009seaog4oahdsz","tag_id":"cjvkoa5hd0000zdaof0o85rc0","_id":"cjvkoa5he0001zdao37fwx3q8"}],"Tag":[{"name":"Redux","_id":"cjvkl7rrv0004seao004akv1z"},{"name":"Saga","_id":"cjvkl7rs00008seao78sn1w8d"},{"name":"React","_id":"cjvkl7rs5000bseao50mil14r"},{"name":"CLI","_id":"cjvkl7rs5000cseaok58f10s1"},{"name":"Mac OS","_id":"cjvkl7rs6000fseao19bppkip"},{"name":"port","_id":"cjvkl7rs6000hseao2r4eawxw"},{"name":"VS Code","_id":"cjvkl7rs6000iseaoxm72q84x"},{"name":"NodeJS","_id":"cjvkl7rs7000lseaovlsszloe"},{"name":"C++","_id":"cjvkl7rs7000nseaogiid2r4q"},{"name":"Java","_id":"cjvkl7rs8000qseaoattp5tle"},{"name":"Python","_id":"cjvkl7rs8000rseao09lsvohd"},{"name":"Lisp","_id":"cjvkl7rsa000tseaowwnx3mvc"},{"name":"Scheme","_id":"cjvkl7rsb000wseao71r4lm8w"},{"name":"Prefix Notation","_id":"cjvkl7rsb000zseaofzvptucx"},{"name":"Functional Programming","_id":"cjvkl7rsb0010seaowxz42s25"},{"name":"Golang Array Slice","_id":"cjvkoa5hd0000zdaof0o85rc0"}]}}